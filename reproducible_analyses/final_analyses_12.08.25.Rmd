---
title: "Final Pre-Data Collection Code: JTF002: DHF"
author: "Erin M. Buchanan & Lusine Grigoryan"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries

```{r libraries}
library(devtools) 
library(rio)
library(dplyr)
library(lavaan)
library(semPlot) 
library(faux)
library(broom)
library(semPower)
library(lme4)
library(lmerTest)
library(psych)
library(sirt)
library(tidyr)
library(stringr)
library(parameters)
library(visualizemi)
library(ggplot2)
library(UpSetR) # for missing data 
library(countrycode)

set.seed(48299439)
```

# SEM Variable Definition

This section defines the correlated error for Level 1/2 analyses for Hypothesis 1 (and then used throughout). We define these values at the top here to keep from repeating them below for clarity on the parts of the model that change.

```{r overall-variables}
corr_endors <- '
  dhf_endors_1 ~~ dhf_endors_2 +dhf_endors_3+dhf_endors_4+dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_2 ~~ dhf_endors_3+dhf_endors_4+dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
 
  dhf_endors_3 ~~ dhf_endors_4+dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_4 ~~ dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_5 ~~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_6 ~~ dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_7 ~~ dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_8 ~~ dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_9 ~~ dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_10 ~~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_11 ~~ dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
    
  dhf_endors_12 ~~ dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
      
  dhf_endors_13 ~~ dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
        
  dhf_endors_14 ~~ dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
          
  dhf_endors_15 ~~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
            
  dhf_endors_16 ~~ dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
              
  dhf_endors_17 ~~ dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
                
  dhf_endors_18 ~~ dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
                  
  dhf_endors_19 ~~ dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
                    
  dhf_endors_20 ~~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_21 ~~ dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_22 ~~ dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_23 ~~ dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_24 ~~ dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_25 ~~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_26 ~~ dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_27 ~~ dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_28 ~~ dhf_endors_29+dhf_endors_30

  dhf_endors_29 ~~ dhf_endors_30'

corr_norm <- '
  dhf_norm_1 ~~ dhf_norm_2 +dhf_norm_3+dhf_norm_4+dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_2 ~~ dhf_norm_3+dhf_norm_4+dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
 
  dhf_norm_3 ~~ dhf_norm_4+dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_4 ~~ dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_5 ~~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_6 ~~ dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_7 ~~ dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_8 ~~ dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_9 ~~ dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_10 ~~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_11 ~~ dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
    
  dhf_norm_12 ~~ dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
      
  dhf_norm_13 ~~ dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
        
  dhf_norm_14 ~~ dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
          
  dhf_norm_15 ~~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
            
  dhf_norm_16 ~~ dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
              
  dhf_norm_17 ~~ dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
                
  dhf_norm_18 ~~ dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
                  
  dhf_norm_19 ~~ dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
                    
  dhf_norm_20 ~~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_21 ~~ dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_22 ~~ dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_23 ~~ dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_24 ~~ dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_25 ~~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_26 ~~ dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_27 ~~ dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_28 ~~ dhf_norm_29+dhf_norm_30

  dhf_norm_29 ~~ dhf_norm_30'
```

# Data

```{r import-data}
# load data
dt <- import("dhf_data_final.csv")

# example data structure 
head(names(dt))
```

# Data Cleaning

Step 1. Data preparation

-   (Re)code all variables, check distributions and missing values.
-   Calculate overall item measures:
    -   Note that these will be calculated by taking the mean score on all appropriate items for that measure excluding missing data, as long as a participant has at least one data point for that measure.
    -   For example, if someone has items 2 and 3 for the SWLS, these two items will averaged for that measure.
    -   We will test the robustness of our findings on a subsample of participants with no missing values. Each analysis will be run only on a subsample of participants who have no missing values on the variables involved in that analysis.

## Socio-demographics

```{r demographic-clean}
#L: variable names changed to match the new data
factorized_var_numbers<-
  c(which(names(dt)=="gender"),
    which(names(dt)=="Migration"),
    which(names(dt)=="location_childhood"),
    which(names(dt)=="location_current"),
    which(names(dt)=="ethnicity"),
    which(names(dt)=="religion"),
    which(names(dt)=="education"),
    which(names(dt)=="student"),
    which(names(dt)=="income"),
    which(names(dt)=="Country"),
    which(names(dt)=="Country_full"),
    which(names(dt)=="Sample"),
    which(names(dt)=="datasource"))

numeric_var_numbers<-
  c(which(names(dt)=="Age"))

# refactor gender, age, education, state, race, migration 
dt[,factorized_var_numbers] <- lapply(dt[,factorized_var_numbers], as.factor)
dt[,numeric_var_numbers] <- as.numeric(dt[,numeric_var_numbers])
```

## Clean Country Names

```{r demographic-clean-country}
country_codes <- import("country_codes.xlsx")
dt_temp <- dt %>% 
  # clean up missing data 
  mutate(country_res = gsub(-999, NA, country_res),
         country_res = gsub(-99, NA, country_res),
         country_res = gsub(199, NA, country_res)) %>% 
  # don't need this for full data just helps you see
  select(country_res, LabID, Country_full, Country, Q_Language) %>% 
  # create country res full from country codes selected
  mutate(country_res_full = factor(
    country_res,
    levels = c(country_codes$code),
    labels = c(country_codes$country)
  )) %>% 
  # fix some lab id issues 
  mutate(
    LabID = if_else(
      LabID == "" | is.na(LabID),
      str_extract(Q_Language, "(\\d+)(?!.*\\d)"),  # last number in string
      LabID
    )
  ) %>% 
  mutate(LabID = gsub("3587,3587", "3587", LabID),
         LabID = gsub("3746,3746", "3746", LabID)) %>% 
  mutate(
    country_res_full = ifelse(
      is.na(country_res_full),
      as.character(Country_full),
      as.character(country_res_full)
    )
  ) %>% 
  mutate(Country = gsub("ET\\$LabID=3300", "ET", Country), 
         Country = gsub("UA,UA", "UA", Country), 
         Country = gsub("CM,CM", "CM", Country),
         Country = gsub("TRUZ", "UZ", Country),
         Country = gsub("GB", "UK", Country)) %>% 
  mutate(
    Country = if_else(
      is.na(Country) | Country == "",
      str_extract(Q_Language, "(?<=^[A-Z]{2}-?)[A-Z]{2}"),
      Country
    )
  ) %>% 
  mutate(
    Country = case_when(
      Q_Language == "RO-3304"   ~ "RO",
      Q_Language == "SR-2088-C" ~ "SR",
      Q_Language == "HE-2412"   ~ "IL",
      Q_Language == "SR-2088" ~ "SR", 
      Q_Language == "SQI-4150" ~ "SQI",
      Q_Language == "KAT-GE4378" ~ "GA",
      TRUE ~ Country            # keep existing Country
    ),
    country_res_full = case_when(
      is.na(country_res_full) & Q_Language == "RO-3304"   ~ "Romania",
      is.na(country_res_full) & Q_Language == "SR-2088-C" ~ "Serbia",
      is.na(country_res_full) & Q_Language == "HE-2412"   ~ "Israel",
      is.na(country_res_full) & Q_Language == "SR-2088" ~ "Serbia", 
      is.na(country_res_full) & Q_Language == "SQI-4150" ~ "Albania",
      is.na(country_res_full) & Q_Language == "KAT-GE4378" ~ "Georgia",
      is.na(country_res_full) & Q_Language == "EN-KU-2480" ~ "Kuwait",
      TRUE ~ country_res_full            # keep existing Country
    )
  ) %>% 
  mutate(
    country_res_full = if_else(
      is.na(country_res_full) | country_res_full == "",
      countrycode(Country, origin = "iso2c", destination = "country.name"),
      country_res_full
    )
  ) %>% 
  mutate(
    country_res_full = recode(
      country_res_full,
      "Hong Kong (S.A.R.)" = "Hong Kong",
      "Bosnia & Herzegovina" = "Bosnia-Herzegovina",
      "Macao SAR China" = "Macau (S.A.R.)"
    )
  )

# let's look at where they change 
dt_temp %>% 
  select(Country_full, country_res_full) %>% 
  group_by(Country_full, country_res_full) %>% 
  count() %>% 
  filter(Country_full != country_res_full)

table(dt_temp$country_res_full, useNA = "ifany")
length(unique(dt_temp$country_res_full))
sum(table(dt_temp$country_res_full, useNA = "ifany") > 50)
```

- don't exclude age, migration if they are missing
- include missing for attention checks for alls but exclude if it's missing overall
- fix country issues with labid country q_lang --> going with country_res then lab information, else exclude 

## Data exclusions based on demographics

### Age

```{r demographic-clean-age}
table(dt$Age, useNA = "ifany")
dt$Age[dt$Age == -999] <- NA
dt$Age[dt$Age == -99] <- NA
table(dt$Age, useNA = "ifany")

describe(dt$Age)

# look at missing data for Age versus rest of study 
dt_age_test <- 
  dt %>% 
  select(Age, dhf_endors_1:dhf_norm_30) %>% 
  rowwise() %>%
  mutate(missing_count = sum(is.na(c_across(everything()))),
         missing_Age = is.na(Age)) %>%
  ungroup()

dt_age_test %>% 
  group_by(missing_Age) %>% 
  summarize(missingness_avg = mean(missing_count)/(ncol(.)-1), 
            range_low = min(missing_count), 
            range_high = max(missing_count),
            n = n())

dt_age_test %>%
  filter(missing_Age) %>% 
  mutate(missing_bin = cut(
    missing_count,
    breaks = c(0, 10, 20, 30, 40, 50, 60, Inf),
    labels = c("1-10", "11-20", "21-30", "31-40", "41-50", "51-60", "61+"),
    right = TRUE
  )) %>%
  count(missing_bin)

# mark age in dataset 
dt <- dt %>% 
  mutate(Age_exclude = is.na(Age))

table(dt$Age_exclude)
```

### Born/Raised in Country 

- Many NAs, some because participants dropped out, some because the question wasn't shown in the country. If I exclude NAs here, we lose all ALLS data, so including for now. 

```{r demographics-clean-country}
#exclude those who were not born and raised in the country
table(dt$Migration, useNA = "ifany")

dt <- dt %>% 
  mutate(Migration = gsub(-99, NA, Migration)) %>% 
  mutate(Migration_exclude = (Migration == 2 | Migration == 4 | is.na(Migration)))

table(dt$Migration_exclude)
```

### Attention Checks

- It looked like we also didn't have these attention checks in ALLS countries, as we lose them all after this exclusion

```{r demographics-clean-attention}
#exclude participants who failed 2 or 3 attention checks
dt <- dt %>% 
  mutate(attention1_score = ifelse(attention_1==2, 1, 0),
         attention2_score = ifelse(attention_2==5, 1, 0),
         attention3_score = ifelse(attention_3==3, 1, 0)) %>% 
  rowwise() %>% 
  mutate(attention_exclude = (sum(c(attention1_score, attention2_score, attention3_score)) < 2) | is.na(sum(c(attention1_score, attention2_score, attention3_score)))) %>% 
  ungroup()

table(dt$attention_exclude, useNA = "ifany")
```

### Countries < 50 

```{r demographics-clean-country}
#exclude countries with <50 participants
table(dt$Country_full, useNA = "ifany")

country_missing <- dt %>% 
  filter(is.na(Country_full))
table(country_missing$Q_Language)

dt <- dt %>% 
  group_by(Country_full) %>%
  mutate(country_count = n()) %>%
  ungroup() %>% 
  mutate(country_exclude = country_count < 50) # add missing 
```

### Examine Exclusions Together

```{r exclusions}
dt_exclude <- dt %>% 
  mutate(alls_exclude = datasource == "ALLS") %>% 
  select(ends_with("exclude")) %>% 
  as.data.frame()

sets <- c("Age_exclude","Migration_exclude",
          "attention_exclude","country_exclude",
          "alls_exclude")
idx <- seq_len(nrow(dt_exclude))
sets_list <- setNames(lapply(sets, \(s) idx[dt_exclude[[s]]]), sets)
upset(fromList(sets_list), order.by = "freq")
```

- don't exclude age, migration if they are missing
- include missing for attention checks for alls but exclude if it's missing overall
- fix country issues with labid country q_lang --> going with country_res then lab information, else exclude 

```{r}
table(dt4$gender, useNA = "ifany")
prop.table(table(dt4$gender)) #67% women, 31% men, 1% NB, 1% other or no response  

table(dt4$datasource, useNA = "ifany") #All ALLS data is gone, because of migration var and attention checks. Decide what to do.

table(dt4$student, useNA = "ifany")
prop.table(table(dt4$student)) #70% students, 30% not

table(dt4$religion, useNA = "ifany")
prop.table(table(dt4$religion)) #28% No affiliation, 39% Christian, 17% Muslim, 2% Jewish, 2% Hindu, 4% Buddhist, 8% other or do not want to respond

table(dt4$Progress, useNA = "ifany") #varies between 51-100%, which means they all passed at least DHF, which was our exclusion criteria. Two weird categories besides number - "complete" and "live", check with Priya

##dt4 should be used for all analysis except those involving behavioral measures##
```

suggestion combine these together into a dataset marked for each one's exclusion to see if the Age thing will matter 

## Behavior_comprehension checks

-   Create a new dataset excluding participants who failed to correctly answer the comprehension questions in the dictator and/or ultimatum games (dt5). This dataset will be used for all analyses that involve the games.

```{r exclude-comprehension}
#dictator game
dt4$dictator_cpass <- ifelse((dt4$Dictator.comp1.1_dich=="Correct"|dt4$Dictator.comp2.1_dich=="Correct")&
                               (dt4$Dictator.comp1.2_dich=="Correct"|dt4$Dictator.comp2.2_dich=="Correct"),1,0)
table(dt4$dictator_cpass, useNA = "ifany")
dt5 <- subset(dt4, dictator_cpass==1) #N=21612

##use dt5 for all tests that involve the Dictator Game##

#ultimatum game
dt4$ultimatum_cpass <- ifelse((dt4$Ultimatum.comp.1.1_dich=="Correct"|dt4$Ultimatum.comp.2.1_dich=="Correct")&
                               (dt4$Ultimatum.comp.1.2_dich=="Correct"|dt4$Ultimatum.comp.2.2_dich=="Correct"),1,0)
dt6 <- subset(dt4, ultimatum_cpass==1) #N=20690

##use dt6 for all tests that involve the Dictator Game##


```

-   Randomly match participants within countries and calculate their hypothetical earnings based on their decisions in the economic games.

```{r decision-matching}
##I'm thinking we should calculate this only based on the ultimatum game, because for the dictator game, it doesn't really matter whether they send money to someone else or not, the total amount of money in the pool remains the same; whereas in the ultimatum game, if offers are rejected, the total amount of money goes down. Does that make sense? Any reason why we would want to also do the matching for the dictator game? 

# if you are in the same group the money is just the average of the group
# cooperation game more important --> group overall might win or lose 
```

-   Merge all country datasets (dt1 and dt2).

```{r merge-all-data}
# coming based on real dataset
```


## DHF

```{r dhf-clean}
# DHF ----

# look at the scaling 
table(dt$dhf_endors_1, useNA = "ifany") #L: -99 is also a missing value. Assign all as missing? 

dt$dhf_endors_1[dt$Age == -99] <- NA

numeric_var_numbers<-
  c(which(names(dt)=="Age"))

# examine data
DHF_first_num <- which(names(dt)=="dhf_endors_1")
DHF_last_num <- which(names(dt)=="dhf_norm_30")
describe(dt[ , c(DHF_first_num:DHF_last_num)]) #L: why some of the output shows up in console and some only here?
#L: why is this needed? how is it different from just c(dhf_endors_1:dhf_norm_30)?

dt <- dt %>%
  mutate(across(dhf_endors_1:dhf_norm_30, ~na_if(as.numeric(.), -99)))

```


## Behavior

```{r behavior-clean}
# Behavior ----

# dictator = universal prosociality for our experiment
dt$prosocial <- as.numeric(dt$Dictator_decision)

# examine the data 
describe(dt$prosocial) 

# ultimatum_receiver=negative reciprocity
# select those rows 
receiver <- dt %>% 
  select(ResponseId, `Ultimatum Receiver_1`:`Ultimatum Receiver_11`)

# convert to long format for scoring
receiver_long <- receiver %>%
  pivot_longer(!ResponseId, names_to = "proposed", values_to = "decision")
  
# score the dictator game based on decisions made by pairs of 
# participants 
receiver_long$change <- ifelse(receiver_long$decision=="I accept" & 
                     (((receiver_long$decision != dplyr::lag(receiver_long$decision))==TRUE)|
                        (receiver_long$proposed=="Ultimatum Receiver_1")),1,0)
receiver_long$proposed <- str_remove(receiver_long$proposed, "Ultimatum Receiver_")
receiver_long$UG_negrec <- ifelse(receiver_long$change==1,receiver_long$proposed,0)
neg_rec_df <- subset(receiver_long, receiver_long$UG_negrec!=0)
neg_rec_df$dupl <- ifelse(duplicated(neg_rec_df$ResponseId)==TRUE,1,0)
neg_rec_df <- subset(neg_rec_df, neg_rec_df$dupl==0)

neg_rec_df <- neg_rec_df %>% 
  select(ResponseId, UG_negrec)
dtg <- merge(dt, neg_rec_df, by="ResponseId")
dtg$UG_negrec <- as.numeric(dtg$UG_negrec)

# examine data
100*table(dtg$`Ultimatum Receiver_1`)%>% prop.table() 
100*table(dtg$`Ultimatum Receiver_2`)%>% prop.table() 
100*table(dtg$`Ultimatum Receiver_3`)%>% prop.table() 
100*table(dtg$`Ultimatum Receiver_4`)%>% prop.table() 
100*table(dtg$`Ultimatum Receiver_5`)%>% prop.table() 

# ultimatum_proposer=positive reciprocity
# select data 
proposer <- dt %>% 
  select(ResponseId, `Ultimatum Proposer_1`:`Ultimatum Proposer_11`)

# pivot longer to score the data 
proposer_long <- proposer %>%
  pivot_longer(!ResponseId, names_to = "proposed", values_to = "decision")
proposer_long$proposed <- str_remove(proposer_long$proposed, "Ultimatum Proposer_")

proposer_long[ , c("proposed", "decision")] <- lapply(proposer_long[ , c("proposed", "decision")], as.numeric)
proposer_long$proposed <- proposer_long$proposed-1
cor.test(proposer_long$proposed, proposer_long$decision) 
# r between proposal to and from = .54***  
describe(proposer_long$decision) 
# m=4.78 (4.78/11*100=43%)

proposer_long$pr <- ifelse(proposer_long$decision>=proposer_long$proposed,1,0)
pos_rec_df <- aggregate(proposer_long$pr,by=list(proposer_long$ResponseId), FUN=sum)
pos_rec_df$UG_posrec <- (pos_rec_df$x/11)*100
pos_rec_df$ResponseId <- pos_rec_df$Group.1
pos_rec_df <- pos_rec_df %>% 
  select(ResponseId, UG_posrec)

# create merged dataset
dtg <- merge(dtg, pos_rec_df, by="ResponseId")

# examine correlations
cor.test(dtg$PosRec,dtg$UG_posrec) 
cor.test(dtg$NegRec,dtg$UG_negrec) 
cor.test(dtg$PosRec,dtg$UG_negrec) 
cor.test(dtg$NegRec,dtg$UG_posrec) 
```

## Expectations

```{r expectations-clean}
# Expectations----
expect <- dt %>% 
  select(ResponseId, `Ultimatum expect_1`:`Ultimatum expect_11`)

# create an expectation long dataset to score the data
expect_long <- expect %>%
  pivot_longer(!ResponseId, names_to = "proposed", values_to = "decision")

# score the expectations
expect_long$change <- ifelse(expect_long$decision=="The other person would accept" & 
                     (((expect_long$decision != dplyr::lag(expect_long$decision))==TRUE)|
                        (expect_long$proposed=="Ultimatum expect_1")),1,0)
expect_long$proposed <- str_remove(expect_long$proposed, "Ultimatum expect_")
expect_long$UG_expect <- ifelse(expect_long$change==1, expect_long$proposed, 0)
expect_df <- subset(expect_long, expect_long$UG_expect!=0)
expect_df$dupl <- ifelse(duplicated(expect_df$ResponseId)==TRUE,1,0)
expect_df <- subset(expect_df, expect_df$dupl==0)

# select the final columns and merge
expect_df <- expect_df %>% 
  select(ResponseId, UG_expect)
dtg <- merge(dtg, expect_df, by="ResponseId")
dtg$UG_expect <- as.numeric(dtg$UG_expect)

# check the data 
describe(dtg$UG_expect)
```

## Reciprocity

```{r reciprocity-clean}
# Reciprocity ----

# look at the scoring
table(dt$Reciprocity_1, useNA = "ifany") # not all response options are available for this var
table(dt$Reciprocity_6, useNA = "ifany") # for this variable all options are shown

# recode variables to numeric
dt <- dt %>%
  mutate_at(vars(Reciprocity_1:Reciprocity_6), ~dplyr::case_when(
    . == "Does not apply to me at all\r\n1\r\n" ~ 1,
    . == "1" ~ 1,
    . == "2" ~ 2,
    . == "3" ~ 3,
    . == "4" ~ 4,
    . == "5" ~ 5,
    . == "6" ~ 6,
    . == "7" ~ 6,
    . == "Applies to me perfectly\r\n7\r\n" ~ 7,
    TRUE ~ NA_integer_
  ))

# examine data
Recprocity_first_num <- which(names(dt)=="Reciprocity_1")
Recprocity_last_num <- which(names(dt)=="Reciprocity_6")
describe(dt[,c(Recprocity_first_num:Recprocity_last_num)])

# review alpha 
psych::alpha(dt[c("Reciprocity_1","Reciprocity_2","Reciprocity_3")]) 
psych::alpha(dt[c("Reciprocity_4","Reciprocity_5","Reciprocity_6")]) 

# calculate positive and negative reciprocity  
dt$PosRec <- rowMeans(dt[c("Reciprocity_1","Reciprocity_2","Reciprocity_3")], na.rm=TRUE)
describe(dt$PosRec)
dt$NegRec <- rowMeans(dt[c("Reciprocity_4","Reciprocity_5","Reciprocity_6")], na.rm=TRUE)
describe(dt$NegRec)
```

## Calculate Reliability at Country Level

-   Calculate alpha reliability coefficients by country for each secondary measure (self-reported positive and negative reciprocity, attitude toward violence (three subscales and the total scale), self-face and other-face concern, reactions to provocation (three subscales), values (four higher-order value subscales), moral foundations (five subscales), intrinsic religiosity from DUREL, SWLS). If alpha is \>.60, calculate the index. If alpha is \< .60, consider modifications. Items will be removed only if the removal of the item improves alpha by \> .10 points in at least half of the countries.

```{r reliability}
# secondary measure (self-reported positive and negative reciprocity, attitude toward violence (three subscales and the total scale), self-face and other-face concern, reactions to provocation (three subscales), values (four higher-order value subscales), moral foundations (five subscales), intrinsic religiosity from DUREL, SWLS)

# we would do this by country - the code above shows the reliability overall, would include psych::alpha for each country. 
```

## Merge with Country Data

-   Merge with secondary country-level data on GDP per capita, inequality (Gini), HDI, GII, Democracy and Global freedom indicators.

```{r merge-country-level}
# coming based on real dataset
```

-   Merge with secondary historical country-level data on population density-1500 and 2000, pathogen prevalence, resource scarcity, war, and territorial threats.

```{r merge-country-level2}
# coming based on real dataset
```

-   Merge with country-level secondary data on cultural dimensions normsism-collectivism, flexibility-monumentalism, tightness-looseness, relational mobility, and Schwartz country-level value scores.

```{r merge-country-level3}
# coming based on real dataset
```

```{r temp-data}
# temp rename data to make this code proposal work 
DF <- dtg
```

# Terminology

Individual endorsement: Ratings on DHF for how much an individual endorses each item

Cultural norms: ratings on DHF for how much the person believes the country cultural norms represent endorsement on each item

Individual-level: using each participant's scores to represent the variable

Sample-level: using an average score by country to represent the variable

Level 1: [within] Analysis in multilevel models using the DHF data points for each participant (i.e., using each person’s scores as the level of analysis)

Level 2: [cluster] Analysis in multilevel models using the data points nested or clustered by the indicated variable (i.e., basically the average score for each item across the cluster variable as the level of analysis)

# Overall Model Comments

In each structural model, we may find the following issues:

-   Heywood cases:
    -   Too high correlations: we will consider combining factors when correlations between latent variables are too high if they theoretically make sense.\
    -   Negative variances: we will set the variance to a small positive number based on the variances of other items or latent variables
-   Non-convergence:
    -   We will try to find the issue of non-convergence - for example, if the country level does not have enough variability, we may remove the clustering effect to show convergence.
    -   For hierarchical models, we will consider setting all exogenous only correlations to 0 - rather than the proposed model below - to ensure identification.
    -   For all models, we will investigate just the level 1 factor structure of the model to determine model misspecification.
    -   For all models, we will investigate each country separately to determine if one sample creates the specific non-convergence issue (in the full model or just level 1 factor structure).
    -   We will also consider testing level-1 and level-2 for each model separately if they cannot be combined with convergence.

*Note*: code below is the pre-registered models. They currently do not run because of convergence issues, but these have not been edited because they are the planned models with larger samples.

# H1A

*Hypothesis*:

H1A: A hierarchical model with three higher-order factors of dignity, honor, and face, each represented by two facets of self-concern and other-concern, will appropriately describe the data.

*Analysis Plan*:

Individual endorsement and cultural norms will be tested separately. For each model, country will be used as a cluster variable.

Factor structure (see Fig. 1A): Multilevel confirmatory factor analysis (CFA), specifying a hierarchical model with three correlated higher-order latent factors representing dignity, honor, and face, each with two sub-factors representing the self-concern and other-concern facets.

Test 1: Level 1 will include the proposed factor structure, and Level 2 will include only the saturated model where all observed variables are intercorrelated.

Test 2: Level 1 will include only the saturated model of observed variable correlations, and Level 2 will include the proposed factor structure.

Individual endorsement and cultural norms will be tested separately. For each model, country will be used as a cluster variable.

*Model Evaluation*:

If the model converges, it will be compared to the models below (see notes below). If the model does not converge after making adjustments as described under “Overall model plans”, we will test the simpler alternative model with 6 correlated latent factors (see Fig. 1C). After model selection, we will use the guidelines in the model improvement and alignment section to improve model fit.

## Data Simulation

```{r data-simulation-hierarchical, eval = F}
DF_individual <- DF %>% 
  filter(`US state` == "Texas" | `US state` == "New York") %>% 
  dplyr::rename(country = `US state`) %>% 
   mutate(country = droplevels(as.factor(country))) %>% 
  select(DHF_endorsement_1:DHF_endorsement_30, country)

colnames(DF_individual) <- c(paste0(
  rep(c("D_self", "D_other", "H_self", 
        "H_other", "F_self", "F_other"), 
      each = 5),
  rep(1:5)), "country")

DF_norms <- DF %>% 
  filter(`US state` == "Texas" | `US state` == "New York") %>% 
  dplyr::rename(country = `US state`) %>% 
  mutate(country = droplevels(as.factor(country))) %>% 
  select(DHF_Norms_1:DHF_Norms_30, country)

colnames(DF_norms) <- c(paste0(
  rep(c("D_self", "D_other", "H_self", 
        "H_other", "F_self", "F_other"), 
      each = 5),
  rep(1:5)), "country")
```

## Power

```{r power-hierarchical, eval = F}
p <- 30 # number of observed variables 
k <- 564 # number of estimated parameters 
# you don't divide by 2 because you have it for the within and between covariance matrices 
df <- p*(p - 1) - k
df
semPower(type = 'a-priori', 
         effect = .08,
         effect.measure = "RMSEA",
         alpha = .05, 
         power = .90, 
         df = df,
         p = 30
         )
```

```{r power-hierarchical2, eval = F}
semPower(type = 'a-priori', 
         effect = .90,
         effect.measure = "AGFI",
         alpha = .05, 
         power = .90, 
         df = df,
         p = 30
         )
```

## H1A Individual

### Hierarchical Individual Test 1

```{r individual-hierarchical-test1-original, eval = F}
hierarchical.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
Level: 2
', 
corr_error)

hierarchical.individual.test1.fit <- cfa(model = hierarchical.model.test1,
                    data = DF_individual,
                    cluster = "country"
                    # options to consider
                    # optim.method = "em",
                    # em.iter.max = 1000,
                    # em.fx.tol = 1e-08, 
                    # em.dx.tol = 1e-04
                    )

summary(hierarchical.individual.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

hierarchical.individual.test1.fitindices <- tidy(fitmeasures(hierarchical.individual.test1.fit))
hierarchical.individual.test1.params <- tidy(hierarchical.individual.test1.fit)
```

notes on what added here blah blah blah 

```{r individual-hierarchical-test1-updated}
hierarchical.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
Level: 2
', 
corr_error)

hierarchical.individual.test1.fit <- cfa(model = hierarchical.model.test1,
                    data = DF_individual,
                    cluster = "country"
                    # options to consider
                    # optim.method = "em",
                    # em.iter.max = 1000,
                    # em.fx.tol = 1e-08, 
                    # em.dx.tol = 1e-04
                    )

summary(hierarchical.individual.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

hierarchical.individual.test1.fitindices <- tidy(fitmeasures(hierarchical.individual.test1.fit))
hierarchical.individual.test1.params <- tidy(hierarchical.individual.test1.fit)
```

### Hierarchical Individual Test 2

```{r individual-hierarchical-test2, eval = F}
hierarchical.model.test2 <- 
paste0(' 
Level: 1', 
corr_error, 
'
Level: 2 
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5
  
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+D_other1+
  D_other2+D_other3+D_other4+D_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
  F_other1+F_other2+F_other3+F_other4+F_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
  H_other1+H_other2+H_other3+H_other4+H_other5
  
  D_self ~~ 0*D_other
  H_self ~~ 0*H_other
  F_self ~~ 0*F_other
')

hierarchical.individual.test2.fit <- cfa(model = hierarchical.model.test2,
                    data = DF_individual,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(hierarchical.individual.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

hierarchical.individual.test2.fitindices <- tidy(fitmeasures(hierarchical.individual.test2.fit))
hierarchical.individual.test2.params <- tidy(hierarchical.individual.test2.fit)
```

## H1A Norms

### Hierarchical Norms Test 1

```{r norms-hierarchical-test1, eval = F}
hierarchical.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5
  
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+D_other1+
  D_other2+D_other3+D_other4+D_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
  F_other1+F_other2+F_other3+F_other4+F_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
  H_other1+H_other2+H_other3+H_other4+H_other5
  
  D_self ~~ 0*D_other
  H_self ~~ 0*H_other
  F_self ~~ 0*F_other
  
Level: 2
', 
corr_error)

hierarchical.norms.test1.fit <- cfa(model = hierarchical.model.test1,
                    data = DF_norms,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(hierarchical.norms.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

hierarchical.norms.test1.fitindices <- tidy(fitmeasures(hierarchical.norms.test1.fit))
hierarchical.norms.test1.params <- tidy(hierarchical.norms.test1.fit)
```

### Hierarchical Norms Test 2

```{r norms-hierarchical-test2, eval = F}
hierarchical.model.test2 <- 
paste0(' 
Level: 1', 
corr_error, 
'
Level: 2 
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5
  
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+D_other1+
  D_other2+D_other3+D_other4+D_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
  F_other1+F_other2+F_other3+F_other4+F_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
  H_other1+H_other2+H_other3+H_other4+H_other5
  
  D_self ~~ 0*D_other
  H_self ~~ 0*H_other
  F_self ~~ 0*F_other
')

hierarchical.norms.test2.fit <- cfa(model = hierarchical.model.test2,
                    data = DF_norms,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(hierarchical.norms.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

hierarchical.norms.test2.fitindices <- tidy(fitmeasures(hierarchical.norms.test2.fit))
hierarchical.norms.test2.params <- tidy(hierarchical.norms.test2.fit)
```

# H1B

*Hypothesis*:

H1b: The hierarchical model will fit the data better than the three-factor model. We will alternatively test a six-factor model in case the hierarchical model does not converge.

*Analysis Plan*:

Individual endorsement and cultural norms will be tested separately. For each model, country will be used as a cluster variable.

Factor structure (see Fig. 1B): Multilevel CFA with three-factor correlated model of the DHF latent variables.

Test 1: Level 1 will include the proposed factor structure, and Level 2 will include only the saturated model where all observed variables are intercorrelated.

Test 2: Level 1 will include only the saturated model of observed variable correlations, and Level 2 will include the proposed factor structure.

*Model Evaluation*:

The model will be considered significantly better than an alternative if: - AIC is lower - BIC is lower - ΔCFI \> .010 (the model with higher CFA is better) - ΔRMSEA \> .015 (the model with lower RMSEA is better) - Chen (2007)

All these criteria will be considered together, and if the majority of them are fulfilled, the model will be considered significantly better than the alternative. If models are not significantly different from each other, the theoretically hypothesized hierarchical model will be preferred.

## Power

```{r power-comparison}
k2 <- 558 # number of parameters in 3 factor
k3 <- 570 # number of parameters in 6 factor

df2 <- p*(p-1) - k2
df3 <- p*(p-1) - k3
semPower.aPriori(
  effect = c(.08-.015, .08),
  effect.measure = "RMSEA",
  alpha = .05, 
  power = .90, 
  df = c(df2, df)) # compare this model to the original if converge

semPower.aPriori(
  effect = c(.08-.015, .08),
  effect.measure = "RMSEA",
  alpha = .05, 
  power = .90, 
  df = c(df3, df2)) # only compare this model to three-factor
```

## H1B Individual

### 3-factor Individual Test 1

```{r individual-threefactor-test1, eval = F}
threefactor.model.test1 <- 
paste0(' 
Level: 1
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+
    D_other1+D_other2+D_other3+D_other4+D_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
    H_other1+H_other2+H_other3+H_other4+H_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
   F_other1+F_other2+F_other3+F_other4+F_other5

Level: 2
', 
corr_error)

threefactor.individual.test1.fit <- cfa(model = threefactor.model.test1,
                    data = DF_individual,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.individual.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

threefactor.individual.test1.fitindices <- tidy(fitmeasures(threefactor.individual.test1.fit))
threefactor.individual.test1.params <- tidy(threefactor.individual.test1.fit)
```

### 3-Factor Individual Test 2

```{r individual-threefactor-test2, eval = F}
threefactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_error, 
'
Level: 2 
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+
    D_other1+D_other2+D_other3+D_other4+D_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
    H_other1+H_other2+H_other3+H_other4+H_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
   F_other1+F_other2+F_other3+F_other4+F_other5

')

threefactor.individual.test2.fit <- cfa(model = threefactor.model.test2,
                    data = DF_individual,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.individual.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

threefactor.individual.test2.fitindices <- tidy(fitmeasures(threefactor.individual.test2.fit))
threefactor.individual.test2.params <- tidy(threefactor.individual.test2.fit)
```

## H1B Individual (Alternative)

### 6-factor Individual Test 1

```{r individual-sixfactor-test1, eval = F}
sixfactor.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5

Level: 2
', 
corr_error)

sixfactor.individual.test1.fit <- cfa(model = sixfactor.model.test1,
                    data = DF_individual,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.individual.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

sixfactor.individual.test1.fitindices <- tidy(fitmeasures(sixfactor.individual.test1.fit))
sixfactor.individual.test1.params <- tidy(sixfactor.individual.test1.fit)
```

### 6-Factor Individual Test 2

```{r individual-sixfactor-test2, eval = F}
sixfactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_error, 
'
Level: 2 
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5

')

sixfactor.individual.test2.fit <- cfa(model = sixfactor.model.test2,
                    data = DF_individual,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.individual.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

sixfactor.individual.test2.fitindices <- tidy(fitmeasures(sixfactor.individual.test2.fit))
sixfactor.individual.test2.params <- tidy(sixfactor.individual.test2.fit)
```

### Comparison Individual

```{r model-comparison-individual, eval = F}
hierarchical.individual.test1.fitindices
hierarchical.individual.test2.fitindices
threefactor.individual.test1.fitindices
threefactor.individual.test2.fitindices

# if necessary
sixfactor.individual.test1.fitindices
sixfactor.individual.test2.fitindices

# pick a model based on the rules above 
```

## H1B Norms

### 3-factor Norms Test 1

```{r norms-threefactor-test1, eval = F}
threefactor.model.test1 <- 
paste0(' 
Level: 1
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+
    D_other1+D_other2+D_other3+D_other4+D_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
    H_other1+H_other2+H_other3+H_other4+H_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
   F_other1+F_other2+F_other3+F_other4+F_other5

Level: 2
', 
corr_error)

threefactor.norms.test1.fit <- cfa(model = threefactor.model.test1,
                    data = DF_norms,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.norms.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

threefactor.norms.test1.fitindices <- tidy(fitmeasures(threefactor.norms.test1.fit))
threefactor.norms.test1.params <- tidy(threefactor.norms.test1.fit)
```

### 3-Factor Norms Test 2

```{r norms-threefactor-test2, eval = F}
threefactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_error, 
'
Level: 2 
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+
    D_other1+D_other2+D_other3+D_other4+D_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
    H_other1+H_other2+H_other3+H_other4+H_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
   F_other1+F_other2+F_other3+F_other4+F_other5

')

threefactor.norms.test2.fit <- cfa(model = threefactor.model.test2,
                    data = DF_norms,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.norms.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

threefactor.norms.test2.fitindices <- tidy(fitmeasures(threefactor.norms.test2.fit))
threefactor.norms.test2.params <- tidy(threefactor.norms.test2.fit)
```

## H1B Norms (Alternative)

### 6-factor Norms Test 1

```{r norms-sixfactor-test1, eval = F}
sixfactor.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5

Level: 2
', 
corr_error)

sixfactor.norms.test1.fit <- cfa(model = sixfactor.model.test1,
                    data = DF_norms,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.norms.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

sixfactor.norms.test1.fitindices <- tidy(fitmeasures(sixfactor.norms.test1.fit))
sixfactor.norms.test1.params <- tidy(sixfactor.norms.test1.fit)
```

### 6-Factor Norms Test 2

```{r norms-sixfactor-test2, eval = F}
sixfactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_error, 
'
Level: 2 
  D_self =~ D_self1+D_self2+D_self3+D_self4+D_self5
  D_other =~ D_other1+D_other2+D_other3+D_other4+D_other5
  H_self =~ H_self1+H_self2+H_self3+H_self4+H_self5
  H_other =~ H_other1+H_other2+H_other3+H_other4+H_other5
  F_self =~ F_self1+F_self2+F_self3+F_self4+F_self5
  F_other =~ F_other1+F_other2+F_other3+F_other4+F_other5

')

sixfactor.norms.test2.fit <- cfa(model = sixfactor.model.test2,
                    data = DF_norms,
                    cluster = "country"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.norms.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

sixfactor.norms.test2.fitindices <- tidy(fitmeasures(sixfactor.norms.test2.fit))
sixfactor.norms.test2.params <- tidy(sixfactor.norms.test2.fit)
```

### Comparison Norms

```{r model-comparison-norms, eval = F}
hierarchical.norms.test1.fitindices
hierarchical.norms.test2.fitindices
threefactor.norms.test1.fitindices
threefactor.norms.test2.fitindices

# if necessary
sixfactor.norms.test1.fitindices
sixfactor.norms.test2.fitindices

# pick a model based on the rules above 
```

# Model Improvement

*Hypothesis*:

See hypotheses above.

*Analysis Plan*:

The final model will be examined for: - Poorly loading items. - Modification indices. - Model fit. - Group alignment.

*Model Evaluation*:

Item evaluation:

-   If a given item does not significantly load on the respective factor AND the model fit improves after removing the item, or the item loads in the opposite to expected direction, the items will be removed. Otherwise, the item will be retained.
-   If modification indices suggest a strong residual correlation between items AND this correlation is theoretically justified, a residual correlation will be added.

Model evaluation:

-   We will consider the model to have a good fit to the data if RMSEA \< .08 and SRMR_within \< .08. If ICC \< .10, we will additionally use CFI \> .90, and SRMR_between \< .08 as criteria.
-   If .08 \< RMSEA \< .10, .08 \< SRMR \< .10, and .85 \< CFI \< .90, we will consider the model acceptable, unless there are specific issues with items as described above.
-   If RMSEA \> .10, SRMR \> .10, CFI \< .85, we will consider the model unacceptable.

All model fit indices will be considered together, and if the majority of indices suggest acceptable fit, a single indicator will not be considered sufficient to reject the model.

## Model Improvement: Individual

```{r individual-model-improve, eval = F}
# we will examine the parameters to ensure they are significant
# if one is poor remove and retest model fit 
  # remove if poor AND model fit goes up
# remove items with negative loadings 
# only do this for the final chosen model 

# for example 
hierarchical.individual.test1.fit

# examine modification indices
modificationindices(hierarchical.individual.test1.fit)

# examine new model fits
  # rerun models as above
  # check the fit outputs 
hierarchical.individual.test1.fitindices
```

## Model Improvement: Norms

```{r norms-model-improve, eval = F}
# we will examine the parameters to ensure they are significant
# if one is poor remove and retest model fit 
  # remove if poor AND model fit goes up
# remove items with negative loadings 
# only do this for the final chosen model 

# for example 
hierarchical.norms.test1.fit

# examine modification indices
modificationindices(hierarchical.norms.test1.fit)

# examine new model fits
  # rerun models as above
  # check the fit outputs 
hierarchical.norms.test1.fitindices
```

# Alignment Procedure

## Individual

```{r alignment-individual}
# testing just the three factor structure with level 1 only to show how this procedure works 
hierarchical.align.model <- '
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+D_other1+
  D_other2+D_other3+D_other4+D_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
  F_other1+F_other2+F_other3+F_other4+F_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
  H_other1+H_other2+H_other3+H_other4+H_other5
'

# temp <- cfa(model = hierarchical.align.model,
#             data = DF_individual,
#             orthogonal = TRUE)
# summary(temp, standardized = TRUE)

# calculate MGCFA
hierarchical.mgcfa.fit <- mgcfa(
  model = hierarchical.align.model,
  data = DF_individual, 
  group = "country",
  group.equal = c("loadings", "intercepts"),
  check.gradient = FALSE,
  orthogonal = TRUE
)

summary(hierarchical.mgcfa.fit$model_overall)
summary(hierarchical.mgcfa.fit$model_configural)
hierarchical.mgcfa.fit$model_fit

# extract item parameters separate group analyses
ipars <- lavaan::parameterEstimates(hierarchical.mgcfa.fit$model_configural)
# extract lambda's: groups are in rows, items in columns
# nrow is the number of groups
lambda <- matrix(ipars[ ipars$op=="=~", "est"], 
                  nrow = 2, byrow = TRUE)
colnames(lambda) <- ipars[ ipars$op=="=~", "rhs"][1:(length(ipars[ ipars$op=="=~", "rhs"])/2)]
# extract nu's
nu <- matrix( ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ], 
              nrow = 2,  byrow = TRUE)
colnames(nu) <- ipars[ ipars$op=="~1"  & ipars$se !=0, "lhs" ][1:(length(ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ])/2)]

Ng <-  unlist(hierarchical.mgcfa.fit$model_configural@SampleStats@nobs)
wgt <- matrix( sqrt(Ng), length(Ng), ncol(nu) )

mod1 <- sirt::invariance.alignment(lambda, nu, wgt, align.pow=c(2,2))
summary(mod1)
```

## Norms

```{r alignment-norms}
# testing just the three factor structure with level 1 only to show how this procedure works 
hierarchical.align.model <- '
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+D_other1+
  D_other2+D_other3+D_other4+D_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
  F_other1+F_other2+F_other3+F_other4+F_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
  H_other1+H_other2+H_other3+H_other4+H_other5
'

# temp <- cfa(model = hierarchical.align.model,
#             data = DF_norms,
#             orthogonal = TRUE)
# summary(temp, standardized = TRUE)

# calculate MGCFA
hierarchical.mgcfa.fit <- mgcfa(
  model = hierarchical.align.model,
  data = DF_norms, 
  group = "country",
  group.equal = c("loadings", "intercepts"),
  check.gradient = FALSE,
  orthogonal = TRUE
)

summary(hierarchical.mgcfa.fit$model_overall)
summary(hierarchical.mgcfa.fit$model_configural)
hierarchical.mgcfa.fit$model_fit

# extract item parameters separate group analyses
ipars <- lavaan::parameterEstimates(hierarchical.mgcfa.fit$model_configural)
# extract lambda's: groups are in rows, items in columns
# nrow is the number of groups
lambda <- matrix(ipars[ ipars$op=="=~", "est"], 
                  nrow = 2, byrow = TRUE)
colnames(lambda) <- ipars[ ipars$op=="=~", "rhs"][1:(length(ipars[ ipars$op=="=~", "rhs"])/2)]
# extract nu's
nu <- matrix( ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ], 
              nrow = 2,  byrow = TRUE)
colnames(nu) <- ipars[ ipars$op=="~1"  & ipars$se !=0, "lhs" ][1:(length(ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ])/2)]

Ng <-  unlist(hierarchical.mgcfa.fit$model_configural@SampleStats@nobs)
wgt <- matrix( sqrt(Ng), length(Ng), ncol(nu) )


mod1 <- sirt::invariance.alignment(lambda, nu, wgt, align.pow=c(2,2))
summary(mod1)
```

# H2

*Hypothesis*:

H2: The individual endorsement of the other-concern facet of all three cultural logics will predict more prosocial behavior.

*Analysis Plan*:

A multilevel model predicting prosociality from six or three cultural logic indices (depending on the best fitting model in H1b) with random intercept for country.

All individual-level predictors will be group-mean centered (level 1), and all sample-level predictors will be grand-mean centered (level 2).

*Evaluation*:

A significant positive effect (p \< .05) of the other-concern facet of each cultural logic will support the hypotheses. Significant effects for some but no effect for other other-facets will be interpreted as partial support for the hypothesis. Null effects for any or negative effects for some will be interpreted as evidence against the hypothesis.

If the 3-factor model is used (dignity, honor, face), the test will be exploratory.

## Data Simulation

DHF indices will be calculated based on the best performing model for each level. Individual-level DHF endorsement scores will be calculated as averages of individual endorsement items, and country-level DHF norms scores will be calculated as averages of norms items, aggregated at country level (see below for H3).

```{r h2-data-simulation}
DF_individual_H2 <- DF %>% 
  filter(`US state` == "Texas" | `US state` == "New York") %>% 
  dplyr::rename(country = `US state`) %>% 
  select(DHF_endorsement_1:DHF_endorsement_30,
         DHF_Norms_1:DHF_Norms_30, 
         prosocial,
         country, 
         ResponseId) %>% 
  group_by(ResponseId) %>% 
  mutate(
    D_self_individual = mean(DHF_endorsement_1:DHF_endorsement_5),
    D_other_individual = mean(DHF_endorsement_6:DHF_endorsement_10),
    H_self_individual = mean(DHF_endorsement_11:DHF_endorsement_15),
    H_other_individual = mean(DHF_endorsement_16:DHF_endorsement_20),
    F_self_individual = mean(DHF_endorsement_21:DHF_endorsement_25),
    F_other_individual = mean(DHF_endorsement_26:DHF_endorsement_30),
    D_individual = mean(DHF_endorsement_1:DHF_endorsement_10),
    H_individual = mean(DHF_endorsement_11:DHF_endorsement_20),
    F_individual = mean(DHF_endorsement_21:DHF_endorsement_30)
  ) %>% 
  ungroup() 

DF_H2 <- sim_df(data = DF_individual_H2 %>% 
                  select(prosocial, country, D_self_individual:F_individual), 
                n = 300,
                between = "country")
```

## Proposed Model

All individual-level predictors will be group-mean centered (level 1), and all sample-level predictors will be grand-mean centered (level 2).

```{r h2-model}
# group mean centering for level 1 variable 
# by country
DF_H2 <- DF_H2 %>% 
  # group_by(country) %>% 
  mutate(D_self_individual_Z = scale(D_self_individual, 
                                     center = TRUE),
         D_other_individual_Z = scale(D_other_individual), 
                                     center = TRUE,
         H_self_individual_Z = scale(H_self_individual, 
                                     center = TRUE),
         H_other_individual_Z = scale(H_other_individual, 
                                     center = TRUE),
         F_self_individual_Z = scale(F_self_individual, 
                                     center = TRUE),
         F_other_individual_Z = scale(F_other_individual, 
                                     center = TRUE)
         )

# six factors - current pilot data 
h2.fit <- lmer(prosocial ~ D_self_individual_Z + D_other_individual_Z + 
                    H_self_individual_Z + H_other_individual_Z + 
                    F_self_individual_Z + F_other_individual_Z +
                 (1|country), 
                  data = DF_H2)

parameters(h2.fit)
```

## Power

```{r h2-power-sim, eval = F}
# power simulation
n_people <- seq(20, 100, by = 10)

power.save <- list()
start.number <- 1

for (i in 1:1000){ # how many times to run the power 
  for (p in n_people){ # how many participants 
    
    # random effect of country
    country_ran_eff <- data.frame(
      country = 1:50,
      ran_eff = rnorm(n = 50, mean = .31, sd = .05)
    )
    
    # simulate a dataset with 50 countries by the number of people 
    DF <- DF_individual %>% 
      # get variables
      select(prosocial, D_self_individual:F_individual) %>% 
      # make enough data to make correlation work
      sim_df(., n = 50*p) %>% 
      # create fake countries
      mutate(country = rep(1:50, length.out = nrow(.))) %>% 
      # merge with fake random intercept effects 
      left_join(country_ran_eff, by = "country") %>% 
      group_by(country) %>% 
      # create fixed effects prosocial
      mutate(
        # intercept * random intercept effect 
        prosocial = 4.20*ran_eff + 
          # fixed effects 
          rnorm(1, mean = .07, sd = .10)*D_self_individual + 
          rnorm(1, mean = .20, sd = .10)*D_other_individual + 
          rnorm(1, mean = .20, sd = .10)*H_self_individual + 
          rnorm(1, mean = .20, sd = .10)*H_other_individual + 
          rnorm(1, mean = -.29, sd = .10)*F_self_individual + 
          rnorm(1, mean = .20, sd = .10)*F_other_individual + 
          # small error sigma for each person
          rnorm(1, mean = 2, sd = 1)
        ) 
      
    power.model <- lmer(
      prosocial ~ D_self_individual + D_other_individual + 
        H_self_individual + H_other_individual + 
        F_self_individual + F_other_individual +
        (1|country), data = DF)
    
    coef.model <- as.data.frame(summary(power.model)[["coefficients"]])
    # underestimating variance here 
    coef.model$`Std. Error` <- coef.model$`Std. Error`*10  
    # recalc t and p
    coef.model$`t value` <- coef.model$Estimate / coef.model$`Std. Error`
    coef.model$`Pr(>|t|)` <- pt(coef.model$`t value`, df = coef.model$df, lower.tail = FALSE)*2

    power.save[[start.number]] <- c(p, i, coef.model$`Pr(>|t|)`[3], 
                                  coef.model$`Pr(>|t|)`[5], 
                                  coef.model$`Pr(>|t|)`[7])
    power.save[[start.number]] <- as.data.frame(t(power.save[[start.number]]))
    colnames(power.save[[start.number]]) <- c("sample_size", "run", 
                                              "d_other", "h_other", "f_other")
    start.number <- start.number + 1
    
  }
  
}

power.save.df <- bind_rows(power.save) %>% 
  mutate(all_three = d_other <= .05 & h_other <= .05 & f_other <=.05) %>% 
  group_by(sample_size) %>% 
  summarize(power = sum(all_three) / n())

export(power.save.df, "power/h2_power_summary.csv", row.names = F)
```

```{r h2-show-power}
power.save.df <- import("power/h2_power_summary.csv")

power.save.df
```

# H3

*Hypothesis*:

H3a: Higher country-level honor logic scores will predict higher positive reciprocity.

H3b: Higher country-level face logic scores will predict higher positive reciprocity.

H3c: Higher country-level honor logic scores will predict higher negative reciprocity.

*Analysis Plan*:

A multilevel, random-intercept path model predicting universal prosociality and positive and negative reciprocity from individual-level and sample-level DHF norm scores. The models below and in further hypotheses use 3 factors at the individual and 3 factors at the sample level; this is conditional upon the higher-order DHF factors showing appropriate fit in for both endorsement and sample measures.

Country will be used as the cluster variable for random intercepts.

Level 1: prosocial, positive reciprocity, and negative reciprocity will be predicted by DHF scores for individual endorsement.

Level 2: prosocial, positive reciprocity, and negative reciprocity will be predicted by DHF scores for sample aggregated norms.

*Evaluation*:

A significant positive effect (p\<.05) of sample-level honor logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level face logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level honor logic on negative reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

## Data Simulation

```{r h3-data-simulation}
DF_final_H345 <- DF %>% 
  filter(`US state` == "Texas" | `US state` == "New York") %>% 
  dplyr::rename(country = `US state`) %>% 
  mutate(country = as.factor(country)) %>% 
  mutate(country = droplevels(country)) %>% 
  select(DHF_endorsement_1:DHF_endorsement_30,
         DHF_Norms_1:DHF_Norms_30, 
         prosocial,
         PosRec,
         NegRec,
         country, 
         ResponseId) %>% 
  group_by(ResponseId) %>% 
  mutate(
    D_individual = mean(DHF_endorsement_1:DHF_endorsement_10),
    H_individual = mean(DHF_endorsement_11:DHF_endorsement_20),
    F_individual = mean(DHF_endorsement_21:DHF_endorsement_30),
    D_sample = mean(DHF_Norms_1:DHF_Norms_10),
    H_sample = mean(DHF_Norms_11:DHF_Norms_20),
    F_sample = mean(DHF_Norms_21:DHF_Norms_30)) %>% 
  ungroup() 

DF_final_H <- sim_df(data = DF_final_H345 %>% 
                  select(prosocial, country, PosRec, NegRec, 
                         D_individual:F_sample) %>% 
                    mutate(country = rep(1:5, length.out = nrow(DF_final_H345))), 
                n = 300,
                between = c("country"))

# for this model, the D_sample, etc. have to be aggregates
DF_final_H3 <- DF_final_H %>% 
  left_join(
    DF_final_H %>% 
      group_by(country) %>% 
      summarize(D_sample_agg = mean(D_sample),
                H_sample_agg = mean(H_sample),
                F_sample_agg = mean(F_sample)),
    by = "country"
  )

# group mean centering for level 1 variable 
# grand mean centering for level 2 variable
# by country
DF_final_H3 <- DF_final_H3 %>% 
  # group_by(country) %>% 
  mutate(D_individual_Z = scale(D_individual, 
                                     center = TRUE),
         H_individual_Z = scale(H_individual, 
                                     center = TRUE),
         F_individual_Z = scale(F_individual, 
                                     center = TRUE),
         D_sample_agg_Z = scale(D_sample_agg, 
                                center = TRUE), 
         H_sample_agg_Z = scale(H_sample_agg, 
                                center = TRUE), 
         F_sample_agg_Z = scale(F_sample_agg, 
                                center = TRUE),
         D_sample_Z = scale(D_sample, 
                           center = TRUE), 
         H_sample_Z = scale(H_sample,
                            center = TRUE), 
         F_sample_Z = scale(F_sample,
                            center = TRUE)
         )
```

## Power

Parameters are based on *z*-score estimation, which do not involve degrees of freedom for significance purposes. If we assume our standard errors are approximate from the sample data (\~ .10 across parameters as high estimate with smaller sample size models), we would be able to detect regression loadings of approximately .20 (i.e., 1.96 \* SE).

```{r}
prosocial.model <-'
  prosocial ~ D_individual_Z + H_individual_Z + F_individual_Z
  PosRec ~ D_individual_Z + H_individual_Z + F_individual_Z
  NegRec ~ D_individual_Z + H_individual_Z + F_individual_Z
'
  
prosocial.fit <- sem(
  model = prosocial.model,
  data = DF_final_H3
)

tidy(prosocial.fit)
```

## Proposed Model

```{r h3-model, eval = F}
prosocial.model <-'
Level: 1
  prosocial ~ D_individual_Z + H_individual_Z + F_individual_Z
  PosRec ~ D_individual_Z + H_individual_Z + F_individual_Z
  NegRec ~ D_individual_Z + H_individual_Z + F_individual_Z
Level: 2
  prosocial ~ D_sample_agg_Z + H_sample_agg_Z + F_sample_agg_Z
  PosRec ~ D_sample_agg_Z + H_sample_agg_Z + F_sample_agg_Z
  NegRec ~ D_sample_agg_Z + H_sample_agg_Z + F_sample_agg_Z
'
  
prosocial.fit <- sem(
  model = prosocial.model,
  data = DF_final_H3,
  cluster = "country"
)

summary(prosocial.fit, 
        standardized = TRUE,
        fit.measures = TRUE,
        rsquare = TRUE)

tidy(fitmeasures(prosocial.fit))
tidy(prosocial.fit)
```

# H4

*Hypothesis*:

H4a: Individual endorsement of honor culture will positively predict attitude toward violence.

H4b: Individual endorsement of face culture will positively predict other-face concern in interpersonal conflict.

H4c: Individual endorsement of dignity culture will negatively predict other-face concern in interpersonal conflict.

*Analysis Plan*:

H4a: A multilevel, random-intercept model (country) predicting attitude to violence from individual-level endorsement and country-level norm scores for honor, face, and dignity.

H4b-c: A multilevel, random-intercept model (country) predicting other-face concern from individual-level endorsement and country-level norm scores for honor, face, and dignity.

*Evaluation*:

H4a: A significant (p\<.05) positive effect of individual-level honor will be interpreted as support for the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

H4b: A significant (p\<.05) positive effect of individual-level face will be interpreted as support for the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

H4c: A significant (p\<.05) negative effect of individual-level dignity will be interpreted as support for the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

## Data Simulation

```{r h4-data-simulation}
# making up numbers here for each group differently 
DF_final_H4 <- DF_final_H3 %>% 
  mutate(attviol = c(rnorm(300, mean = 4, sd = 1), 
                     rnorm(300, mean = 5.2, sd = 1),
                     rnorm(300, mean = 4.76, sd = 1), 
                     rnorm(300, mean = 5.16, sd = 1),
                     rnorm(300, mean = 4.8, sd = 1)),
         oface = c(rnorm(300, mean = 3.1, sd = 1), 
                     rnorm(300, mean = 2.4, sd = 1),
                     rnorm(300, mean = 3.56, sd = 1), 
                     rnorm(300, mean = 2.10, sd = 1),
                     rnorm(300, mean = 2.78, sd = 1))) 
```

## Proposed Model

```{r h4-model}
h3.model.a <- lmer(attviol ~ D_individual_Z + H_individual_Z + F_individual_Z + 
                     D_sample_Z + H_sample_Z + F_sample_Z + (1|country),
                   data = DF_final_H4,
                   na.action = "na.omit"
                   )

summary(h3.model.a)

h3.model.b <- lmer(oface ~ D_individual_Z + H_individual_Z + F_individual_Z + 
                     D_sample_Z + H_sample_Z + F_sample_Z + (1|country),
                   data = DF_final_H4, 
                   na.action = "na.omit")

summary(h3.model.b)
```

## Power

```{r h4-calc-power, eval = F}
# power simulation
n_people <- seq(20, 100, by = 10)

power.save.h4a <- list()
power.save.h4b <- list()
start.number <- 1

for (i in 1:1000){ # how many times to run the power 
  for (p in n_people){ # how many participants 
    
    # random effect of country
    country_ran_eff <- data.frame(
      country = 1:50,
      ran_eff = rnorm(n = 50, mean = .31, sd = .05)
    )
    
    # simulate a dataset with 50 countries by the number of people 
    DF <- DF_final_H4 %>% 
      # get variables
      select(attviol, D_individual, H_individual, 
             F_individual, D_sample, H_sample, F_sample, 
             country) %>% 
      # make enough data to make correlation work
      sim_df(., n = 50*p) %>% 
      # create fake countries
      mutate(country = rep(1:50, length.out = nrow(.))) %>% 
      # merge with fake random intercept effects 
      left_join(country_ran_eff, by = "country") %>% 
      group_by(country) %>% 
      # create fixed effects prosocial
      mutate(
        # intercept * random intercept effect 
        attviol = 4*ran_eff + 
          # fixed effects 
          rnorm(1, mean = -.07, sd = .10)*D_individual + 
          rnorm(1, mean = .20, sd = .10)*H_individual + 
          rnorm(1, mean = -.08, sd = .10)*F_individual + 
          rnorm(1, mean = .10, sd = .10)*D_sample + 
          rnorm(1, mean = .05, sd = .10)*H_sample + 
          rnorm(1, mean = -.10, sd = .10)*F_sample + 
          # small error sigma for each person
          rnorm(1, mean = 2, sd = 1), 
        oface = 4*ran_eff + 
          # fixed effects 
          rnorm(1, mean = -.20, sd = .10)*D_individual + 
          rnorm(1, mean = -.08, sd = .10)*H_individual + 
          rnorm(1, mean = .20, sd = .10)*F_individual + 
          rnorm(1, mean = -.07, sd = .10)*D_sample + 
          rnorm(1, mean = -.10, sd = .10)*H_sample + 
          rnorm(1, mean = .03, sd = .10)*F_sample + 
          # small error sigma for each person
          rnorm(1, mean = 2, sd = 1)
        ) 
      
    power.model.h4a <- lmer(
      attviol ~ D_individual + H_individual + F_individual +
        D_sample + H_sample + F_sample + (1|country),
      data = DF)
    
    coef.model <- as.data.frame(summary(power.model.h4a)[["coefficients"]])
    # underestimating variance here 
    coef.model$`Std. Error` <- coef.model$`Std. Error`*10  
    # recalc t and p
    coef.model$`t value` <- coef.model$Estimate / coef.model$`Std. Error`
    coef.model$`Pr(>|t|)` <- pt(coef.model$`t value`, df = coef.model$df, lower.tail = FALSE)*2

    power.save.h4a[[start.number]] <- c(p, i, coef.model$`Pr(>|t|)`[3])
    power.save.h4a[[start.number]] <- as.data.frame(t(power.save.h4a[[start.number]]))
    colnames(power.save.h4a[[start.number]]) <- c("sample_size", "run", 
                                              "h_individual")
    
    power.model.h4b <- lmer(
      oface ~ D_individual + H_individual + F_individual +
        D_sample + H_sample + F_sample + (1|country),
      na.action = "na.omit", 
      data = DF)
    
    coef.model <- as.data.frame(summary(power.model.h4b)[["coefficients"]])
    # underestimating variance here 
    coef.model$`Std. Error` <- coef.model$`Std. Error`*10  
    # recalc t and p
    coef.model$`t value` <- coef.model$Estimate / coef.model$`Std. Error`
    coef.model$`Pr(>|t|)` <- pt(abs(coef.model$`t value`), df = coef.model$df, lower.tail = FALSE)*2

    power.save.h4b[[start.number]] <- c(p, i, 
                                        coef.model$`Pr(>|t|)`[4], 
                                        coef.model$`Pr(>|t|)`[2])
    power.save.h4b[[start.number]] <- as.data.frame(t(power.save.h4b[[start.number]]))
    colnames(power.save.h4b[[start.number]]) <- c("sample_size", "run", 
                                              "f_individual", "d_individual")
    start.number <- start.number + 1
    
  }
  
}

power.save.df.h4a <- bind_rows(power.save.h4a) %>% 
  mutate(sig = h_individual <= .05) %>% 
  group_by(sample_size) %>% 
  summarize(power = sum(sig) / n())

export(power.save.df.h4a, "power/h4a_power_summary.csv", row.names = F)

power.save.df.h4b <- bind_rows(power.save.h4b) %>% 
  mutate(
    f_individual = ifelse(f_individual > 1, 1, f_individual),
    d_individual = ifelse(d_individual > 1, 1, d_individual),
    sig_hb = f_individual <= .05,
    sig_hc = d_individual <= .05) %>% 
  group_by(sample_size) %>% 
  summarize(power_hb = sum(sig_hb) / n(),
            power_hc = sum(sig_hc) / n())

export(power.save.df.h4b, "power/h4b_power_summary.csv", row.names = F)
```

```{r h4-show-power}
power.save.df.h4a <- import("power/h4a_power_summary.csv")

power.save.df.h4a

power.save.df.h4b <- import("power/h4b_power_summary.csv")

power.save.df.h4b
```

# H5

*Hypothesis*:

H5a: Individual endorsement of honor culture will positively predict retaliation in response to provocation.

H5b: Individual endorsement of face culture will positively predict withdrawal in response to provocation.

H5c: Individual endorsement of dignity culture will positively predict humor in response to provocation.

*Analysis Plan*:

A multilevel, random-intercept path model predicting retaliation, withdrawal, and humor as reactions to provocation from individual-level endorsement and sample-level aggregate scores for honor, face, and dignity.

Country will be used as the cluster variable for random intercepts.

Level 1: Retaliation, withdrawal, and humor will be predicted by DHF scores for individual endorsement.

Level 2: Retaliation, withdrawal, and humor will be predicted by DHF scores for sample aggregated norms.

*Evaluation*:

A significant positive effect (p\<.05) of sample-level honor logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level face logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level honor logic on negative reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

## Data Simulation

```{r h5-data-simulation}
DF_final_H5 <- DF_final_H3 %>% 
  mutate(retaliation = c(rnorm(300, mean = 4, sd = 1), 
                     rnorm(300, mean = 5.2, sd = 1),
                     rnorm(300, mean = 4.76, sd = 1), 
                     rnorm(300, mean = 5.16, sd = 1),
                     rnorm(300, mean = 4.8, sd = 1)),
         withdrawal = c(rnorm(300, mean = 3.1, sd = 1), 
                     rnorm(300, mean = 2.4, sd = 1),
                     rnorm(300, mean = 3.56, sd = 1), 
                     rnorm(300, mean = 2.10, sd = 1),
                     rnorm(300, mean = 2.78, sd = 1)),
         humor = c(rnorm(300, mean = 4.7, sd = 1), 
                     rnorm(300, mean = 6.2, sd = 1),
                     rnorm(300, mean = 3.4, sd = 1), 
                     rnorm(300, mean = 5.0, sd = 1),
                     rnorm(300, mean = 5.23, sd = 1))) 
```

## Power

Parameters are based on *z*-score estimation, which do not involve degrees of freedom for significance purposes. If we assume our standard errors are approximate from the sample data (\~ .10 across parameters as high estimate with smaller sample size models), we would be able to detect regression loadings of approximately .20 (i.e., 1.96 \* SE).

```{r}
provocation.model <-'
  retaliation ~ D_individual_Z + H_individual_Z + F_individual_Z
  withdrawal ~ D_individual_Z + H_individual_Z + F_individual_Z
  humor ~ D_individual_Z + H_individual_Z + F_individual_Z
'
  
provocation.fit <- sem(
  model = provocation.model,
  data = DF_final_H5
)

tidy(provocation.fit)
```

## Proposed Model

```{r h5-model, eval = F}
provocation.model <-'
Level: 1
  retaliation ~ D_individual_Z + H_individual_Z + F_individual_Z
  withdrawal ~ D_individual_Z + H_individual_Z + F_individual_Z
  humor ~ D_individual_Z + H_individual_Z + F_individual_Z
Level: 2
  retaliation  ~ D_sample_agg_Z + H _sample_agg_Z + F_sample_agg_Z
  withdrawal ~ D_sample_agg_Z + H_sample_agg_Z + F_sample_agg_Z 
  humor ~ D_sample_agg_Z + H _sample_agg_Z + F_sample_agg_Z 
'
  
provocation.fit <- sem(
  model = provocation.model,
  data = DF_final_H5,
  cluster = "country"
)

summary(provocation.fit, 
        standardized = TRUE,
        fit.measures = TRUE,
        rsquare = TRUE)

tidy(fitmeasures(provocation.fit))
tidy(provocation.fit)
```
