---
title: "Final Pre-Data Collection Code: JTF002: DHF"
author: "Erin M. Buchanan & Lusine Grigoryan"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: true
  chunk_output_type: console
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries

```{r libraries}
library(devtools) 
library(rio)
library(dplyr)
library(lavaan)
library(XML)
library(semPlot) 
library(faux)
library(broom)
library(semPower)
library(lme4)
library(lmerTest)
library(psych)
library(sirt)
library(tidyr)
library(stringr)
library(parameters)
library(performance)
library(lavaan)
library(misty)
# devtools::install_github("doomlab/visualizemi")
library(visualizemi)
library(ggplot2)
library(beepr)
library(UpSetR) 
library(countrycode)

set.seed(48299439)
```

# SEM Variable Definition

This section defines the correlated error for Level 1/2 analyses for Hypothesis 1 (and then used throughout). We define these values at the top here to keep from repeating them below for clarity on the parts of the model that change.

```{r overall-variables}
corr_endors <- '
  dhf_endors_1 ~~ dhf_endors_2 +dhf_endors_3+dhf_endors_4+dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_2 ~~ dhf_endors_3+dhf_endors_4+dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
 
  dhf_endors_3 ~~ dhf_endors_4+dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_4 ~~ dhf_endors_5 + dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_5 ~~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_6 ~~ dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_7 ~~ dhf_endors_8+dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_8 ~~ dhf_endors_9+dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_9 ~~ dhf_endors_10 + dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_10 ~~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_11 ~~ dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
    
  dhf_endors_12 ~~ dhf_endors_13+dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
      
  dhf_endors_13 ~~ dhf_endors_14+dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
        
  dhf_endors_14 ~~ dhf_endors_15 + dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
          
  dhf_endors_15 ~~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
            
  dhf_endors_16 ~~ dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
              
  dhf_endors_17 ~~ dhf_endors_18+dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
                
  dhf_endors_18 ~~ dhf_endors_19+dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
                  
  dhf_endors_19 ~~ dhf_endors_20 + dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
                    
  dhf_endors_20 ~~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  dhf_endors_21 ~~ dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_22 ~~ dhf_endors_23+dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_23 ~~ dhf_endors_24+dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_24 ~~ dhf_endors_25 + dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_25 ~~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_26 ~~ dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_27 ~~ dhf_endors_28+dhf_endors_29+dhf_endors_30

  dhf_endors_28 ~~ dhf_endors_29+dhf_endors_30

  dhf_endors_29 ~~ dhf_endors_30'

corr_norm <- '
  dhf_norm_1 ~~ dhf_norm_2 +dhf_norm_3+dhf_norm_4+dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_2 ~~ dhf_norm_3+dhf_norm_4+dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
 
  dhf_norm_3 ~~ dhf_norm_4+dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_4 ~~ dhf_norm_5 + dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_5 ~~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_6 ~~ dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_7 ~~ dhf_norm_8+dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_8 ~~ dhf_norm_9+dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_9 ~~ dhf_norm_10 + dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_10 ~~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_11 ~~ dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
    
  dhf_norm_12 ~~ dhf_norm_13+dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
      
  dhf_norm_13 ~~ dhf_norm_14+dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
        
  dhf_norm_14 ~~ dhf_norm_15 + dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
          
  dhf_norm_15 ~~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
            
  dhf_norm_16 ~~ dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
              
  dhf_norm_17 ~~ dhf_norm_18+dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
                
  dhf_norm_18 ~~ dhf_norm_19+dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
                  
  dhf_norm_19 ~~ dhf_norm_20 + dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
                    
  dhf_norm_20 ~~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  dhf_norm_21 ~~ dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_22 ~~ dhf_norm_23+dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_23 ~~ dhf_norm_24+dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_24 ~~ dhf_norm_25 + dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_25 ~~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_26 ~~ dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_27 ~~ dhf_norm_28+dhf_norm_29+dhf_norm_30

  dhf_norm_28 ~~ dhf_norm_29+dhf_norm_30

  dhf_norm_29 ~~ dhf_norm_30'
```

# Data

```{r import-data}
# load data
dt <- import("dhf_data_final.csv")

# example data structure 
head(names(dt))
```

# Data Cleaning

Step 1. Data preparation

-   (Re)code all variables, check distributions and missing values.
-   Calculate overall item measures:
    -   Note that these will be calculated by taking the mean score on all appropriate items for that measure excluding missing data, as long as a participant has at least one data point for that measure.
    -   For example, if someone has items 2 and 3 for the SWLS, these two items will averaged for that measure.
    -   We will test the robustness of our findings on a subsample of participants with no missing values. Each analysis will be run only on a subsample of participants who have no missing values on the variables involved in that analysis.

## Socio-demographics

```{r demographic-clean}
#variable names changed to match the new data
factorized_var_numbers<-
  c(which(names(dt)=="gender"),
    which(names(dt)=="Migration"),
    which(names(dt)=="location_childhood"),
    which(names(dt)=="location_current"),
    which(names(dt)=="ethnicity"),
    which(names(dt)=="religion"),
    which(names(dt)=="education"),
    which(names(dt)=="student"),
    which(names(dt)=="income"),
    which(names(dt)=="Country"),
    which(names(dt)=="Country_full"),
    which(names(dt)=="Sample"),
    which(names(dt)=="datasource"))

numeric_var_numbers<-
  c(which(names(dt)=="Age"))

# refactor gender, age, education, state, race, migration 
dt[,factorized_var_numbers] <- lapply(dt[,factorized_var_numbers], as.factor)
dt[,numeric_var_numbers] <- as.numeric(dt[,numeric_var_numbers])
```

## Clean Country Names

```{r demographic-clean-country}
country_codes <- import("country_codes.xlsx")
dt <- dt %>% 
  mutate(country_res = gsub(-999, NA, country_res),
         country_res = gsub(-99, NA, country_res),
         country_res = gsub(199, NA, country_res)) %>% 
  mutate(country_res_full = factor(
    country_res,
    levels = c(country_codes$code),
    labels = c(country_codes$country)
  )) %>% 
  mutate(
    LabID = if_else(
      LabID == "" | is.na(LabID),
      str_extract(Q_Language, "(\\d+)(?!.*\\d)"),  # last number in string
      LabID
    )
  ) %>% 
  mutate(LabID = gsub("3587,3587", "3587", LabID),
         LabID = gsub("3746,3746", "3746", LabID)) %>% 
  mutate(
    country_res_full = ifelse(
      is.na(country_res_full),
      as.character(Country_full),
      as.character(country_res_full)
    )
  ) %>% 
  mutate(Country = gsub("ET\\$LabID=3300", "ET", Country), 
         Country = gsub("UA,UA", "UA", Country), 
         Country = gsub("CM,CM", "CM", Country),
         Country = gsub("TRUZ", "UZ", Country),
         Country = gsub("GB", "UK", Country)) %>% 
  mutate(
    Country = if_else(
      is.na(Country) | Country == "",
      str_extract(Q_Language, "(?<=^[A-Z]{2}-?)[A-Z]{2}"),
      Country
    )
  ) %>% 
  mutate(
    Country = case_when(
      Q_Language == "RO-3304"   ~ "RO",
      Q_Language == "SR-2088-C" ~ "SR",
      Q_Language == "HE-2412"   ~ "IL",
      Q_Language == "SR-2088" ~ "SR", 
      Q_Language == "SQI-4150" ~ "SQI",
      Q_Language == "KAT-GE4378" ~ "GA",
      TRUE ~ Country            # keep existing Country
    ),
    country_res_full = case_when(
      is.na(country_res_full) & Q_Language == "RO-3304"   ~ "Romania",
      is.na(country_res_full) & Q_Language == "SR-2088-C" ~ "Serbia",
      is.na(country_res_full) & Q_Language == "HE-2412"   ~ "Israel",
      is.na(country_res_full) & Q_Language == "SR-2088" ~ "Serbia", 
      is.na(country_res_full) & Q_Language == "SQI-4150" ~ "Albania",
      is.na(country_res_full) & Q_Language == "KAT-GE4378" ~ "Georgia",
      is.na(country_res_full) & Q_Language == "EN-KU-2480" ~ "Kuwait",
      TRUE ~ country_res_full            # keep existing Country
    )
  ) %>% 
  mutate(
    country_res_full = if_else(
      is.na(country_res_full) | country_res_full == "",
      countrycode(Country, origin = "iso2c", destination = "country.name"),
      country_res_full
    )
  ) %>% 
  mutate(
    country_res_full = recode(
      country_res_full,
      "Hong Kong (S.A.R.)" = "Hong Kong",
      "Bosnia & Herzegovina" = "Bosnia-Herzegovina",
      "Macao SAR China" = "Macau (S.A.R.)"
    )
  )

# let's look at where they change 
dt %>% 
  select(Country_full, country_res_full) %>% 
  group_by(Country_full, country_res_full) %>%
  summarise(n = n()) %>%
  filter(Country_full != country_res_full)
  
table(dt$country_res_full, useNA = "ifany")
length(unique(dt$country_res_full))
sum(table(dt$country_res_full, useNA = "ifany") > 50)
```

##Data exclusions based on demographics
```{r demographic-clean}
#Age

table(dt$Age, useNA = "ifany") #strangely high amount of <NA>=8931

#exclude participants who are <18
dt1 <- subset(dt, Age >=18|is.na(Age)) #n=38151

describe(dt1$Age) #18-99, M=25.5, SD=10.1

#exclude those who were not born and raised in the country
table(dt1$Migration, useNA = "ifany") #NAs are cases where question was not shown, so include
dt2 <- subset(dt1, Migration==1|Migration==3|is.na(Migration)) #n=35901 

#exclude participants who failed 2 or 3 attention checks, except for ALLS countries where attention checks were not shown
dt2$attention1 <- ifelse(dt2$attention_1==2|dt2$datasource == "ALLS", 1, 0)
dt2$attention2 <- ifelse(dt2$attention_2==5|dt2$datasource == "ALLS", 1, 0)
dt2$attention3 <- ifelse(dt2$attention_3==3|dt2$datasource == "ALLS", 1, 0)
dt2$attention <- rowSums(dt2[c("attention1", "attention2", "attention3")], na.rm=T)
dt3 <- subset(dt2, attention>=2) #n=26620  

#exclude countries with <50 participants and where country is missing

table(dt3$country_res_full, useNA = "ifany")
dt3$country_res_full <- as.factor(dt3$country_res_full)

dt4 <- dt3 %>%
  group_by(country_res_full) %>%
  filter(!is.na(country_res_full) & n() >= 50) %>%
  ungroup() %>%
  mutate(country_res_full = droplevels(country_res_full))


table(dt4$country_res_full, useNA = "ifany")  #Final total N=26511  

sum(table(dt4$country_res_full, useNA = "ifany") >= 50)  #64 countries with >=50 observations
sum(table(dt4$country_res_full, useNA = "ifany") >= 100) #57 countries with >=100 observations
sum(table(dt4$country_res_full, useNA = "ifany") >= 300) #38 countries with >=300 observations

table(dt4$Progress, useNA = "ifany") #varies between 51-100%, which means they all passed at least DHF, which was our exclusion criteria. ALLS data doesn't have this var. Two weird categories besides numbers - "complete" and "live", check with Priya

dt4[dt4 == -99] <- NA
dt4[dt4 == -999] <- NA
#all -99 and -999 in the dataset are now assigned as missing 

##demographics of the overall sample

describe(dt4$Age)

table(dt4$gender, useNA = "ifany")
prop.table(table(dt4$gender)) #66% women, 32% men, 0.8% NB, 1.2% other or no response  

table(dt4$datasource, useNA = "ifany") #Qualtrics=22902, ALLS=2915, Gorilla=694 
table(dt4$datasource, dt4$country_res_full)

table(dt4$student, useNA = "ifany")
prop.table(table(dt4$student)) #70% students, 30% not

table(dt4$ethnicity, useNA = "ifany")
prop.table(table(dt4$ethnicity)) #70% largest ethnic group

table(dt4$religion, useNA = "ifany")
prop.table(table(dt4$religion)) #26% No affiliation, 43% Christian, 16% Muslim, 2% Jewish, 2% Hindu, 3% Buddhist, 8% other or do not want to respond

##dt4 should be used for all analysis except those involving behavioral measures##

```


-   Merge all country datasets (dt1 and dt2).
#not needed, as this has been done at data cleaning stage

```{r merge-all-data, eval=FALSE}
# coming based on real dataset
```


## Calculate Reliability at Country Level

-   Calculate alpha reliability coefficients by country for each secondary measure (self-reported positive and negative reciprocity, attitude toward violence (four subscales and the total scale), self-face and other-face concern, reactions to provocation (three subscales), values (four higher-order value subscales), moral foundations (five subscales), intrinsic religiosity from DUREL, SWLS). If alpha is \>.60, calculate the index. If alpha is \< .60, consider modifications. Items will be removed only if the removal of the item improves alpha by \> .10 points in at least half of the countries.

```{r reliability}
# secondary measure (self-reported positive and negative reciprocity, attitude toward violence (four subscales and the total scale), self-face and other-face concern, reactions to provocation (three subscales), values (four higher-order value subscales), moral foundations (five subscales), intrinsic religiosity (from DUREL), subjective well being (SWLS) 

# we would do this by country (overall sample calculation is included optionally)

# Merge Schwartz values columns (male, female & neutral versions)
print("Merging Schwartz values columns...")
for(i in 1:21) {
  col_name <- paste0("values_", i)
  col_n <- paste0("values_n_", i)
  col_m <- paste0("values_m_", i)  
  col_f <- paste0("values_f_", i)
  
  if(all(c(col_n, col_m, col_f) %in% names(dt4))) {
    dt4 <- dt4 %>%
      mutate(!!col_name := coalesce(!!sym(col_n), !!sym(col_m), !!sym(col_f)))
  }
}

# Define all scales and subscales
scales_list <- list(
  # 1. Reciprocity
  "Positive_Reciprocity" = c("Reciprocity_1", "Reciprocity_2", "Reciprocity_3"),
  "Negative_Reciprocity" = c("Reciprocity_4", "Reciprocity_5", "Reciprocity_6"),
  
  # 2. Violence attitudes
  "Penal_Code_Violence" = c("violence_1", "violence_2", "violence_3"),
  "War_Acceptance" = c("violence_4", "violence_5", "violence_6"),
  "Corporal_Punishment" = c("violence_7", "violence_8", "violence_9"),
  "Intimate_Violence" = c("violence_10", "violence_11", "violence_12"),
  "Total_Violence_Scale" = paste0("violence_", 1:12),
  
  # 3. Face concerns
  "Other_Face_Concern" = c("conflict_face_2", "conflict_face_3", "conflict_face_4", 
                           "conflict_face_5", "conflict_face_6", "conflict_face_7"),
  "Self_Face_Concern" = c("conflict_face_8", "conflict_face_9", "conflict_face_10", "conflict_face_11"),
  
  # 4. Reactions to provocation
  "Withdrawal" = c("insult1_1", "insult2_1", "insult3_1"),
  "Retaliation" = c("insult1_2", "insult2_2", "insult3_2"),
  "Humor" = c("insult1_3", "insult2_3", "insult3_3"),
  
  # 5. Moral Foundations
  "MFQ_Care" = paste0("MFQ_", c(1, 7, 13, 19, 25, 31)),
  "MFQ_Equality" = paste0("MFQ_", c(2, 8, 14, 20, 26, 32)),
  "MFQ_Proportionality" = paste0("MFQ_", c(3, 9, 15, 21, 27, 33)),
  "MFQ_Loyalty" = paste0("MFQ_", c(4, 10, 16, 22, 28, 34)),
  "MFQ_Authority" = paste0("MFQ_", c(5, 11, 17, 23, 29, 35)),
  "MFQ_Purity" = paste0("MFQ_", c(6, 12, 18, 24, 30, 36)),
  
  # 6. Intrinsic Religiosity
  "Intrinsic_Religiosity" = c("relig_intrinsic_1", "relig_intrinsic_2", "relig_intrinsic_3"),
  
  # 7. Subjective Well-being
  "Subjective_Wellbeing" = c("swbls_1", "swbls_2", "swbls_3", "swbls_4", "swbls_5"),
  
  # 8. Schwartz Values - Basic values
  "Conformity" = paste0("values_", c(7, 16)),
  "Tradition" = paste0("values_", c(9, 20)),
  "Benevolence" = paste0("values_", c(12, 18)),
  "Universalism" = paste0("values_", c(3, 8, 19)),
  "Self_Direction" = paste0("values_", c(1, 11)),
  "Stimulation" = paste0("values_", c(6, 15)),
  "Hedonism" = paste0("values_", c(10, 21)),
  "Achievement" = paste0("values_", c(4, 13)),
  "Power" = paste0("values_", c(2, 17)),
  "Security" = paste0("values_", c(5, 14)),
  
  # Schwartz Values - Higher order values
  "Self_Transcendence" = paste0("values_", c(3, 8, 19, 12, 18)),
  "Self_Enhancement" = paste0("values_", c(4, 13, 2, 17)),
  "Openness_to_Change" = paste0("values_", c(1, 11, 6, 15, 10, 21)),
  "Conservation" = paste0("values_", c(5, 14, 7, 16, 9, 20))
)

# Function to safely calculate alpha (avoiding duplicates)
safe_alpha_calculation <- function(data, scale_name, group_name) {
  tryCatch({
    # Remove zero-variance items
    data_clean <- data[, sapply(data, function(x) var(x, na.rm = TRUE) > 0 & !is.na(var(x, na.rm = TRUE))), drop = FALSE]
    
    if(ncol(data_clean) < 2) {
      return(list(alpha = NA, alpha_drop = NULL, valid_items = ncol(data_clean), items_analyzed = colnames(data_clean)))
    }
    
    # Calculate alpha WITHOUT automatic reverse coding to avoid duplicates
    alpha_result <- psych::alpha(data_clean, check.keys = FALSE, warnings = FALSE)
    
    return(list(
      alpha = alpha_result$total$std.alpha,
      alpha_drop = alpha_result$alpha.drop,
      valid_items = ncol(data_clean),
      items_analyzed = colnames(data_clean)
    ))
    
  }, error = function(e) {
    return(list(alpha = NA, alpha_drop = NULL, valid_items = 0, items_analyzed = character(0)))
  })
}

# Function to analyze alpha for each country
analyze_country_alphas_revised <- function() {
  countries <- unique(dt4$country_res_full[!is.na(dt4$country_res_full)])
  results <- list()
  
  # Overall sample first
  cat("Analyzing overall sample...\n")
  overall_results <- list()
  
  for(scale_name in names(scales_list)) {
    scale_vars <- scales_list[[scale_name]]
    available_vars <- scale_vars[scale_vars %in% names(dt4)]
    
    if(length(available_vars) < 2) next
    
    scale_data <- dt4[, available_vars, drop = FALSE]
    scale_data <- scale_data[complete.cases(scale_data), , drop = FALSE]
    
    if(nrow(scale_data) < 10) next
    
    alpha_analysis <- safe_alpha_calculation(scale_data, scale_name, "Overall")
    
    overall_results[[scale_name]] <- list(
      country = "Overall",
      scale = scale_name,
      n = nrow(scale_data),
      alpha = alpha_analysis$alpha,
      alpha_drop = alpha_analysis$alpha_drop,
      valid_items = alpha_analysis$valid_items,
      total_items = length(available_vars),
      items_analyzed = alpha_analysis$items_analyzed
    )
  }
  
  results[["Overall"]] <- overall_results
  
  # By country
  for(country in countries) {
    cat("Analyzing country:", country, "\n")
    country_data <- dt4[dt4$country_res_full == country & !is.na(dt4$country_res_full), ]
    country_results <- list()
    
    for(scale_name in names(scales_list)) {
      scale_vars <- scales_list[[scale_name]]
      available_vars <- scale_vars[scale_vars %in% names(country_data)]
      
      if(length(available_vars) < 2) next
      
      scale_data <- country_data[, available_vars, drop = FALSE]
      scale_data <- scale_data[complete.cases(scale_data), , drop = FALSE]
      
      if(nrow(scale_data) < 10) next
      
      alpha_analysis <- safe_alpha_calculation(scale_data, scale_name, country)
      
      country_results[[scale_name]] <- list(
        country = country,
        scale = scale_name,
        n = nrow(scale_data),
        alpha = alpha_analysis$alpha,
        alpha_drop = alpha_analysis$alpha_drop,
        valid_items = alpha_analysis$valid_items,
        total_items = length(available_vars),
        items_analyzed = alpha_analysis$items_analyzed
      )
    }
    
    results[[country]] <- country_results
  }
  
  return(results)
}

# Run the analysis
print("CRONBACH'S ALPHA ANALYSIS")
print("(Items removed if they help ≥50% of countries with α<0.60)")
print(paste(rep("=", 65), collapse = ""))

all_results <- analyze_country_alphas_revised()

# Create summary table of all alphas
summary_table <- data.frame()

for(country in names(all_results)) {
  country_results <- all_results[[country]]
  
  for(scale_name in names(country_results)) {
    scale_result <- country_results[[scale_name]]
    
    summary_table <- rbind(summary_table, data.frame(
      Country = country,
      Scale = scale_name,
      N = scale_result$n,
      Valid_Items = scale_result$valid_items,
      Total_Items = scale_result$total_items,
      Alpha = round(scale_result$alpha, 3),
      stringsAsFactors = FALSE
    ))
  }
}

# Identify problematic scales (alpha < .60)
problematic_scales <- summary_table %>%
  filter(!is.na(Alpha) & Alpha < 0.60) %>%
  arrange(Country, Alpha)

print("\n1. SCALES WITH ALPHA < .60")
print(paste(rep("-", 40), collapse = ""))
print(problematic_scales)

if(nrow(problematic_scales) == 0) {
  print("No scales found with alpha < .60!")
} else {
  
  # Count how many countries have problems with each scale
  scale_problem_counts <- problematic_scales %>%
    group_by(Scale) %>%
    summarise(
      Countries_with_problems = n(),
      .groups = "drop"
    ) %>%
    arrange(desc(Countries_with_problems))
  
  print("\n2. SCALES BY NUMBER OF PROBLEMATIC COUNTRIES")
  print(paste(rep("-", 50), collapse = ""))
  print(scale_problem_counts)
  
  # Apply item removal analysis to ALL scales with alpha < 0.60
  print("\n2. SCALES BY NUMBER OF PROBLEMATIC COUNTRIES")
  print(paste(rep("-", 50), collapse = ""))
  print(scale_problem_counts)
  
  # Use ALL scales that have any problematic countries
  scales_for_analysis <- scale_problem_counts$Scale
  
  print(paste("\n3. SCALES FOR ITEM REMOVAL ANALYSIS"))
  print(paste("(All scales with alpha < 0.60 in any countries)"))
  print(paste(rep("-", 60), collapse = ""))
  print(scales_for_analysis)
  
  # For all scales with problems, show item-removal statistics
  print("\n4. ITEM-REMOVAL ANALYSIS FOR ALL PROBLEMATIC SCALES")
  print(paste(rep("-", 55), collapse = ""))
  
  item_removal_details <- data.frame()
  
  for(scale_name in scales_for_analysis) {
    # Get all countries with problems for this scale
    problem_countries <- problematic_scales %>%
      filter(Scale == scale_name) %>%
      pull(Country)
    
    cat("\n", paste(rep("=", 60), collapse = ""), "\n")
    cat("SCALE:", scale_name, "\n")
    cat("Countries with alpha < 0.60:", length(problem_countries), "\n")
    cat("Countries:", paste(problem_countries, collapse = ", "), "\n")
    cat(paste(rep("=", 60), collapse = ""), "\n")
    
    # Collect item removal stats for each problem country
    scale_item_stats <- data.frame()
    
    for(country in problem_countries) {
      cat("\nAnalyzing", country, "...\n")
      
      # Get data for this country and scale
      if(country == "Overall") {
        scale_vars <- scales_list[[scale_name]]
        available_vars <- scale_vars[scale_vars %in% names(dt4)]
        scale_data <- dt4[, available_vars, drop = FALSE]
        scale_data <- scale_data[complete.cases(scale_data), , drop = FALSE]
      } else {
        country_data <- dt4[dt4$country_res_full == country & !is.na(dt4$country_res_full), ]
        scale_vars <- scales_list[[scale_name]]
        available_vars <- scale_vars[scale_vars %in% names(country_data)]
        scale_data <- country_data[, available_vars, drop = FALSE]
        scale_data <- scale_data[complete.cases(scale_data), , drop = FALSE]
      }
      
      alpha_analysis <- safe_alpha_calculation(scale_data, scale_name, country)
      current_alpha <- alpha_analysis$alpha
      
      cat("Current alpha:", round(current_alpha, 3), "\n")
      
      if(!is.null(alpha_analysis$alpha_drop) && nrow(alpha_analysis$alpha_drop) > 0) {
        
        # Clean item names to avoid duplicates
        alpha_drop_clean <- alpha_analysis$alpha_drop
        alpha_drop_clean$Item <- rownames(alpha_drop_clean)
        
        # Remove any items with '-' suffix (reverse coding artifacts)
        alpha_drop_clean <- alpha_drop_clean[!grepl("-$", alpha_drop_clean$Item), ]
        
        if(nrow(alpha_drop_clean) > 0) {
          alpha_drop_df <- data.frame(
            Country = country,
            Scale = scale_name,
            Item = alpha_drop_clean$Item,
            Current_Alpha = current_alpha,
            Alpha_if_deleted = round(alpha_drop_clean$std.alpha, 3),
            Improvement = round(alpha_drop_clean$std.alpha - current_alpha, 3),
            stringsAsFactors = FALSE
          )
          
          scale_item_stats <- rbind(scale_item_stats, alpha_drop_df)
        }
      }
    }
    
    if(nrow(scale_item_stats) > 0) {
      # Summarize across countries for this scale
      item_summary <- scale_item_stats %>%
        group_by(Item) %>%
        summarise(
          Countries_helped = sum(Improvement > 0.10),
          Total_countries = n(),
          Avg_improvement = mean(Improvement),
          .groups = "drop"
        ) %>%
        mutate(
          Proportion_helped = round(Countries_helped / Total_countries, 3),
          Recommendation = ifelse(Countries_helped / Total_countries >= 0.5, "REMOVE", "KEEP")
        ) %>%
        arrange(desc(Proportion_helped))
      
      cat("\nSUMMARY FOR", scale_name, ":\n")
      print(item_summary)
      
      # Add to detailed results
      detailed_results <- scale_item_stats %>%
        left_join(item_summary, by = "Item")
      
      item_removal_details <- rbind(item_removal_details, detailed_results)
      
      # Show recommendations
      items_to_remove <- item_summary %>%
        filter(Recommendation == "REMOVE")
      
      if(nrow(items_to_remove) > 0) {
        cat("\nRECOMMENDED FOR REMOVAL:\n")
        for(i in 1:nrow(items_to_remove)) {
          cat("- ", items_to_remove$Item[i], 
              " (helps ", items_to_remove$Countries_helped[i], "/", items_to_remove$Total_countries[i], 
              " countries, ", round(items_to_remove$Proportion_helped[i] * 100, 1), "%)\n")
        }
      } else {
        cat("\nNo items recommended for removal from", scale_name, "\n")
      }
    }
  }
  
  # Final summary
  if(nrow(item_removal_details) > 0) {
    print("\n5. FINAL RECOMMENDATIONS SUMMARY")
    print(paste(rep("=", 45), collapse = ""))
    
    final_recommendations <- item_removal_details %>%
      select(Scale, Item, Countries_helped, Total_countries, Proportion_helped, Avg_improvement, Recommendation) %>%
      distinct() %>%
      filter(Recommendation == "REMOVE") %>%
      arrange(Scale, desc(Proportion_helped))
    
    # Create detailed item-level problem summary
    item_problem_summary <- item_removal_details %>%
      select(Scale, Item, Countries_helped, Total_countries, Proportion_helped, Avg_improvement, Recommendation) %>%
      distinct() %>%
      arrange(Scale, Item) %>%
      mutate(
        Countries_not_helped = Total_countries - Countries_helped,
        Problem_description = paste0("Alpha <0.60 in ", Total_countries, " countries, helps ", Countries_helped, " (", round(Proportion_helped * 100, 1), "%)")
      )
    
    print("\nDETAILED ITEM-LEVEL SUMMARY:")
    print(item_problem_summary)
    
    if(nrow(final_recommendations) > 0) {
      print("\nITEMS TO REMOVE:")
      print(final_recommendations)
    } else {
      print("\nNO ITEMS MEET THE REMOVAL CRITERIA")
      print("(Must improve alpha by >0.10 in ≥50% of countries with α<0.60)")
    }
    
    # Export files
    write.csv(summary_table, "all_alpha_results.csv", row.names = FALSE)
    write.csv(problematic_scales, "problematic_scales.csv", row.names = FALSE)
    write.csv(scale_problem_counts, "scale_problem_counts.csv", row.names = FALSE)
    write.csv(item_problem_summary, "item_problem_summary.csv", row.names = FALSE)
    
    if(nrow(final_recommendations) > 0) {
      write.csv(final_recommendations, "final_recommendations.csv", row.names = FALSE)
    }
    
    cat("\nFiles exported:\n")
    cat("- all_alpha_results.csv\n")
    cat("- problematic_scales.csv\n")
    cat("- scale_problem_counts.csv\n")
    cat("- item_problem_summary.csv\n")
    if(nrow(final_recommendations) > 0) {
      cat("- final_recommendations.csv\n")
    }
  }
}


print(paste("\n", paste(rep("=", 65), collapse = "")))
print("ANALYSIS COMPLETE")
print(paste(rep("=", 65), collapse = ""))
```

##Indices for secondary measures

-  For all secondary scales, we will calculate the mean score based on the items that comprise each overall scale and component subscale if their reliability is acceptable (\>.60). Indices will be calculated for the following variables: self-reported positive and negative reciprocity; general attitude toward violence (all items), and the four subscales: acceptance of war, acceptance of intimate violence, acceptance of penal code violence, and acceptance of corporal punishment for children; self-face and other-face concern in interpersonal conflict; retaliation, withdrawal, and humor as reactions to provocation (mean of 3 items/scenarios per subscale); 10 values and 4 higher-order values according to Schwartz’s original conceptualization; 6 moral foundations; intrinsic religiosity based on raw scores (3 items) and a composite religiosity score based on standardized scores (5 items); and global life satisfaction.

```{r}
# Ensure Schwartz values are merged (if not already done in the reliability check stage)
print("Ensuring Schwartz values are merged...")
for(i in 1:21) {
  col_name <- paste0("values_", i)
  col_n <- paste0("values_n_", i)
  col_m <- paste0("values_m_", i)  
  col_f <- paste0("values_f_", i)
  
  if(all(c(col_n, col_m, col_f) %in% names(dt4))) {
    dt4 <- dt4 %>%
      mutate(!!col_name := coalesce(!!sym(col_n), !!sym(col_m), !!sym(col_f)))
  }
}

print("CREATING SCALE INDICES")
print(paste(rep("=", 50), collapse = ""))

# Function to calculate mean with at least 50% valid responses
calculate_scale_mean <- function(data, vars, min_valid_prop = 0.5) {
  # Check which variables exist
  available_vars <- vars[vars %in% names(data)]
  
  if(length(available_vars) == 0) {
    return(rep(NA, nrow(data)))
  }
  
  # Calculate means requiring at least 50% valid responses
  scale_data <- data[, available_vars, drop = FALSE]
  n_items <- ncol(scale_data)
  min_valid <- ceiling(n_items * min_valid_prop)
  
  # Calculate row means with minimum valid responses
  row_means <- rowMeans(scale_data, na.rm = TRUE)
  valid_count <- rowSums(!is.na(scale_data))
  
  # Set to NA if insufficient valid responses
  row_means[valid_count < min_valid] <- NA
  
  return(row_means)
}

# Create all scale indices
print("1. Creating reciprocity indices...")

# 1. RECIPROCITY
dt4 <- dt4 %>%
  mutate(
    Positive_Reciprocity = calculate_scale_mean(., c("Reciprocity_1", "Reciprocity_2", "Reciprocity_3")),
    Negative_Reciprocity = calculate_scale_mean(., c("Reciprocity_4", "Reciprocity_5", "Reciprocity_6"))
  )

print("2. Creating violence attitude indices...")

# 2. VIOLENCE ATTITUDES
dt4 <- dt4 %>%
  mutate(
    Penal_Code_Violence = calculate_scale_mean(., c("violence_1", "violence_2", "violence_3")),
    War_Acceptance = calculate_scale_mean(., c("violence_4", "violence_5", "violence_6")),
    Corporal_Punishment = calculate_scale_mean(., c("violence_7", "violence_8", "violence_9")),
    Intimate_Violence = calculate_scale_mean(., c("violence_10", "violence_11", "violence_12")),
    Total_Violence = calculate_scale_mean(., paste0("violence_", 1:12))
  )

print("3. Creating face concern indices...")

# 3. FACE CONCERNS
dt4 <- dt4 %>%
  mutate(
    Other_Face_Concern = calculate_scale_mean(., c("conflict_face_2", "conflict_face_3", "conflict_face_4", 
                                                   "conflict_face_5", "conflict_face_6", "conflict_face_7")),
    Self_Face_Concern = calculate_scale_mean(., c("conflict_face_8", "conflict_face_9", "conflict_face_10", "conflict_face_11"))
  )

print("4. Creating reactions to insult indices (excluding 3rd scenario)...")

# 4. REACTIONS TO PROVOCATION (excluding 3rd scenario items due to problematic alpha)
dt4 <- dt4 %>%
  mutate(
    Withdrawal = calculate_scale_mean(., c("insult1_1", "insult2_1")),
    Retaliation = calculate_scale_mean(., c("insult1_2", "insult2_2")),
    Humor = calculate_scale_mean(., c("insult1_3", "insult2_3"))
  )

print("5. Creating Schwartz higher-order values indices...")

# 5. SCHWARTZ HIGHER-ORDER VALUES
dt4 <- dt4 %>%
  mutate(
    Self_Transcendence = calculate_scale_mean(., paste0("values_", c(3, 8, 19, 12, 18))),
    Self_Enhancement = calculate_scale_mean(., paste0("values_", c(4, 13, 2, 17))),
    Openness_to_Change = calculate_scale_mean(., paste0("values_", c(1, 11, 6, 15, 10, 21))),
    Conservation = calculate_scale_mean(., paste0("values_", c(5, 14, 7, 16, 9, 20)))
  )

print("6. Creating moral foundations indices...")

# 6. MORAL FOUNDATIONS
dt4 <- dt4 %>%
  mutate(
    MFQ_Care = calculate_scale_mean(., paste0("MFQ_", c(1, 7, 13, 19, 25, 31))),
    MFQ_Equality = calculate_scale_mean(., paste0("MFQ_", c(2, 8, 14, 20, 26, 32))),
    MFQ_Proportionality = calculate_scale_mean(., paste0("MFQ_", c(3, 9, 15, 21, 27, 33))),
    MFQ_Loyalty = calculate_scale_mean(., paste0("MFQ_", c(4, 10, 16, 22, 28, 34))),
    MFQ_Authority = calculate_scale_mean(., paste0("MFQ_", c(5, 11, 17, 23, 29, 35))),
    MFQ_Purity = calculate_scale_mean(., paste0("MFQ_", c(6, 12, 18, 24, 30, 36)))
  )

print("7. Creating religiosity indices...")

# 7. INTRINSIC RELIGIOSITY (raw scores)
dt4 <- dt4 %>%
  mutate(
    Intrinsic_Religiosity = calculate_scale_mean(., c("relig_intrinsic_1", "relig_intrinsic_2", "relig_intrinsic_3"))
  )

# 8. COMPOSITE RELIGIOSITY (standardized scores)
print("8. Creating composite religiosity index (standardized scores)...")

# Check if religiosity variables exist
religiosity_vars <- c("relig_attendance", "relig_private", "relig_intrinsic_1", "relig_intrinsic_2", "relig_intrinsic_3")
available_relig_vars <- religiosity_vars[religiosity_vars %in% names(dt4)]

if(length(available_relig_vars) > 0) {
  # Standardize each religiosity variable
  dt4_standardized <- dt4
  for(var in available_relig_vars) {
    dt4_standardized[[paste0(var, "_z")]] <- scale(dt4[[var]])[,1]
  }
  
  # Calculate composite score from standardized variables
  standardized_vars <- paste0(available_relig_vars, "_z")
  dt4$Composite_Religiosity <- calculate_scale_mean(dt4_standardized, standardized_vars)
  
  cat("Composite religiosity created using:", paste(available_relig_vars, collapse = ", "), "\n")
} else {
  dt4$Composite_Religiosity <- NA
  cat("Warning: Religiosity variables not found. Composite religiosity set to NA.\n")
}

print("9. Creating subjective well-being index...")

# 9. SUBJECTIVE WELL-BEING
dt4 <- dt4 %>%
  mutate(
    Subjective_Wellbeing = calculate_scale_mean(., c("swbls_1", "swbls_2", "swbls_3", "swbls_4", "swbls_5"))
  )

# List all created indices
created_indices <- c(
  "Positive_Reciprocity", "Negative_Reciprocity",
  "Penal_Code_Violence", "War_Acceptance", "Corporal_Punishment", "Intimate_Violence", "Total_Violence",
  "Other_Face_Concern", "Self_Face_Concern",
  "Withdrawal", "Retaliation", "Humor",
  "Self_Transcendence", "Self_Enhancement", "Openness_to_Change", "Conservation",
  "MFQ_Care", "MFQ_Equality", "MFQ_Proportionality", "MFQ_Loyalty", "MFQ_Authority", "MFQ_Purity",
  "Intrinsic_Religiosity", "Composite_Religiosity", "Subjective_Wellbeing"
)

print("\nCreated indices:")
print(created_indices)

print("\nCREATING DESCRIPTIVE STATISTICS")
print(paste(rep("=", 50), collapse = ""))

# Function to calculate descriptives for a group
calculate_descriptives <- function(data, group_name) {
  descriptives <- data.frame()
  
  for(index in created_indices) {
    if(index %in% names(data)) {
      values <- data[[index]]
      n_valid <- sum(!is.na(values))
      
      # Handle cases where all values are NA
      if(n_valid == 0) {
        descriptive_row <- data.frame(
          Group = group_name,
          Scale = index,
          N = 0,
          Missing = length(values),
          Mean = NA,
          SD = NA,
          Min = NA,
          Max = NA,
          stringsAsFactors = FALSE
        )
      } else {
        descriptive_row <- data.frame(
          Group = group_name,
          Scale = index,
          N = n_valid,
          Missing = sum(is.na(values)),
          Mean = round(mean(values, na.rm = TRUE), 3),
          SD = round(sd(values, na.rm = TRUE), 3),
          Min = round(min(values, na.rm = TRUE), 3),
          Max = round(max(values, na.rm = TRUE), 3),
          stringsAsFactors = FALSE
        )
      }
      
      descriptives <- rbind(descriptives, descriptive_row)
    }
  }
  
  return(descriptives)
}

# 1. OVERALL SAMPLE DESCRIPTIVES
print("1. Calculating overall sample descriptives...")

overall_descriptives <- calculate_descriptives(dt4, "Overall")

print("Overall sample descriptives:")
print(overall_descriptives)

# 2. BY-COUNTRY DESCRIPTIVES
print("\n2. Calculating by-country descriptives...")

countries <- unique(dt4$country_res_full[!is.na(dt4$country_res_full)])
all_descriptives <- overall_descriptives

for(country in countries) {
  cat("Processing country:", country, "\n")
  country_data <- dt4[dt4$country_res_full == country & !is.na(dt4$country_res_full), ]
  
  if(nrow(country_data) > 0) {
    country_descriptives <- calculate_descriptives(country_data, country)
    all_descriptives <- rbind(all_descriptives, country_descriptives)
  }
}

# Sort descriptives by scale and group
all_descriptives <- all_descriptives %>%
  arrange(Scale, Group)

print("\n3. SUMMARY BY SCALE")
print(paste(rep("-", 30), collapse = ""))

# Create summary showing overall + first few countries for each scale
for(scale in created_indices) {
  scale_desc <- all_descriptives %>%
    filter(Scale == scale) %>%
    slice_head(n = 6)  # Overall + 5 countries
  
  if(nrow(scale_desc) > 0) {
    cat("\n", scale, ":\n")
    print(scale_desc[, c("Group", "N", "Mean", "SD")])
  }
}

print("\n4. EXPORTING RESULTS")
print(paste(rep("-", 25), collapse = ""))

# Export descriptive statistics
write.csv(all_descriptives, "scale_indices_descriptives.csv", row.names = FALSE)

# Export dataset with new indices (optional - only first 1000 rows if dataset is very large)
if(nrow(dt4) > 5000) {
  cat("Dataset is large (", nrow(dt4), " rows). Exporting sample of indices only.\n")
  
  # Export just the indices and identifying variables
  indices_only <- dt4 %>%
    select(country_res_full, all_of(created_indices)) %>%
    slice_head(n = 5000)
  
  write.csv(indices_only, "sample_scale_indices.csv", row.names = FALSE)
  
} else {
  cat("Exporting full dataset with indices.\n")
  # Note: Be cautious with large datasets - this might create a very large file
  indices_only <- dt4 %>%
    select(country_res_full, all_of(created_indices))
  
  write.csv(indices_only, "all_scale_indices.csv", row.names = FALSE)
}

# Summary of missing data patterns
print("\n5. MISSING DATA SUMMARY")
print(paste(rep("-", 30), collapse = ""))

missing_summary <- all_descriptives %>%
  filter(Group == "Overall") %>%
  select(Scale, N, Missing) %>%
  mutate(
    Total = N + Missing,
    Percent_Missing = round((Missing / Total) * 100, 1)
  ) %>%
  arrange(desc(Percent_Missing))

print("Missing data by scale (overall sample):")
print(missing_summary)

cat("\nFiles exported:\n")
cat("- scale_indices_descriptives.csv (mean, SD, N for all scales by country)\n")
if(nrow(dt4) > 5000) {
  cat("- sample_scale_indices.csv (sample of scale scores)\n")
} else {
  cat("- all_scale_indices.csv (all scale scores)\n")
}

print("\nNote: All indices calculated with requirement of ≥50% valid item responses")
print("Indices with insufficient valid responses are set to NA")

print(paste("\n", paste(rep("=", 50), collapse = "")))
print("INDICES CREATION AND DESCRIPTIVES COMPLETE")
print(paste(rep("=", 50), collapse = ""))
```


## Merge with Country Data
#not needed, because it has been done at data cleaning stage 
-   Merge with secondary country-level data on GDP per capita, inequality (Gini), HDI, GII, Democracy and Global freedom indicators.

```{r merge-country-level, eval=FALSE}
# coming based on real dataset
```

-   Merge with secondary historical country-level data on population density-1500 and 2000, pathogen prevalence, resource scarcity, war, and territorial threats.

```{r merge-country-level2, eval=FALSE}
# coming based on real dataset
```

-   Merge with country-level secondary data on cultural dimensions normsism-collectivism, flexibility-monumentalism, tightness-looseness, relational mobility, and Schwartz country-level value scores.

```{r merge-country-level3, eval=FALSE}
# coming based on real dataset
```

```{r temp-data, eval=FALSE}
# temp rename data to make this code proposal work 
DF <- dtg
```

## DHF

```{r dhf-clean}
# DHF ----

# look at the scaling 
table(dt4$dhf_endors_1, useNA = "ifany") #Although the progress var above shows >50% for all participants,  this var has 263 NAs (not seen). Both -99 and NA are missing values. Assign -99 as missing 

table(dt4$dhf_norm_1, useNA = "ifany") #>2000 missing
table(dt4$dhf_norm_1, dt4$datasource,useNA = "ifany") #because only a subset of participants were asked these questions in ALLS data

dt4 %>%
  select(dhf_endors_1:dhf_norm_30) %>%
  describe() 

```
# Terminology

Individual endorsement: Ratings on DHF for how much an individual endorses each item

Cultural norms: ratings on DHF for how much the person believes the country cultural norms represent endorsement on each item

Individual-level: using each participant's scores to represent the variable

Sample-level: using an average score by country to represent the variable

Level 1: [within] Analysis in multilevel models using the DHF data points for each participant (i.e., using each person’s scores as the level of analysis)

Level 2: [cluster] Analysis in multilevel models using the data points nested or clustered by the indicated variable (i.e., basically the average score for each item across the cluster variable as the level of analysis)

# Overall Model Comments

In each structural model, we may find the following issues:

-   Heywood cases:
    -   Too high correlations: we will consider combining factors when correlations between latent variables are too high if they theoretically make sense.\
    -   Negative variances: we will set the variance to a small positive number based on the variances of other items or latent variables
-   Non-convergence:
    -   We will try to find the issue of non-convergence - for example, if the country level does not have enough variability, we may remove the clustering effect to show convergence.
    -   For hierarchical models, we will consider setting all exogenous only correlations to 0 - rather than the proposed model below - to ensure identification.
    -   For all models, we will investigate just the level 1 factor structure of the model to determine model misspecification.
    -   For all models, we will investigate each country separately to determine if one sample creates the specific non-convergence issue (in the full model or just level 1 factor structure).
    -   We will also consider testing level-1 and level-2 for each model separately if they cannot be combined with convergence.

*Note*: code below is the pre-registered models. They currently do not run because of convergence issues, but these have not been edited because they are the planned models with larger samples.

# H1A

*Hypothesis*:

H1A: A hierarchical model with three higher-order factors of dignity, honor, and face, each represented by two facets of self-concern and other-concern, will appropriately describe the data.

*Analysis Plan*:

Individual endorsement and cultural norms will be tested separately. For each model, country will be used as a cluster variable.

Factor structure (see Fig. 1A): Multilevel confirmatory factor analysis (CFA), specifying a hierarchical model with three correlated higher-order latent factors representing dignity, honor, and face, each with two sub-factors representing the self-concern and other-concern facets.

Test 1: Level 1 will include the proposed factor structure, and Level 2 will include only the saturated model where all observed variables are intercorrelated.

Test 2: Level 1 will include only the saturated model of observed variable correlations, and Level 2 will include the proposed factor structure.

Individual endorsement and cultural norms will be tested separately. For each model, country will be used as a cluster variable.

*Model Evaluation*:

If the model converges, it will be compared to the models below (see notes below). If the model does not converge after making adjustments as described under “Overall model plans”, we will test the simpler alternative model with 6 correlated latent factors (see Fig. 1C). After model selection, we will use the guidelines in the model improvement and alignment section to improve model fit.

## Data Simulation
#not needed, do not run
```{r data-simulation-hierarchical, eval=FALSE}
DF_individual <- DF %>% 
  filter(`US state` == "Texas" | `US state` == "New York") %>% 
  dplyr::rename(country = `US state`) %>% 
   mutate(country = droplevels(as.factor(country))) %>% 
  select(DHF_endorsement_1:DHF_endorsement_30, country)

colnames(DF_individual) <- c(paste0(
  rep(c("D_self", "D_other", "H_self", 
        "H_other", "F_self", "F_other"), 
      each = 5),
  rep(1:5)), "country")

DF_norms <- DF %>% 
  filter(`US state` == "Texas" | `US state` == "New York") %>% 
  dplyr::rename(country = `US state`) %>% 
  mutate(country = droplevels(as.factor(country))) %>% 
  select(DHF_Norms_1:DHF_Norms_30, country)

colnames(DF_norms) <- c(paste0(
  rep(c("D_self", "D_other", "H_self", 
        "H_other", "F_self", "F_other"), 
      each = 5),
  rep(1:5)), "country")
```

## Power
#not needed, do not run
```{r power-hierarchical, eval=FALSE}
p <- 30 # number of observed variables 
k <- 564 # number of estimated parameters 
# you don't divide by 2 because you have it for the within and between covariance matrices 
df <- p*(p - 1) - k
df
semPower(type = 'a-priori', 
         effect = .08,
         effect.measure = "RMSEA",
         alpha = .05, 
         power = .90, 
         df = df,
         p = 30
         )
```

```{r power-hierarchical2, eval=FALSE}
semPower(type = 'a-priori', 
         effect = .90,
         effect.measure = "AGFI",
         alpha = .05, 
         power = .90, 
         df = df,
         p = 30
         )
```

## H1A Individual


### Hierarchical Individual Test 1

```{r individual-hierarchical-test1, eval = F}
hierarchical.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other

  
Level: 2
', 
corr_endors)

hierarchical.individual.test1.fit <- cfa(model = hierarchical.model.test1,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    #optim.method = "em"
                    # em.iter.max = 1000,
                    # em.fx.tol = 1e-08, 
                    # em.dx.tol = 1e-04
                    )
beep()

summary(hierarchical.individual.test1.fit, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)

#hierarchical.individual.test1.fitindices <- tidy(fitmeasures(hierarchical.individual.test1.fit))
hierarchical.individual.test1.params <- tidy(hierarchical.individual.test1.fit)
```

Updated model:

- Model estimation without "em" failed. Model converged after adding "em", but has a negative ver-covar matrix  
```{r individual-hierarchical-test1-updated}
hierarchical.model.test1.up <- 
paste0(' 
Level: 1
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
 
  
Level: 2
', 
corr_endors)

hierarchical.individual.test1.up.fit <- cfa(model = hierarchical.model.test1.up,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    optim.method = "em"
                    # em.iter.max = 1000,
                    # em.fx.tol = 1e-08, 
                    # em.dx.tol = 1e-04
                    )
beep()

summary(hierarchical.individual.test1.up.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#hierarchical.individual.test1.up.fitindices <- tidy(fitmeasures(hierarchical.individual.test1.up.fit))
hierarchical.individual.test1.up.params <- tidy(hierarchical.individual.test1.up.fit)
```

### Hierarchical Individual Test 2

```{r individual-hierarchical-test2-original}
hierarchical.model.test2 <- 
paste0(' 
Level: 1', 
corr_endors, 
'
Level: 2 
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
')

hierarchical.individual.test2.fit <- cfa(model = hierarchical.model.test2,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(hierarchical.individual.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#hierarchical.individual.test2.fitindices <- tidy(fitmeasures(hierarchical.individual.test2.fit))
hierarchical.individual.test2.params <- tidy(hierarchical.individual.test2.fit)
```
### Hierarchical Individual Test combined

```{r individual-hierarchical-testc-updated}
hierarchical.model.testc <- 
paste0(' 
Level: 1
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
 
  
Level: 2
 D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
  D_self ~~ 0.01*D_self
  H_self ~~ 0.01*H_self
  H_other ~~ 0.01*H_other
')

hierarchical.model.testc.fit <- cfa(model = hierarchical.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    # optim.method = "em"
                    # em.iter.max = 1000,
                    # em.fx.tol = 1e-08, 
                    # em.dx.tol = 1e-04
                    )
beep()

summary(hierarchical.model.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#hierarchical.individual.test1.up.fitindices <- tidy(fitmeasures(hierarchical.individual.test1.up.fit))
hierarchical.model.testc.params <- tidy(hierarchical.model.testc.fit)
```

# H1B

*Hypothesis*:

H1b: The hierarchical model will fit the data better than the three-factor model. We will alternatively test a six-factor model in case the hierarchical model does not converge.

*Analysis Plan*:

Individual endorsement and cultural norms will be tested separately. For each model, country will be used as a cluster variable.

Factor structure (see Fig. 1B): Multilevel CFA with three-factor correlated model of the DHF latent variables.

Test 1: Level 1 will include the proposed factor structure, and Level 2 will include only the saturated model where all observed variables are intercorrelated.

Test 2: Level 1 will include only the saturated model of observed variable correlations, and Level 2 will include the proposed factor structure.

*Model Evaluation*:

The model will be considered significantly better than an alternative if: - AIC is lower - BIC is lower - ΔCFI \> .010 (the model with higher CFA is better) - ΔRMSEA \> .015 (the model with lower RMSEA is better) - Chen (2007)

All these criteria will be considered together, and if the majority of them are fulfilled, the model will be considered significantly better than the alternative. If models are not significantly different from each other, the theoretically hypothesized hierarchical model will be preferred.

## Power

```{r power-comparison, eval=F}
k2 <- 558 # number of parameters in 3 factor
k3 <- 570 # number of parameters in 6 factor

df2 <- p*(p-1) - k2
df3 <- p*(p-1) - k3
semPower.aPriori(
  effect = c(.08-.015, .08),
  effect.measure = "RMSEA",
  alpha = .05, 
  power = .90, 
  df = c(df2, df)) # compare this model to the original if converge

semPower.aPriori(
  effect = c(.08-.015, .08),
  effect.measure = "RMSEA",
  alpha = .05, 
  power = .90, 
  df = c(df3, df2)) # only compare this model to three-factor
```

## H1B Individual

### 3-factor Individual Test 1

```{r individual-threefactor-test1}
threefactor.model.test1 <- 
paste0(' 
Level: 1
  D =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5+ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15+ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25+ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

Level: 2
', 
corr_endors)

threefactor.individual.test1.fit <- cfa(model = threefactor.model.test1,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    optim.method = "em" 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.individual.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#threefactor.individual.test1.fitindices <- tidy(fitmeasures(threefactor.individual.test1.fit))
threefactor.individual.test1.params <- tidy(threefactor.individual.test1.fit)
```

### 3-Factor Individual Test 2

```{r individual-threefactor-test2}
threefactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_endors, 
'
Level: 2 
   D =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5+ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
   H =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15+ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
   F =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25+ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

')

threefactor.individual.test2.fit <- cfa(model = threefactor.model.test2,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.individual.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#threefactor.individual.test2.fitindices <- tidy(fitmeasures(threefactor.individual.test2.fit))
threefactor.individual.test2.params <- tidy(threefactor.individual.test2.fit)
```
### 3-Factor Individual Test combined

```{r individual-threefactor-test2}
threefactor.model.testc <- 
paste0(' 
Level: 1

D =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5+ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
   H =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15+ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
   F =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25+ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30


Level: 2 
   D =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5+ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
   H =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15+ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
   F =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25+ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

')

threefactor.individual.testc.fit <- cfa(model = threefactor.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.individual.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#threefactor.individual.test2.fitindices <- tidy(fitmeasures(threefactor.individual.test2.fit))
threefactor.individual.testc.params <- tidy(threefactor.individual.testc.fit)
```

## H1B Individual (Alternative)

### 6-factor Individual Test 1

```{r individual-sixfactor-test1}
sixfactor.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

Level: 2
', 
corr_endors)

sixfactor.individual.test1.fit <- cfa(model = sixfactor.model.test1,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.individual.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.individual.test1.fitindices <- tidy(fitmeasures(sixfactor.individual.test1.fit))
sixfactor.individual.test1.params <- tidy(sixfactor.individual.test1.fit)
```

### 6-Factor Individual Test 2

```{r individual-sixfactor-test2}
sixfactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_endors, 
'
Level: 2 
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

')

sixfactor.individual.test2.fit <- cfa(model = sixfactor.model.test2,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.individual.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.individual.test2.fitindices <- tidy(fitmeasures(sixfactor.individual.test2.fit))
sixfactor.individual.test2.params <- tidy(sixfactor.individual.test2.fit)
```
### 6-Factor Individual Test combined

```{r individual-sixfactor-testc}
sixfactor.model.testc <- 
paste0(' 
Level: 1

D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
Level: 2 
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_13+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30

')

sixfactor.individual.testc.fit <- cfa(model = sixfactor.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.individual.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.individual.test2.fitindices <- tidy(fitmeasures(sixfactor.individual.test2.fit))
sixfactor.individual.testc.params <- tidy(sixfactor.individual.testc.fit)
```

### 6+3-Factor Individual Test combined - modified

```{r individual-six3factor-testc}
six3factor.model.testc <- 
paste0(' 
Level: 1

D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
  
Level: 2 
  D =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5+ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H =~ dhf_endors_11+dhf_endors_12+dhf_endors_14+dhf_endors_15+ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19
  F =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25+ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
')

six3factor.individual.testc.fit <- cfa(model = six3factor.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(six3factor.individual.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.individual.test2.fitindices <- tidy(fitmeasures(sixfactor.individual.test2.fit))
six3factor.individual.testc.params <- tidy(six3factor.individual.testc.fit)
```

### Comparison Individual
Tidy fitmeasures didn't work, so I've commented them out and this chunk will not run. Model comparisons were done manually. 

```{r model-comparison-individual, eval = F}
hierarchical.individual.test1.fitindices
hierarchical.individual.test2.fitindices
threefactor.individual.test1.fitindices
threefactor.individual.test2.fitindices

# if necessary
sixfactor.individual.test1.fitindices
sixfactor.individual.test2.fitindices

# pick a model based on the rules above 
```

## H1A norms


### Hierarchical norms Test 1

```{r norms-hierarchical-test1}
hierarchical.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other

  
Level: 2
', 
corr_norm)

hierarchical.norms.test1.fit <- cfa(model = hierarchical.model.test1,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    optim.method = "em"
                    # em.iter.max = 1000,
                    # em.fx.tol = 1e-08, 
                    # em.dx.tol = 1e-04
                    )
beep()

summary(hierarchical.norms.test1.fit, fit.measures = TRUE, rsquare = TRUE, standardized = TRUE)

#hierarchical.norms.test1.og.fitindices <- tidy(fitmeasures(hierarchical.norms.test1.og.fit))
hierarchical.norms.test1.params <- tidy(hierarchical.norms.test1.fit)
```


### Hierarchical norms Test 2

```{r norms-hierarchical-test2-original}
hierarchical.model.test2 <- 
paste0(' 
Level: 1', 
corr_norm, 
'
Level: 2 
  D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
  D_self ~~ 0.01*D_self
  H_other ~~ 0.01*H_other
  D_other ~~ 0.01*D_other
')

hierarchical.norms.test2.fit <- cfa(model = hierarchical.model.test2,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(hierarchical.norms.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#hierarchical.norms.test2.fitindices <- tidy(fitmeasures(hierarchical.norms.test2.fit))
hierarchical.norms.test2.params <- tidy(hierarchical.norms.test2.fit)
```
### Hierarchical norms Test combined

```{r norms-hierarchical-testc}
hierarchical.model.testc <- 
paste0(' 
Level: 1
  D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
  D_other ~~ 0.01*D_other

 
  
Level: 2
 D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
  D =~ D_self + D_other
  F =~ F_self + F_other
  H =~ H_self + H_other
  
  H_other ~~ 0.01*H_other
  D_other ~~ 0.01*D_other

')

hierarchical.model.testc.fit <- cfa(model = hierarchical.model.testc,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    optim.method = "em"
                    # em.iter.max = 1000,
                    # em.fx.tol = 1e-08, 
                    # em.dx.tol = 1e-04
                    )
beep()

summary(hierarchical.model.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#hierarchical.norms.test1.up.fitindices <- tidy(fitmeasures(hierarchical.norms.test1.up.fit))
hierarchical.model.testc.params <- tidy(hierarchical.model.testc.fit)
```

# H1B

*Hypothesis*:

H1b: The hierarchical model will fit the data better than the three-factor model. We will alternatively test a six-factor model in case the hierarchical model does not converge.

*Analysis Plan*:

norms normement and cultural norms will be tested separately. For each model, country will be used as a cluster variable.

Factor structure (see Fig. 1B): Multilevel CFA with three-factor correlated model of the DHF latent variables.

Test 1: Level 1 will include the proposed factor structure, and Level 2 will include only the saturated model where all observed variables are intercorrelated.

Test 2: Level 1 will include only the saturated model of observed variable correlations, and Level 2 will include the proposed factor structure.

*Model Evaluation*:

The model will be considered significantly better than an alternative if: - AIC is lower - BIC is lower - ΔCFI \> .010 (the model with higher CFA is better) - ΔRMSEA \> .015 (the model with lower RMSEA is better) - Chen (2007)

All these criteria will be considered together, and if the majority of them are fulfilled, the model will be considered significantly better than the alternative. If models are not significantly different from each other, the theoretically hypothesized hierarchical model will be preferred.

## Power

```{r power-comparison, eval=F}
k2 <- 558 # number of parameters in 3 factor
k3 <- 570 # number of parameters in 6 factor

df2 <- p*(p-1) - k2
df3 <- p*(p-1) - k3
semPower.aPriori(
  effect = c(.08-.015, .08),
  effect.measure = "RMSEA",
  alpha = .05, 
  power = .90, 
  df = c(df2, df)) # compare this model to the original if converge

semPower.aPriori(
  effect = c(.08-.015, .08),
  effect.measure = "RMSEA",
  alpha = .05, 
  power = .90, 
  df = c(df3, df2)) # only compare this model to three-factor
```

## H1B norms

### 3-factor norms Test 1

```{r norms-threefactor-test1}
threefactor.model.test1 <- 
paste0(' 
Level: 1
  D =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5+ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15+ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25+ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

Level: 2
', 
corr_norm)

threefactor.norms.test1.fit <- cfa(model = threefactor.model.test1,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    optim.method = "em", 
                    em.iter.max = 1000,
                    em.fx.tol = 1e-08, 
                    em.dx.tol = 1e-04
                    )

summary(threefactor.norms.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#threefactor.norms.test1.fitindices <- tidy(fitmeasures(threefactor.norms.test1.fit))
threefactor.norms.test1.params <- tidy(threefactor.norms.test1.fit)
```

### 3-Factor norms Test 2

```{r norms-threefactor-test2}
threefactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_norm, 
'
Level: 2 
   D =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5+ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
   H =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15+ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
   F =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25+ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

')

threefactor.norms.test2.fit <- cfa(model = threefactor.model.test2,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.norms.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#threefactor.norms.test2.fitindices <- tidy(fitmeasures(threefactor.norms.test2.fit))
threefactor.norms.test2.params <- tidy(threefactor.norms.test2.fit)
```
### 3-Factor norms Test combined

```{r norms-threefactor-test2}
threefactor.model.testc <- 
paste0(' 
Level: 1

D =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5+ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
   H =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15+ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
   F =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25+ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30


Level: 2 
   D =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5+ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
   H =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15+ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
   F =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25+ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

')

threefactor.norms.testc.fit <- cfa(model = threefactor.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(threefactor.norms.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#threefactor.norms.test2.fitindices <- tidy(fitmeasures(threefactor.norms.test2.fit))
threefactor.norms.testc.params <- tidy(threefactor.norms.testc.fit)
```

## H1B norms (Alternative)

### 6-factor norms Test 1

```{r norms-sixfactor-test1}
sixfactor.model.test1 <- 
paste0(' 
Level: 1
  D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

Level: 2
', 
corr_norm)

sixfactor.norms.test1.fit <- cfa(model = sixfactor.model.test1,
                    data = dt4,
                    cluster = "country_res_full",
                    # options to consider
                    optim.method = "em", 
                    em.iter.max = 1000,
                    em.fx.tol = 1e-08, 
                    em.dx.tol = 1e-04
                    )

summary(sixfactor.norms.test1.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.norms.test1.fitindices <- tidy(fitmeasures(sixfactor.norms.test1.fit))
sixfactor.norms.test1.params <- tidy(sixfactor.norms.test1.fit)
```

### 6-Factor norms Test 2

```{r norms-sixfactor-test2}
sixfactor.model.test2 <- 
paste0(' 
Level: 1', 
corr_norm, 
'
Level: 2 
  D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

')

sixfactor.norms.test2.fit <- cfa(model = sixfactor.model.test2,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.norms.test2.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.norms.test2.fitindices <- tidy(fitmeasures(sixfactor.norms.test2.fit))
sixfactor.norms.test2.params <- tidy(sixfactor.norms.test2.fit)
```
### 6-Factor norms Test combined

```{r norms-sixfactor-testc}
sixfactor.model.testc <- 
paste0(' 
Level: 1

D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
Level: 2 
  D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30

')

sixfactor.norms.testc.fit <- cfa(model = sixfactor.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(sixfactor.norms.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.norms.test2.fitindices <- tidy(fitmeasures(sixfactor.norms.test2.fit))
sixfactor.norms.testc.params <- tidy(sixfactor.norms.testc.fit)
```

### 6+3-Factor norms Test combined

```{r norms-six3factor-testc}
six3factor.model.testc <- 
paste0(' 
Level: 1

D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
Level: 2 
  D =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5+ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H =~ dhf_norm_11+dhf_norm_12+dhf_norm_13+dhf_norm_14+dhf_norm_15+ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19+dhf_norm_20
  F =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25+ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
')

six3factor.norms.testc.fit <- cfa(model = six3factor.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(six3factor.norms.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.norms.test2.fitindices <- tidy(fitmeasures(sixfactor.norms.test2.fit))
six3factor.norms.testc.params <- tidy(six3factor.norms.testc.fit)
```

### 6+3-Factor norms Test combined - modified
#removing dhf_norm_13

```{r norms-six3factor-testc}
six3factor.model.testc <- 
paste0(' 
Level: 1

D_self =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5
  D_other =~ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H_self =~ dhf_norm_11+dhf_norm_12+dhf_norm_14+dhf_norm_15
  H_other =~ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19
  F_self =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25
  F_other =~ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
  
Level: 2 
  D =~ dhf_norm_1+dhf_norm_2+dhf_norm_3+dhf_norm_4+dhf_norm_5+ dhf_norm_6+dhf_norm_7+dhf_norm_8+dhf_norm_9+dhf_norm_10
  H =~ dhf_norm_11+dhf_norm_12+dhf_norm_14+dhf_norm_15+ dhf_norm_16+dhf_norm_17+dhf_norm_18+dhf_norm_19
  F =~ dhf_norm_21+dhf_norm_22+dhf_norm_23+dhf_norm_24+dhf_norm_25+ dhf_norm_26+dhf_norm_27+dhf_norm_28+dhf_norm_29+dhf_norm_30
')

six3factor.norms.testc.fit <- cfa(model = six3factor.model.testc,
                    data = dt4,
                    cluster = "country_res_full"
                    # options to consider
                    #optim.method = "em", 
                    #em.iter.max = 1000
                    #em.fx.tol = 1e-08, 
                    #em.dx.tol = 1e-04
                    )

summary(six3factor.norms.testc.fit,
        fit.measures = TRUE,
        rsquare = TRUE,
        standardized = TRUE)

#sixfactor.norms.test2.fitindices <- tidy(fitmeasures(sixfactor.norms.test2.fit))
six3factor.norms.testc.params <- tidy(six3factor.norms.testc.fit)
```

### Comparison Norms
Tidy fitmeasures didn't work, so I've commented them out and this chunk will not run. Model comparisons were done manually. 

```{r model-comparison-norms, eval = F}
hierarchical.norms.test1.fitindices
hierarchical.norms.test2.fitindices
threefactor.norms.test1.fitindices
threefactor.norms.test2.fitindices

# if necessary
sixfactor.norms.test1.fitindices
sixfactor.norms.test2.fitindices

# pick a model based on the rules above 
```

# Model Improvement

*Hypothesis*:

See hypotheses above.

*Analysis Plan*:

The final model will be examined for: - Poorly loading items. - Modification indices. - Model fit. - Group alignment.

*Model Evaluation*:

Item evaluation:

-   If a given item does not significantly load on the respective factor AND the model fit improves after removing the item, or the item loads in the opposite to expected direction, the items will be removed. Otherwise, the item will be retained.
-   If modification indices suggest a strong residual correlation between items AND this correlation is theoretically justified, a residual correlation will be added.

Model evaluation:

-   We will consider the model to have a good fit to the data if RMSEA \< .08 and SRMR_within \< .08. If ICC \< .10, we will additionally use CFI \> .90, and SRMR_between \< .08 as criteria.
-   If .08 \< RMSEA \< .10, .08 \< SRMR \< .10, and .85 \< CFI \< .90, we will consider the model acceptable, unless there are specific issues with items as described above.
-   If RMSEA \> .10, SRMR \> .10, CFI \< .85, we will consider the model unacceptable.

All model fit indices will be considered together, and if the majority of indices suggest acceptable fit, a single indicator will not be considered sufficient to reject the model.

## Model Improvement: Individual
#see above
```{r individual-model-improve, eval = F}
# we will examine the parameters to ensure they are significant
# if one is poor remove and retest model fit 
  # remove if poor AND model fit goes up
# remove items with negative loadings 
# only do this for the final chosen model 

# for example 
hierarchical.individual.test1.fit

# examine modification indices
modificationindices(hierarchical.individual.test1.fit)

# examine new model fits
  # rerun models as above
  # check the fit outputs 
hierarchical.individual.test1.fitindices
```

## Model Improvement: Norms
#see above
```{r norms-model-improve, eval = F}
# we will examine the parameters to ensure they are significant
# if one is poor remove and retest model fit 
  # remove if poor AND model fit goes up
# remove items with negative loadings 
# only do this for the final chosen model 

# for example 
hierarchical.norms.test1.fit

# examine modification indices
modificationindices(hierarchical.norms.test1.fit)

# examine new model fits
  # rerun models as above
  # check the fit outputs 
hierarchical.norms.test1.fitindices
```

# Alignment Procedure

#Analysis conducted in MPlus

## Individual

```{r alignment-individual, eval=F}
# testing just the three factor structure with level 1 only to show how this procedure works 
sixfactor.align.model <- '
  D_self =~ dhf_endors_1+dhf_endors_2+dhf_endors_3+dhf_endors_4+dhf_endors_5
  D_other =~ dhf_endors_6+dhf_endors_7+dhf_endors_8+dhf_endors_9+dhf_endors_10
  H_self =~ dhf_endors_11+dhf_endors_12+dhf_endors_14+dhf_endors_15
  H_other =~ dhf_endors_16+dhf_endors_17+dhf_endors_18+dhf_endors_19+dhf_endors_20
  F_self =~ dhf_endors_21+dhf_endors_22+dhf_endors_23+dhf_endors_24+dhf_endors_25
  F_other =~ dhf_endors_26+dhf_endors_27+dhf_endors_28+dhf_endors_29+dhf_endors_30
'

 temp <- cfa(model = sixfactor.align.model,
             data = dt4.1,
             group="country_res_full",
             control = list(iter.max = 20000, rel.tol = 1e-4),
             estimator = "MLR")

 summary(temp, standardized = TRUE)

#filter only countries with N>=100

dt4.1 <- dt4 %>%
  group_by(country_res_full) %>%
  filter(!is.na(country_res_full) & n() >= 100) %>%
  ungroup() %>%
  mutate(country_res_full = droplevels(country_res_full))
table(dt4.1$country_res_full)

# calculate MGCFA
sixfactor.mgcfa.fit <- mgcfa(
  model = sixfactor.align.model,
  data = dt4.1, 
  group = "country_res_full",
  group.equal = c("loadings", "intercepts"),
  check.gradient = FALSE,
  #orthogonal = TRUE
)

summary(sixfactor.mgcfa.fit)
summary(sixfactor.mgcfa.fit$model_overall)
summary(sixfactor.mgcfa.fit$model_configural)
sixfactor.mgcfa.fit$model_fit

# extract item parameters separate group analyses
ipars <- lavaan::parameterEstimates(hierarchical.mgcfa.fit$model_configural)
# extract lambda's: groups are in rows, items in columns
# nrow is the number of groups
lambda <- matrix(ipars[ ipars$op=="=~", "est"], 
                  nrow = 2, byrow = TRUE)
colnames(lambda) <- ipars[ ipars$op=="=~", "rhs"][1:(length(ipars[ ipars$op=="=~", "rhs"])/2)]
# extract nu's
nu <- matrix( ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ], 
              nrow = 2,  byrow = TRUE)
colnames(nu) <- ipars[ ipars$op=="~1"  & ipars$se !=0, "lhs" ][1:(length(ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ])/2)]

Ng <-  unlist(hierarchical.mgcfa.fit$model_configural@SampleStats@nobs)
wgt <- matrix( sqrt(Ng), length(Ng), ncol(nu) )

mod1 <- sirt::invariance.alignment(lambda, nu, wgt, align.pow=c(2,2))
summary(mod1)
```

## Norms

```{r alignment-norms, eval=F}
# testing just the three factor structure with level 1 only to show how this procedure works 
hierarchical.align.model <- '
  D =~ D_self1+D_self2+D_self3+D_self4+D_self5+D_other1+
  D_other2+D_other3+D_other4+D_other5
  F =~ F_self1+F_self2+F_self3+F_self4+F_self5+
  F_other1+F_other2+F_other3+F_other4+F_other5
  H =~ H_self1+H_self2+H_self3+H_self4+H_self5+
  H_other1+H_other2+H_other3+H_other4+H_other5
'

# temp <- cfa(model = hierarchical.align.model,
#             data = DF_norms,
#             orthogonal = TRUE)
# summary(temp, standardized = TRUE)

# calculate MGCFA
hierarchical.mgcfa.fit <- mgcfa(
  model = hierarchical.align.model,
  data = DF_norms, 
  group = "country",
  group.equal = c("loadings", "intercepts"),
  check.gradient = FALSE,
  orthogonal = TRUE
)

summary(hierarchical.mgcfa.fit$model_overall)
summary(hierarchical.mgcfa.fit$model_configural)
hierarchical.mgcfa.fit$model_fit

# extract item parameters separate group analyses
ipars <- lavaan::parameterEstimates(hierarchical.mgcfa.fit$model_configural)
# extract lambda's: groups are in rows, items in columns
# nrow is the number of groups
lambda <- matrix(ipars[ ipars$op=="=~", "est"], 
                  nrow = 2, byrow = TRUE)
colnames(lambda) <- ipars[ ipars$op=="=~", "rhs"][1:(length(ipars[ ipars$op=="=~", "rhs"])/2)]
# extract nu's
nu <- matrix( ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ], 
              nrow = 2,  byrow = TRUE)
colnames(nu) <- ipars[ ipars$op=="~1"  & ipars$se !=0, "lhs" ][1:(length(ipars[ ipars$op=="~1"  & ipars$se !=0, "est" ])/2)]

Ng <-  unlist(hierarchical.mgcfa.fit$model_configural@SampleStats@nobs)
wgt <- matrix( sqrt(Ng), length(Ng), ncol(nu) )


mod1 <- sirt::invariance.alignment(lambda, nu, wgt, align.pow=c(2,2))
summary(mod1)
```

# H2

*Hypothesis*:

H2: The individual endorsement of the other-concern facet of all three cultural logics will predict more prosocial behavior.

*Analysis Plan*:

A multilevel model predicting prosociality from six or three cultural logic indices (depending on the best fitting model in H1b) with random intercept for country.

All individual-level predictors will be group-mean centered (level 1), and all sample-level predictors will be grand-mean centered (level 2).

*Evaluation*:

A significant positive effect (p \< .05) of the other-concern facet of each cultural logic will support the hypotheses. Significant effects for some but no effect for other other-facets will be interpreted as partial support for the hypothesis. Null effects for any or negative effects for some will be interpreted as evidence against the hypothesis.

If the 3-factor model is used (dignity, honor, face), the test will be exploratory.

## DHF indices

DHF indices will be calculated based on the best performing model for each level. Individual-level DHF endorsement scores will be calculated as averages of individual endorsement items, and country-level DHF norms scores will be calculated as averages of norms items, aggregated at country level (see below for H3).

```{r h2-data-simulation}
#calculate participant means for DHF endorsement
dt4 <- dt4  %>% 
  mutate(
    D_self_end = rowMeans(select(.,dhf_endors_1:dhf_endors_5), na.rm=T),
    D_other_end = rowMeans(select(.,dhf_endors_6:dhf_endors_10),na.rm=T),
    H_self_end = rowMeans(select(.,dhf_endors_11:dhf_endors_15),na.rm=T),
    H_other_end = rowMeans(select(.,dhf_endors_16:dhf_endors_20),na.rm=T),
    F_self_end = rowMeans(select(.,dhf_endors_21:dhf_endors_25),na.rm=T),
    F_other_end = rowMeans(select(.,dhf_endors_26:dhf_endors_30),na.rm=T),
    D_end = rowMeans(select(.,dhf_endors_1:dhf_endors_10),na.rm=T),
    H_end = rowMeans(select(.,dhf_endors_11:dhf_endors_20),na.rm=T),
    F_end = rowMeans(select(.,dhf_endors_21:dhf_endors_30),na.rm=T)
  )


#endorsement corrected for response style (within-participant centering)

dt4 <- dt4  %>% 
  mutate(dhf_endors_mean = rowMeans(select(.,dhf_endors_1:dhf_endors_30), na.rm=T))

dt4 <- dt4  %>% 
  mutate(
    D_self_endc = D_self_end - dhf_endors_mean,
    D_other_endc = D_other_end - dhf_endors_mean,
    H_self_endc = H_self_end - dhf_endors_mean,
    H_other_endc = H_other_end - dhf_endors_mean,
    F_self_endc = F_self_end - dhf_endors_mean,
    F_other_endc = F_other_end - dhf_endors_mean,
    D_endc = D_end - dhf_endors_mean,
    H_endc = H_end - dhf_endors_mean,
    F_endc = F_end - dhf_endors_mean,
  )

#calculate country means for endorsement
country_endors <- dt4 %>%
  group_by(country_res_full) %>%
  summarize(
    across(
      c(D_self_end, D_other_end, H_self_end, H_other_end, F_self_end, F_other_end, D_end, H_end, F_end, D_self_endc, D_other_endc, H_self_endc, H_other_endc, F_self_endc, F_other_endc, D_endc, H_endc, F_endc),
      ~mean(., na.rm = TRUE),
      .names = "{.col}_mean_country"
    )
  )


dt4 <- dt4 %>%
  left_join(country_endors, by = "country_res_full")


#calculate participant means for DHF norms

dt4 <- dt4  %>% 
  mutate(
    D_self_norm = rowMeans(select(.,dhf_norm_1:dhf_norm_5), na.rm=T),
    D_other_norm = rowMeans(select(.,dhf_norm_6:dhf_norm_10),na.rm=T),
    H_self_norm = rowMeans(select(.,dhf_norm_11:dhf_norm_15),na.rm=T),
    H_other_norm = rowMeans(select(.,dhf_norm_16:dhf_norm_20),na.rm=T),
    F_self_norm = rowMeans(select(.,dhf_norm_21:dhf_norm_25),na.rm=T),
    F_other_norm = rowMeans(select(.,dhf_norm_26:dhf_norm_30),na.rm=T),
    D_norm = rowMeans(select(.,dhf_norm_1:dhf_norm_10),na.rm=T),
    H_norm = rowMeans(select(.,dhf_norm_11:dhf_norm_20),na.rm=T),
    F_norm = rowMeans(select(.,dhf_norm_21:dhf_norm_30),na.rm=T)
  )


#norms corrected for response style (within-participant centering)

dt4 <- dt4  %>% 
  mutate(dhf_norm_mean = rowMeans(select(.,dhf_norm_1:dhf_norm_30), na.rm=T))

dt4 <- dt4  %>% 
  mutate(
    D_self_normc = D_self_norm - dhf_norm_mean,
    D_other_normc = D_other_norm - dhf_norm_mean,
    H_self_normc = H_self_norm - dhf_norm_mean,
    H_other_normc = H_other_norm - dhf_norm_mean,
    F_self_normc = F_self_norm - dhf_norm_mean,
    F_other_normc = F_other_norm - dhf_norm_mean,
    D_normc = D_norm - dhf_norm_mean,
    H_normc = H_norm - dhf_norm_mean,
    F_normc = F_norm - dhf_norm_mean,
  )

#calculate country means for norms
country_norm <- dt4 %>%
  group_by(country_res_full) %>%
  summarize(
    across(
      c(D_self_norm, D_other_norm, H_self_norm, H_other_norm, F_self_norm, F_other_norm, D_norm, H_norm, F_norm, D_self_normc, D_other_normc, H_self_normc, H_other_normc, F_self_normc, F_other_normc, D_normc, H_normc, F_normc),
      ~mean(., na.rm = TRUE),
      .names = "{.col}_mean_country"
    )
  )


dt4 <- dt4 %>%
  left_join(country_norm, by = "country_res_full")

norm_D <- ggplot(country_norm, aes(x = D_norm_mean_country, y = reorder(country_res_full, D_norm_mean_country))) + geom_col(fill = "steelblue", color = "white", alpha = 0.8)

norm_Dc <-ggplot(country_norm, aes(x = D_normc_mean_country, y = reorder(country_res_full, D_normc_mean_country))) + geom_col(fill = "steelblue", color = "white", alpha = 0.8)

norm_H <- ggplot(country_norm, aes(x = H_norm_mean_country, y = reorder(country_res_full, H_norm_mean_country))) + geom_col(fill = "steelblue", color = "white", alpha = 0.8)

norm_Hc <-ggplot(country_norm, aes(x = H_normc_mean_country, y = reorder(country_res_full, H_normc_mean_country))) + geom_col(fill = "steelblue", color = "white", alpha = 0.8)

norm_F <- ggplot(country_norm, aes(x = F_norm_mean_country, y = reorder(country_res_full, F_norm_mean_country))) + geom_col(fill = "steelblue", color = "white", alpha = 0.8)

norm_Fc <-ggplot(country_norm, aes(x = F_normc_mean_country, y = reorder(country_res_full, F_normc_mean_country))) + geom_col(fill = "steelblue", color = "white", alpha = 0.8)

```

###correlations with country-level indicators


```{r country-level corrs}

library(apaTables)

dt4$cluster <- recode_factor(dt4$country_res_full, 
                             "Argentina" = "Latin America",
                             "Brazil" = "Latin America",
                             "Chile" = "Latin America",
                             "Mexico" = "Latin America",
                             "Armenia" = "Eastern Europe",
                             "Bosnia-Herzegovina" = "Eastern Europe",
                             "Bulgaria" = "Eastern Europe",
                             "Croatia" = "Eastern Europe",
                             "Czech Republic" = "Eastern Europe",
                             "Georgia" = "Eastern Europe",
                             "Greece" = "Eastern Europe",
                             "Hungary" = "Eastern Europe",
                             "Kosovo" = "Eastern Europe",
                             "North Macedonia" = "Eastern Europe",
                             "Poland" = "Eastern Europe",
                             "Russia" = "Eastern Europe",
                             "Serbia" = "Eastern Europe",
                             "Slovakia" = "Eastern Europe",
                             "Kazakhstan" = "Eastern Europe",
                             "Ukraine" = "Eastern Europe",
                             "Australia" = "Anglo-Saxon",
                             "Canada" = "Anglo-Saxon",
                             "New Zealand" = "Anglo-Saxon",
                             "Ireland" = "Anglo-Saxon",
                             "United Kingdom" = "Anglo-Saxon",
                             "United States" = "Anglo-Saxon",
                             "Austria" = "Germanic",
                             "Germany" = "Germanic",
                             "Switzerland" = "Germanic",
                             "The Netherlands" = "Germanic",
                             "Bangladesh" = "South-East Asia",
                             "India" = "South-East Asia",
                             "Indonesia" = "South-East Asia",
                             "Iran" = "South-East Asia",
                             "Malaysia" = "South-East Asia",
                             "Pakistan" = "South-East Asia",
                             "Philippines" = "South-East Asia",
                             "Thailand" = "South-East Asia",
                             "Cameroon" = "Africa",
                             "Ethiopia" = "Africa",
                             "Kenya" = "Africa",
                             "Namibia" = "Africa",
                             "Nigeria" = "Africa",
                             "South Africa" = "Africa",
                             "Ghana" = "Africa",
                             "China" = "Confucian",
                             "Japan" = "Confucian",
                             "Singapore" = "Confucian",
                             "Hong Kong" = "Confucian",
                             "Taiwan" = "Confucian",
                             "Vietnam" = "Confucian",
                             "France" = "Latin Europe",
                             "Israel" = "Latin Europe",
                             "Italy" = "Latin Europe",
                             "Portugal" = "Latin Europe",
                             "Romania" = "Latin Europe",
                             "Spain" = "Latin Europe",
                             "Kuwait" = "Middle East",
                             "Morocco" = "Middle East",
                             "Saudi Arabia" = "Middle East",
                             "Lebanon" = "Middle East",
                             "Turkey" = "Middle East",
                             "Uzbekistan" = "Middle East",
                             "United Arab Emirates" = "Middle East")
table(dt4$cluster)

summary_table <- dt4 %>%
  group_by(cluster) %>%
  summarise(across(c(D_endc, H_endc, F_endc, D_normc, H_normc, F_normc), 
                   list(mean = mean, sd = sd), na.rm=TRUE))
write.csv(summary_table, "summary_table.csv")

dt4 %>%
  summarize(across(c(D_self_normc, D_other_normc, H_self_normc, H_other_normc, F_self_normc, F_other_normc), ~mean(., na.rm = TRUE)))

dt4 %>%
  summarize(across(c(D_self_endc, D_other_endc, H_self_endc, H_other_endc, F_self_endc, F_other_endc), ~mean(., na.rm = TRUE)))

dtc <- dt4[,-c(299:1109)]
dtc <- dtc[,c("country_res_full", "D_normc_mean_country", "H_normc_mean_country", "F_normc_mean_country", "D_endc_mean_country", "H_endc_mean_country", "F_endc_mean_country")]
dtc <- dtc %>%
  distinct(country_res_full, .keep_all = TRUE)

country_data <- import("dhf_countries_dataset.xlsx - DHF_Countries_Data.csv")

describe(country_data$wb_pop_density_1961) #population density in 1961, n=54
describe(country_data$ms_pathogen_9items) #historic pathogen prevalence, n=64
describe(country_data$icb_crisis_participations) #n of crisis, n=35
describe(country_data$icb_avg_violence_level) #average level of violence, n=35
describe(country_data$wb_gdp_pcap_usd_1960) #gdp pc in 1960, n=37
describe(country_data$fiw_F_2013) #Freedom house_Rule of law in 2013, n=67
describe(country_data$fiw_C_2013) #FH_Functioning of government 2013, n=67
describe(country_data$fiw_Total_2013) #FH_total 2013, n=67

historic <- merge(dtc, country_data[,c("dhf_country_name","wb_pop_density_1961", "ms_pathogen_9items", "icb_crisis_participations", "icb_avg_violence_level", "wb_gdp_pcap_usd_1960", "fiw_F_2013", "fiw_C_2013", "fiw_Total_2013")], by.x="country_res_full", by.y="dhf_country_name")


apa.cor.table(historic, "cor_historic.doc")

describe(country_data$wb_gdp_pcap_usd_most_recent) #GDP most recent available n=66
describe(country_data$gii_value_2021) #gender inequality, n=65
describe(country_data$wb_gini_2020) #income inequality 2020, n=33
describe(country_data$fiw_Total_2023) #FH_total 2023, n=67
describe(country_data$hdi_value_2021) #human development index, n=2021

modern <- merge(dtc, country_data[,c("dhf_country_name","wb_gdp_pcap_usd_most_recent", "gii_value_2021", "wb_gini_2020", "fiw_Total_2023", "hdi_value_2021")], by.x="country_res_full", by.y="dhf_country_name")

apa.cor.table(modern, "cor_modern.doc")

dtc <- dt4[,-c(299:1109)]

values_country <- dtc %>%
  group_by(country_res_full) %>%
  summarize(across(c(Openness_to_Change, Conservation, Self_Transcendence, Self_Enhancement), ~mean(., na.rm = TRUE), .names = "{.col}_mean_country"))


dtc <- dtc %>%
  left_join(values_country, by = "country_res_full")

dtc <- dtc[,c("country_res_full", "D_normc_mean_country", "H_normc_mean_country", "F_normc_mean_country", "D_endc_mean_country", "H_endc_mean_country", "F_endc_mean_country", "Openness_to_Change_mean_country", "Conservation_mean_country", "Self_Transcendence_mean_country", "Self_Enhancement_mean_country")]
dtc <- dtc %>%
  distinct(country_res_full, .keep_all = TRUE)

describe(country_data$tl_tightness) #tightness-loosness, n=42
describe(country_data$mk_individualism_collectivism) #ind-coll, n=61
describe(country_data$mk_flexibility_monumentalism) #flex-monument, n=61
describe(country_data$rm_relational_mobility) #relational mobility, n=26

cultural <- merge(dtc, country_data[,c("dhf_country_name","tl_tightness", "mk_individualism_collectivism", "mk_flexibility_monumentalism", "rm_relational_mobility")], by.x="country_res_full", by.y="dhf_country_name")

cultural$"o-c" <- cultural$Openness_to_Change_mean_country-cultural$Conservation_mean_country
cultural$"st-se" <- cultural$Self_Transcendence_mean_country-cultural$Self_Enhancement_mean_country

apa.cor.table(cultural, "cor_cult.doc")


```

### visualization of country means for DHF norms (Shuxian)

```{r h2-visualization-dotplot-noncentered}
#### Cleveland dot plot of Honor/Face/Dignity norms by country (non-centered)

# 1) Reshape to long format (one row per country × dimension)
df_long <- country_norm %>%
  select(
    country_res_full,
    Honor   = H_norm_mean_country,
    Face    = F_norm_mean_country,
    Dignity = D_norm_mean_country
  ) %>%
  pivot_longer(Honor:Dignity, names_to = "Dimension", values_to = "Score")

# 2) Choose how to order countries on the y-axis
#    Option A: by overall mean across the 3 dimensions (lowest → highest)
country_order <- df_long %>%
  group_by(country_res_full) %>%
  summarise(mean_score = mean(Score, na.rm = TRUE), .groups = "drop") %>%
  arrange(mean_score) %>%
  pull(country_res_full)

#    (Alternative)
#    # Option B: by Honor only
#    country_order <- df_long %>% filter(Dimension == "Honor") %>%
#      arrange(Score) %>% pull(country_res_full)
#
#    # Option C: alphabetical
#    country_order <- sort(unique(df_long$country_res_full))

# 3) Apply the order so ggplot respects it
df_long$country_res_full <- factor(df_long$country_res_full, levels = country_order)

# 4) Precompute per-country ranges (min→max across the three dimensions)
ranges <- df_long %>%
  group_by(country_res_full) %>%
  summarise(
    xmin = min(Score, na.rm = TRUE),
    xmax = max(Score, na.rm = TRUE),
    .groups = "drop"
  )

# 5) Plot
p <- ggplot() +
  # grey range bars (min→max per country)
  geom_segment(
    data = ranges,
    aes(x = xmin, xend = xmax, y = country_res_full, yend = country_res_full),
    color = "grey70",
    linewidth = 0.4
  ) +
  # colored points for the three dimensions
  geom_point(
    data = df_long,
    aes(x = Score, y = country_res_full, color = Dimension),
    size = 2.5, alpha = 0.8,
    # Use small vertical jitter if overlapping points are an issue; keep width at 0 for x
    position = position_jitter(height = 0, width = 0)
    # If you prefer perfectly aligned dots, use: position = position_identity()
  ) +
  # Color palette: Dark2 is colorblind-friendly; remove legend title
  scale_color_brewer(palette = "Dark2", name = NULL) +
  labs(x = "Societal mean (1-7)", y = NULL, title = NULL) +
  # Minimal theme + enforce true white background
  theme_minimal(base_size = 12) +
  theme(
    panel.background    = element_rect(fill = "white", color = NA),
    plot.background     = element_rect(fill = "white", color = NA),
    panel.grid.major.y  = element_blank(),     # cleaner y axis
    axis.text.y         = element_text(size = 10),
    legend.position     = "top"
  )

p

# 6) Save
#    Adjust height if you have many countries (more rows → more height).
ggsave(
  filename = "DHF_Norms_dotplot_noncentered.png",
  plot = p,
  width = 9, height = 14, dpi = 600
)

# Vector version for journals (crisp text/lines):
ggsave(
  filename = "DHF_Norms_dotplot_noncentered.pdf",
  plot = p,
  width = 9, height = 14
)
```

```{r h2-visualization-dotplot}
#### Cleveland dot plot of Honor/Face/Dignity norms by country (non-centered & centered)

# 1) Long data for NON-centered
df_nc <- country_norm %>%
  select(
    country_res_full,
    Honor   = H_norm_mean_country,
    Face    = F_norm_mean_country,
    Dignity = D_norm_mean_country
  ) %>%
  pivot_longer(Honor:Dignity, names_to = "Dimension", values_to = "Score") %>%
  mutate(Centering = "Non-centered")

# 2) Long data for CENTERED (same dimension names)
df_c <- country_norm %>%
  select(
    country_res_full,
    Honor   = H_normc_mean_country,
    Face    = F_normc_mean_country,
    Dignity = D_normc_mean_country
  ) %>%
  pivot_longer(Honor:Dignity, names_to = "Dimension", values_to = "Score") %>%
  mutate(Centering = "Centered")

# 3) Combine + set factor orders
df_both <- bind_rows(df_nc, df_c) %>%
  mutate(
    Dimension = factor(Dimension, levels = c("Honor","Face","Dignity")),
    Centering = factor(Centering, levels = c("Non-centered","Centered"))
  )

# 4) Fix a single country order (so both facets share the same y-axis)
#    Here: order by the NON-centered average across the 3 dimensions (intuitive baseline)
country_order <- df_nc %>%
  group_by(country_res_full) %>%
  summarise(mean_score = mean(Score, na.rm = TRUE), .groups = "drop") %>%
  arrange(mean_score) %>%
  pull(country_res_full)

df_both$country_res_full <- factor(df_both$country_res_full, levels = country_order)

# 5) (Optional) draw per-country range segments across the 3 dimensions *within each facet*
ranges <- df_both %>%
  group_by(Centering, country_res_full) %>%
  summarise(
    xmin = min(Score, na.rm = TRUE),
    xmax = max(Score, na.rm = TRUE),
    .groups = "drop"
  )

# 6) Plot: one panel per Centering; dots colored by Dimension
set.seed(123)  # reproducible jitter

p <- ggplot() +
  # grey connector showing spread across the three dimensions for each country in each facet
  geom_segment(
    data = ranges,
    aes(x = xmin, xend = xmax, y = country_res_full, yend = country_res_full),
    color = "grey70", linewidth = 0.4
  ) +
  # three dots per country (Honor/Face/Dignity)
  geom_point(
    data = df_both,
    aes(x = Score, y = country_res_full, color = Dimension),
    size = 2.5, alpha = 0.75,
    position = position_jitter(height = 0, width = 0)  # small vertical separation
  ) +
  facet_wrap(~ Centering, nrow = 1, scales = "free_x") +  # free_x lets centered vs non-centered have their own scales
  scale_color_brewer(palette = "Dark2", name = NULL) +
  labs(x = "Societal mean (1-7)", y = NULL, title = NULL) +
  theme_minimal(base_size = 12) +
  theme(
    panel.background   = element_rect(fill = "white", color = NA),
    plot.background    = element_rect(fill = "white", color = NA),
    panel.grid.major.y = element_blank(),
    axis.text.y        = element_text(size = 10),
    legend.position    = "top"
  )

p

# 7) Save (increase height for many countries)
ggsave("DHF_Norms_dotplot.png", p,
       width = 18, height = 14, dpi = 600)
ggsave("DHF_Norms_dotplot.pdf", p,
       width = 18, height = 14)
```

```{r h2-visualization-worldmap-noncentered}
#### World map of Honor/Face/Dignity norms (non-centered scores)
# --- Packages ---
library(sf)
library(rnaturalearth)
library(viridis)     # palette family; 'C' for non-centered, 'D' for centered (distinct look)
library(patchwork)

# --- 1) World polygons (drop Antarctica for cleaner view) ---
# Uses Natural Earth country names for joining. Currently in geographic (WGS84) CRS.
# If you want Robinson, add: world <- st_transform(world, "+proj=robin") after this block.
world <- ne_countries(scale = "medium", returnclass = "sf") |>
  select(name, geometry) |>
  filter(name != "Antarctica")

# --- 2) Rename and recode to EXACT Natural Earth names ---
# Harmonize your dataset's country labels to match Natural Earth.
# Add more entries to recode() as mismatches arise.
country_data <- country_norm |>
  transmute(
    name    = country_res_full,
    Honor   = H_norm_mean_country,
    Face    = F_norm_mean_country,
    Dignity = D_norm_mean_country
  ) |>
  mutate(
    name = dplyr::recode(
      name,
      "Bosnia-Herzegovina" = "Bosnia and Herzegovina",
      "Czech Republic"     = "Czechia",
      "The Netherlands"    = "Netherlands",
      "United States"      = "United States of America"
    )
  )

# --- 3) Join to polygons ---
# Left join keeps all polygons; countries without data will map as NA (filled by na.value).
world_join <- world |> left_join(country_data, by = "name")

# (Optional) quickly see if any still unmatched
# Use this to catch remaining naming issues and extend recode() above.
# anti_join(country_data, st_drop_geometry(world), by = "name") |> distinct(name)

# --- 4) Long form + consistent limits across facets (so colors are comparable) ---
# Non-centered scores: keep a single limit across all three to make colors comparable row-wise.
world_long <- world_join |>
  select(geometry, Honor, Face, Dignity) |>
  pivot_longer(c(Honor, Face, Dignity),
               names_to = "Dimension", values_to = "Score") |>
  mutate(Dimension = factor(Dimension, levels = c("Honor","Face","Dignity")))

# Set limits explicitly for reproducibility; alternatively use range(world_long$Score, na.rm=TRUE).
lims <- c(3,5.5) # range(world_long$Score, na.rm = TRUE)

# --- 5) Plot: titles centered, thin white borders, compact legend ---
# Apply the same basic theme to all six maps; legends will later be collected per row.
common_theme <- theme(
  plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
  legend.position = "bottom",
  legend.title = element_text(size = 10),
  legend.text  = element_text(size = 9)
)

# Non-centered maps (viridis option "C")
p_honor <- ggplot(filter(world_long, Dimension == "Honor")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean (1-7)", option = "D",
                     limits = lims, na.value = "grey92", direction = -1) +
  labs(title = "Honor norms") +
  theme_void() +
  common_theme

p_face <- ggplot(filter(world_long, Dimension == "Face")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean (1-7)", option = "D",
                     limits = lims, na.value = "grey92", direction = -1) +
  labs(title = "Face norms") +
  theme_void() +
  common_theme

p_dignity <- ggplot(filter(world_long, Dimension == "Dignity")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean (1-7)", option = "D",
                     limits = lims, na.value = "grey92", direction = -1) +
  labs(title = "Dignity norms") +
  theme_void() +
  common_theme

# ---- build plot for non-centered scores only ----
p <- (p_honor | p_face | p_dignity) +
  plot_layout(guides = "collect") &
  theme(
    legend.position  = "bottom"
  )
p

# Export plot
ggsave("DHF_Norms_worldmap_noncentered.png", p,
       width = 18, height = 4, dpi = 600)
ggsave("DHF_Norms_worldmap_noncentered.pdf", p,
       width = 18, height = 4)
```

```{r h2-visualization-worldmap}
#### World map of Honor/Face/Dignity norms
# --- Packages ---
library(sf)
library(rnaturalearth)
library(viridis)     # palette family; 'C' for non-centered, 'D' for centered (distinct look)
library(patchwork)

# --- 1) World polygons (drop Antarctica for cleaner view) ---
# Uses Natural Earth country names for joining. Currently in geographic (WGS84) CRS.
# If you want Robinson, add: world <- st_transform(world, "+proj=robin") after this block.
world <- ne_countries(scale = "medium", returnclass = "sf") |>
  select(name, geometry) |>
  filter(name != "Antarctica")

# --- 2) Rename and recode to EXACT Natural Earth names ---
# Harmonize your dataset's country labels to match Natural Earth.
# Add more entries to recode() as mismatches arise.
country_data <- country_norm |>
  transmute(
    name    = country_res_full,
    Honor   = H_norm_mean_country,
    Face    = F_norm_mean_country,
    Dignity = D_norm_mean_country,
    HonorC   = H_normc_mean_country,
    FaceC    = F_normc_mean_country,
    DignityC = D_normc_mean_country
  ) |>
  mutate(
    name = dplyr::recode(
      name,
      "Bosnia-Herzegovina" = "Bosnia and Herzegovina",
      "Czech Republic"     = "Czechia",
      "The Netherlands"    = "Netherlands",
      "United States"      = "United States of America"
    )
  )

country_data_e <- country_endors |>
  transmute(
    name    = country_res_full,
    Honore   = H_end_mean_country,
    Facee    = F_end_mean_country,
    Dignitye = D_end_mean_country,
    HonoreC   = H_endc_mean_country,
    FaceeC    = F_endc_mean_country,
    DignityeC = D_endc_mean_country
  ) |>
  mutate(
    name = dplyr::recode(
      name,
      "Bosnia-Herzegovina" = "Bosnia and Herzegovina",
      "Czech Republic"     = "Czechia",
      "The Netherlands"    = "Netherlands",
      "United States"      = "United States of America"
    )
  )

# --- 3) Join to polygons ---
# Left join keeps all polygons; countries without data will map as NA (filled by na.value).
world_join <- world |> left_join(country_data, by = "name")
world_join <- world_join |> left_join(country_data_e, by = "name")

# (Optional) quickly see if any still unmatched
# Use this to catch remaining naming issues and extend recode() above.
# anti_join(country_data, st_drop_geometry(world), by = "name") |> distinct(name)

# --- 4) Long form + consistent limits across facets (so colors are comparable) ---
# Non-centered scores: keep a single limit across all three to make colors comparable row-wise.
world_long <- world_join |>
  select(geometry, Honor, Face, Dignity) |>
  pivot_longer(c(Honor, Face, Dignity),
               names_to = "Dimension", values_to = "Score") |>
  mutate(Dimension = factor(Dimension, levels = c("Honor","Face","Dignity")))

# Set limits explicitly for reproducibility; alternatively use range(world_long$Score, na.rm=TRUE).
lims <- c(3,5.5) # range(world_long$Score, na.rm = TRUE)

# Centered scores: keep them separate (different palette/legend) and use symmetric limits if possible.
world_long_centered <- world_join |>
  select(geometry, HonorC, FaceC, DignityC) |>
  pivot_longer(c(HonorC, FaceC, DignityC),
               names_to = "Dimension", values_to = "Score") |>
  mutate(Dimension = factor(Dimension, levels = c("HonorC","FaceC","DignityC")))
#add endorsement
world_long_end <- world_join |>
  select(geometry, HonoreC, FaceeC, DignityeC) |>
  pivot_longer(c(HonoreC, FaceeC, DignityeC),
               names_to = "Dimension", values_to = "Score") |>
  mutate(Dimension = factor(Dimension, levels = c("HonoreC","FaceeC","DignityeC")))

# Prefer symmetric bounds around 0 for interpretability (edit as needed).
limsc <- c(-1,1.3) # range(world_long_centered$Score, na.rm = TRUE)

# --- 5) Plot: titles centered, thin white borders, compact legend ---
# Apply the same basic theme to all six maps; legends will later be collected per row.
common_theme <- theme(
  plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
  legend.position = "bottom",
  legend.title = element_text(size = 10),
  legend.text  = element_text(size = 9)
)

# Non-centered maps (viridis option "C")
p_honor <- ggplot(filter(world_long, Dimension == "Honor")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean (1-7)", option = "D",
                     limits = lims, na.value = "grey92", direction = -1) +
  labs(title = "Honor norms") +
  theme_void() +
  common_theme

p_face <- ggplot(filter(world_long, Dimension == "Face")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean (1-7)", option = "D",
                     limits = lims, na.value = "grey92", direction = -1) +
  labs(title = "Face norms") +
  theme_void() +
  common_theme

p_dignity <- ggplot(filter(world_long, Dimension == "Dignity")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean (1-7)", option = "D",
                     limits = lims, na.value = "grey92", direction = -1) +
  labs(title = "Dignity norms") +
  theme_void() +
  common_theme

# Centered maps (viridis option "D" to visually differentiate from non-centered)
p_honorc <- ggplot(filter(world_long_centered, Dimension == "HonorC")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean", option = "C",
                     limits = limsc, na.value = "grey92", direction = -1) +
  labs(title = "Honor norms") +
  theme_void() +
  common_theme

p_facec <- ggplot(filter(world_long_centered, Dimension == "FaceC")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean", option = "C",
                     limits = limsc, na.value = "grey92", direction = -1) +
  labs(title = "Face norms") +
  theme_void() +
  common_theme

p_dignityc <- ggplot(filter(world_long_centered, Dimension == "DignityC")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean", option = "C",
                     limits = limsc, na.value = "grey92", direction = -1) +
  labs(title = "Dignity norms") +
  theme_void() +
  common_theme

#endorsement_centered maps
# Centered maps (viridis option "D" to visually differentiate from non-centered)
p_honorec <- ggplot(filter(world_long_end, Dimension == "HonoreC")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean", option = "C",
                     limits = limsc, na.value = "grey92", direction = -1) +
  labs(title = "Honor endorsement") +
  theme_void() +
  common_theme

p_faceec <- ggplot(filter(world_long_end, Dimension == "FaceeC")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean", option = "C",
                     limits = limsc, na.value = "grey92", direction = -1) +
  labs(title = "Face endorsement") +
  theme_void() +
  common_theme

p_dignityec <- ggplot(filter(world_long_end, Dimension == "DignityeC")) +
  geom_sf(aes(fill = Score), color = "white", size = 0.1) +
  scale_fill_viridis(name = "Societal mean", option = "C",
                     limits = limsc, na.value = "grey92", direction = -1) +
  labs(title = "Dignity endorsement") +
  theme_void() +
  common_theme

# ---- build two separate rows (each with its own collected legend) ----
# Keep guide collection INSIDE each row so the top row (C) and bottom row (D)
# retain different palettes and their own legends.
row_nc <- (p_honor | p_face | p_dignity) +
  plot_layout(guides = "collect") &
  theme(
    legend.position = "right",          # put legend to the side of the row
    legend.direction = "vertical"       # vertical legend for compact height
  )

row_c <- (p_honorc | p_facec | p_dignityc) +
  plot_layout(guides = "collect") &
  theme(
    legend.position = "right",
    legend.direction = "vertical"
  )

row_ec <- (p_honorec | p_faceec | p_dignityec) +
  plot_layout(guides = "collect") &
  theme(
    legend.position = "right",
    legend.direction = "vertical"
  )


# Final assembly: stack the two rows. Each keeps its own legend and color scale.
final_plot <- row_nc / row_c
final_plot

final_plot2 <- row_ec / row_c
final_plot2

# Export plot
ggsave("DHF_Norms_worldmap.png", final_plot,
       width = 18, height = 6, dpi = 600)
ggsave("DHF_worldmap.png", final_plot2,
       width = 18, height = 6, dpi = 600)
ggsave("DHF_Norms_worldmap.pdf", final_plot,
       width = 18, height = 6)
```
## Behavior_comprehension checks

-   Create a new dataset excluding participants who failed to correctly answer the comprehension questions in the dictator and/or ultimatum games (dt5). This dataset will be used for all analyses that involve the games.

```{r exclude-comprehension}
#dictator game
dt4$dictator_cpass <- ifelse((dt4$Dictator.comp1.1_dich=="Correct"|dt4$Dictator.comp2.1_dich=="Correct")&(dt4$Dictator.comp1.2_dich=="Correct"|dt4$Dictator.comp2.2_dich=="Correct"),1,0)
table(dt4$dictator_cpass, useNA = "ifany")
dt5 <- subset(dt4, dictator_cpass==1) #N=21544

##use dt5 for all tests that involve the Dictator Game##

#ultimatum game
dt4$ultimatum_cpass <- ifelse((dt4$Ultimatum.comp.1.1_dich=="Correct"|dt4$Ultimatum.comp.2.1_dich=="Correct")&(dt4$Ultimatum.comp.1.2_dich=="Correct"|dt4$Ultimatum.comp.2.2_dich=="Correct"),1,0)
dt6 <- subset(dt4, ultimatum_cpass==1) #N=20626

##use dt6 for all tests that involve the Ultimatum Game##


```
## Behavior

```{r behavior-clean}
# Behavior ----
# dictator = universal prosociality for our experiment
dt5$prosocial <- as.numeric(dt5$Dictator_decision)
# examine the data 
table(dt5$prosocial)
hist(dt5$prosocial)
describe(dt5$prosocial) #Mean=4.77, SD=1.75, median=5


# ultimatum_receiver = negative reciprocity
# select those rows 
receiver <- dt6 %>% 
  select(ResponseId, `Ultimatum.Receiver_1`:`Ultimatum.Receiver_11`)

# convert to long format for scoring
receiver_long <- receiver %>%
  pivot_longer(!ResponseId, names_to = "proposed", values_to = "decision")

# score the ultimatum receiver game - adapted for the coding (1=accept, 2=reject)
receiver_long$change <- ifelse(receiver_long$decision == 1 & 
                                 (((receiver_long$decision != dplyr::lag(receiver_long$decision))==TRUE)|
                                    (receiver_long$proposed=="Ultimatum.Receiver_1")),1,0)


receiver_long$proposed <- str_remove(receiver_long$proposed, "Ultimatum.Receiver_")
receiver_long$UG_negrec <- ifelse(receiver_long$change==1, receiver_long$proposed, 0)

neg_rec_df <- subset(receiver_long, receiver_long$UG_negrec!=0)
neg_rec_df$dupl <- ifelse(duplicated(neg_rec_df$ResponseId)==TRUE, 1, 0)
neg_rec_df <- subset(neg_rec_df, neg_rec_df$dupl==0)
neg_rec_df <- neg_rec_df %>% 
  select(ResponseId, UG_negrec)

# Merge with dt6
dt6 <- merge(dt6, neg_rec_df, by="ResponseId")
dt6$UG_negrec <- as.numeric(dt6$UG_negrec)

# examine data
100*table(dt6$`Ultimatum.Receiver_1`) %>% prop.table() 
100*table(dt6$`Ultimatum.Receiver_2`) %>% prop.table() 
100*table(dt6$`Ultimatum.Receiver_3`) %>% prop.table() 
100*table(dt6$`Ultimatum.Receiver_4`) %>% prop.table() 
100*table(dt6$`Ultimatum.Receiver_5`) %>% prop.table() 

# ultimatum_proposer = positive reciprocity
proposer <- dt6 %>% 
  select(ResponseId, `Ultimatum.Proposer_1`:`Ultimatum.Proposer_11`)

# pivot longer to score the data 
proposer_long <- proposer %>%
  pivot_longer(!ResponseId, names_to = "proposed", values_to = "decision")

proposer_long$proposed <- str_remove(proposer_long$proposed, "Ultimatum.Proposer_")
proposer_long[, c("proposed", "decision")] <- lapply(proposer_long[, c("proposed", "decision")], as.numeric)
proposer_long$proposed <- proposer_long$proposed - 1

cor.test(proposer_long$proposed, proposer_long$decision) 
# r between proposal to and from = .605***  
describe(proposer_long$decision) 
# m=4.89 (4.89/11*100=44.5%)

proposer_long <- proposer_long %>% 
group_by(ResponseId) %>%
  mutate(cor = cor(proposed, decision, method = "spearman", use="everything"))

proposer_long$pr <- ifelse(proposer_long$decision >= proposer_long$proposed, 1, 0)
pos_rec_df <- aggregate(proposer_long$pr, by=list(proposer_long$ResponseId), FUN=sum)
pos_rec_df$UG_posrec <- (pos_rec_df$x/11)*100
pos_rec_df$ResponseId <- pos_rec_df$Group.1
pos_rec_df <- pos_rec_df %>% 
  select(ResponseId, UG_posrec)

# create merged dataset
dt6 <- merge(dt6, pos_rec_df, by="ResponseId")

# examine correlations (adapted variable names)
cor.test(dt6$Positive_Reciprocity, dt6$UG_posrec) 
cor.test(dt6$Negative_Reciprocity, dt6$UG_negrec) 
cor.test(dt6$Positive_Reciprocity, dt6$UG_negrec) 
cor.test(dt6$Negative_Reciprocity, dt6$UG_posrec)

print(paste("Final dataset has", nrow(dt6), "participants"))

# N(dt6)=20545 after creating positive & negative reciprocity 
##81(0.4%) participants were excluded during behavioral measure creation
#correlation between self-reported positive reciprocity and behavioral positive reciprocity:r=0.128***
#correlation between self-reported negative reciprocity and behavioral negative reciprocity:r=0.109***
#correlation between self-reported positive reciprocity and behavioral negative reciprocity:r=-0.027***
#correlation between self-reported negative reciprocity and behavioral positive reciprocity:r=-0.039***  
```

## Expectations

```{r expectations-clean, eval=FALSE}
# Expectations----
expect <- dt %>% 
  select(ResponseId, `Ultimatum.expect_1`:`Ultimatum.expect_11`)

# create an expectation long dataset to score the data
expect_long <- expect %>%
  pivot_longer(!ResponseId, names_to = "proposed", values_to = "decision")

# score the expectations
expect_long$change <- ifelse(expect_long$decision=="The other person would accept" & 
                     (((expect_long$decision != dplyr::lag(expect_long$decision))==TRUE)|
                        (expect_long$proposed=="Ultimatum expect_1")),1,0)
expect_long$proposed <- str_remove(expect_long$proposed, "Ultimatum expect_")
expect_long$UG_expect <- ifelse(expect_long$change==1, expect_long$proposed, 0)
expect_df <- subset(expect_long, expect_long$UG_expect!=0)
expect_df$dupl <- ifelse(duplicated(expect_df$ResponseId)==TRUE,1,0)
expect_df <- subset(expect_df, expect_df$dupl==0)

# select the final columns and merge
expect_df <- expect_df %>% 
  select(ResponseId, UG_expect)
dtg <- merge(dtg, expect_df, by="ResponseId")
dtg$UG_expect <- as.numeric(dtg$UG_expect)

# check the data 
describe(dtg$UG_expect)
```

-   Randomly match participants within countries and calculate their hypothetical earnings based on their decisions in the economic games.

```{r decision-matching}
##I'm thinking we should calculate this only based on the ultimatum game, because for the dictator game, it doesn't really matter whether they send money to someone else or not, the total amount of money in the pool remains the same; whereas in the ultimatum game, if offers are rejected, the total amount of money goes down. Does that make sense? Any reason why we would want to also do the matching for the dictator game? 

table(dt6$Ultimatum.Receiver_1)

ultim_totaw <- dt6 %>%
  group_by(country_res_full) %>%
  summarise(ultim_accept = sum(Ultimatum.Receiver_1==1, na.rm=T),
            n_country=n())
ultim_totaw$ultim_totaw <- (ultim_totaw$ultim_accept*10)/ultim_totaw$n_country
dt6 <- merge(dt6, ultim_totaw[,c(1,4)], by="country_res_full")
plot(dt6$ultim_totaw, dt6$country_res_full)

```
## Proposed Model: H2

All individual-level predictors will be group-mean centered (level 1), and all sample-level predictors will be grand-mean centered (level 2).

```{r h2-model}
# ============================================================================
# H2 ANALYSIS USING dt5 (PROSOCIAL OUTCOME)
# ============================================================================

print("Preparing H2 analysis with misty centering")
print(paste("Dataset has", nrow(dt5), "participants"))

# Proper multilevel centering using misty package
DF_H2 <- dt5 %>% 
  mutate(
    # Group-mean centering for individual-level variables (Level 1)
    D_self_end_CWC = center(D_self_end, type = "CWC", cluster = country_res_full),
    D_other_end_CWC = center(D_other_end, type = "CWC", cluster = country_res_full), 
    H_self_end_CWC = center(H_self_end, type = "CWC", cluster = country_res_full),
    H_other_end_CWC = center(H_other_end, type = "CWC", cluster = country_res_full), 
    F_self_end_CWC = center(F_self_end, type = "CWC", cluster = country_res_full),
    F_other_end_CWC = center(F_other_end, type = "CWC", cluster = country_res_full)
  )

# Data quality check
print("Data quality check...")
analysis_vars <- c("prosocial", "D_self_end_CWC", "D_other_end_CWC", 
                   "H_self_end_CWC", "H_other_end_CWC", 
                   "F_self_end_CWC", "F_other_end_CWC", "country_res_full")

# Check which variables exist
available_vars <- analysis_vars[analysis_vars %in% names(DF_H2)]
print("Available analysis variables:")
print(available_vars)

# Complete cases
complete_cases <- sum(complete.cases(DF_H2[, available_vars]))
print(paste("Complete cases for analysis:", complete_cases, "out of", nrow(DF_H2)))

# Country sample sizes
country_sizes <- DF_H2 %>%
  filter(!is.na(prosocial)) %>%
  group_by(country_res_full) %>%
  summarise(n = n()) %>%
  arrange(desc(n))

print("Sample sizes by country (top 10):")
print(head(country_sizes, 10))
print(paste("Number of countries:", nrow(country_sizes)))
print(paste("Minimum country sample size:", min(country_sizes$n)))

# H2 Main Analysis - six factors model 
print("\nRunning H2 Analysis - Six DHF Facets Model...")

h2.fit <- lmer(prosocial ~ D_self_end_CWC + D_other_end_CWC + 
                 H_self_end_CWC + H_other_end_CWC + 
                 F_self_end_CWC + F_other_end_CWC +
                 (1|country_res_full), 
               data = DF_H2,
               REML = FALSE)

print("H2 MODEL RESULTS:")
h2_params <- parameters(h2.fit, standardize = "refit", ci = 0.95)
print(h2_params)

# Model performance
print("\nModel Performance:")
perf <- performance(h2.fit)
print(perf)

# R-squared values
r2_vals <- r2(h2.fit)
print(paste("Marginal R² (fixed effects):", round(r2_vals$R2_marginal, 3)))
print(paste("Conditional R² (fixed + random):", round(r2_vals$R2_conditional, 3)))

# Check column names and create standardized results table
print("\nColumn names in h2_params:")
print(names(h2_params))

# Create standardized results table with proper column references
print("\nStandardized Coefficients with 95% CI and p-values:")
h2_results <- data.frame(
  Parameter = h2_params$Parameter,
  Std_Beta = round(h2_params$Coefficient, 4),  # Using Coefficient instead of Std_Coefficient
  CI_Lower = round(h2_params$CI_low, 4),
  CI_Upper = round(h2_params$CI_high, 4),
  p_value = round(h2_params$p, 4),
  Significance = ifelse(h2_params$p < 0.001, "***",
                        ifelse(h2_params$p < 0.01, "**",
                               ifelse(h2_params$p < 0.05, "*", "")))
)
print(h2_results)

# Random effects
rand_effects <- VarCorr(h2.fit)
print("\nRandom Effects Variance:")
print(rand_effects)



print("\nH2 ANALYSIS COMPLETE")
```

## Power

```{r h2-power-sim, eval = F}
# power simulation
n_people <- seq(20, 100, by = 10)

power.save <- list()
start.number <- 1

for (i in 1:1000){ # how many times to run the power 
  for (p in n_people){ # how many participants 
    
    # random effect of country
    country_ran_eff <- data.frame(
      country = 1:50,
      ran_eff = rnorm(n = 50, mean = .31, sd = .05)
    )
    
    # simulate a dataset with 50 countries by the number of people 
    DF <- DF_individual %>% 
      # get variables
      select(prosocial, D_self_individual:F_individual) %>% 
      # make enough data to make correlation work
      sim_df(., n = 50*p) %>% 
      # create fake countries
      mutate(country = rep(1:50, length.out = nrow(.))) %>% 
      # merge with fake random intercept effects 
      left_join(country_ran_eff, by = "country") %>% 
      group_by(country) %>% 
      # create fixed effects prosocial
      mutate(
        # intercept * random intercept effect 
        prosocial = 4.20*ran_eff + 
          # fixed effects 
          rnorm(1, mean = .07, sd = .10)*D_self_individual + 
          rnorm(1, mean = .20, sd = .10)*D_other_individual + 
          rnorm(1, mean = .20, sd = .10)*H_self_individual + 
          rnorm(1, mean = .20, sd = .10)*H_other_individual + 
          rnorm(1, mean = -.29, sd = .10)*F_self_individual + 
          rnorm(1, mean = .20, sd = .10)*F_other_individual + 
          # small error sigma for each person
          rnorm(1, mean = 2, sd = 1)
        ) 
      
    power.model <- lmer(
      prosocial ~ D_self_individual + D_other_individual + 
        H_self_individual + H_other_individual + 
        F_self_individual + F_other_individual +
        (1|country), data = DF)
    
    coef.model <- as.data.frame(summary(power.model)[["coefficients"]])
    # underestimating variance here 
    coef.model$`Std. Error` <- coef.model$`Std. Error`*10  
    # recalc t and p
    coef.model$`t value` <- coef.model$Estimate / coef.model$`Std. Error`
    coef.model$`Pr(>|t|)` <- pt(coef.model$`t value`, df = coef.model$df, lower.tail = FALSE)*2

    power.save[[start.number]] <- c(p, i, coef.model$`Pr(>|t|)`[3], 
                                  coef.model$`Pr(>|t|)`[5], 
                                  coef.model$`Pr(>|t|)`[7])
    power.save[[start.number]] <- as.data.frame(t(power.save[[start.number]]))
    colnames(power.save[[start.number]]) <- c("sample_size", "run", 
                                              "d_other", "h_other", "f_other")
    start.number <- start.number + 1
    
  }
  
}

power.save.df <- bind_rows(power.save) %>% 
  mutate(all_three = d_other <= .05 & h_other <= .05 & f_other <=.05) %>% 
  group_by(sample_size) %>% 
  summarize(power = sum(all_three) / n())

export(power.save.df, "power/h2_power_summary.csv", row.names = F)
```

```{r h2-show-power, eval=F}
power.save.df <- import("power/h2_power_summary.csv")

power.save.df
```

# H3

*Hypothesis*:

H3a: Higher country-level honor logic scores will predict higher positive reciprocity.

H3b: Higher country-level face logic scores will predict higher positive reciprocity.

H3c: Higher country-level honor logic scores will predict higher negative reciprocity.

*Analysis Plan*:

A multilevel, random-intercept path model predicting universal prosociality and positive and negative reciprocity from individual-level and sample-level DHF norm scores. The models below and in further hypotheses use 3 factors at the individual and 3 factors at the sample level; this is conditional upon the higher-order DHF factors showing appropriate fit in for both endorsement and sample measures.

Country will be used as the cluster variable for random intercepts.

Level 1: prosocial, positive reciprocity, and negative reciprocity will be predicted by DHF scores for individual endorsement.

Level 2: prosocial, positive reciprocity, and negative reciprocity will be predicted by DHF scores for sample aggregated norms.

*Evaluation*:

A significant positive effect (p\<.05) of sample-level honor logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level face logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level honor logic on negative reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

## Data Simulation

```{r h3-data-simulation, eval=F}
DF_final_H345 <- DF %>% 
  filter(`US state` == "Texas" | `US state` == "New York") %>% 
  dplyr::rename(country = `US state`) %>% 
  mutate(country = as.factor(country)) %>% 
  mutate(country = droplevels(country)) %>% 
  select(DHF_endorsement_1:DHF_endorsement_30,
         DHF_Norms_1:DHF_Norms_30, 
         prosocial,
         PosRec,
         NegRec,
         country, 
         ResponseId) %>% 
  group_by(ResponseId) %>% 
  mutate(
    D_individual = mean(DHF_endorsement_1:DHF_endorsement_10),
    H_individual = mean(DHF_endorsement_11:DHF_endorsement_20),
    F_individual = mean(DHF_endorsement_21:DHF_endorsement_30),
    D_sample = mean(DHF_Norms_1:DHF_Norms_10),
    H_sample = mean(DHF_Norms_11:DHF_Norms_20),
    F_sample = mean(DHF_Norms_21:DHF_Norms_30)) %>% 
  ungroup() 

DF_final_H <- sim_df(data = DF_final_H345 %>% 
                  select(prosocial, country, PosRec, NegRec, 
                         D_individual:F_sample) %>% 
                    mutate(country = rep(1:5, length.out = nrow(DF_final_H345))), 
                n = 300,
                between = c("country"))

# for this model, the D_sample, etc. have to be aggregates
DF_final_H3 <- DF_final_H %>% 
  left_join(
    DF_final_H %>% 
      group_by(country) %>% 
      summarize(D_sample_agg = mean(D_sample),
                H_sample_agg = mean(H_sample),
                F_sample_agg = mean(F_sample)),
    by = "country"
  )

# group mean centering for level 1 variable 
# grand mean centering for level 2 variable
# by country
DF_final_H3 <- DF_final_H3 %>% 
  # group_by(country) %>% 
  mutate(D_individual_Z = scale(D_individual, 
                                     center = TRUE),
         H_individual_Z = scale(H_individual, 
                                     center = TRUE),
         F_individual_Z = scale(F_individual, 
                                     center = TRUE),
         D_sample_agg_Z = scale(D_sample_agg, 
                                center = TRUE), 
         H_sample_agg_Z = scale(H_sample_agg, 
                                center = TRUE), 
         F_sample_agg_Z = scale(F_sample_agg, 
                                center = TRUE),
         D_sample_Z = scale(D_sample, 
                           center = TRUE), 
         H_sample_Z = scale(H_sample,
                            center = TRUE), 
         F_sample_Z = scale(F_sample,
                            center = TRUE)
         )
```

## Power

Parameters are based on *z*-score estimation, which do not involve degrees of freedom for significance purposes. If we assume our standard errors are approximate from the sample data (\~ .10 across parameters as high estimate with smaller sample size models), we would be able to detect regression loadings of approximately .20 (i.e., 1.96 \* SE).

```{r, eval=F}
prosocial.model <-'
  prosocial ~ D_individual_Z + H_individual_Z + F_individual_Z
  PosRec ~ D_individual_Z + H_individual_Z + F_individual_Z
  NegRec ~ D_individual_Z + H_individual_Z + F_individual_Z
'
  
prosocial.fit <- sem(
  model = prosocial.model,
  data = DF_final_H3
)

tidy(prosocial.fit)
```

## Proposed Model

```{r h3-model, eval = F}
# ============================================================================
# H3 ANALYSIS - MULTILEVEL PATH MODELS
# ===========================================================================

# STEP 1: Prepare prosocial data (dt5) with proper misty centering
print("Preparing prosocial model data from dt5...")
DF_prosocial_H3 <- dt5 %>%
  filter(!is.na(prosocial) & !is.na(D_end) & !is.na(H_end) & !is.na(F_end) &
           !is.na(D_norm_mean_country) & !is.na(H_norm_mean_country) & !is.na(F_norm_mean_country)) %>%
  mutate(
    # Individual-level variables: group-mean centering (CWC)
    D_end_CWC = center(D_end, type = "CWC", cluster = country_res_full),
    H_end_CWC = center(H_end, type = "CWC", cluster = country_res_full),
    F_end_CWC = center(F_end, type = "CWC", cluster = country_res_full),
    
    # Country-level variables: grand-mean centering (CGM)
    D_norm_agg_CGM = center(D_norm_mean_country, type = "CGM"),
    H_norm_agg_CGM = center(H_norm_mean_country, type = "CGM"),
    F_norm_agg_CGM = center(F_norm_mean_country, type = "CGM")
  )

print(paste("Prosocial model sample size:", nrow(DF_prosocial_H3)))

# STEP 2: Prepare reciprocity data (dt6) with proper misty centering
print("Preparing reciprocity model data from dt6...")
DF_reciprocity_H3 <- dt6 %>%
  filter(!is.na(UG_posrec) & !is.na(UG_negrec) & 
           !is.na(D_end) & !is.na(H_end) & !is.na(F_end) &
           !is.na(D_norm_mean_country) & !is.na(H_norm_mean_country) & !is.na(F_norm_mean_country)) %>%
  mutate(
    # Individual-level variables: group-mean centering (CWC)
    D_end_CWC = center(D_end, type = "CWC", cluster = country_res_full),
    H_end_CWC = center(H_end, type = "CWC", cluster = country_res_full),
    F_end_CWC = center(F_end, type = "CWC", cluster = country_res_full),
    
    # Country-level variables: grand-mean centering (CGM) 
    D_norm_agg_CGM = center(D_norm_mean_country, type = "CGM"),
    H_norm_agg_CGM = center(H_norm_mean_country, type = "CGM"),
    F_norm_agg_CGM = center(F_norm_mean_country, type = "CGM")
  )

print(paste("Reciprocity model sample size:", nrow(DF_reciprocity_H3)))

# STEP 3: H3 Model 1 - Prosocial Behavior
print("\nRunning H3 Model 1: Prosocial Behavior...")

prosocial.model <- '
# Level 1: Individual endorsement predicting prosocial behavior
prosocial ~ D_end_CWC + H_end_CWC + F_end_CWC

# Level 2: Country-level norms predicting prosocial behavior  
prosocial ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

prosocial.fit <- sem(
  model = prosocial.model,
  data = DF_prosocial_H3,
  cluster = "country_res_full"
)

print("PROSOCIAL MODEL RESULTS:")
print(summary(prosocial.fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE))

# Extract standardized results for prosocial model
prosocial_std <- standardizedSolution(prosocial.fit, ci = TRUE, level = 0.95)
prosocial_reg <- prosocial_std[prosocial_std$op == "~",]
print("\nStandardized Coefficients with 95% CI:")
prosocial_results <- data.frame(
  Parameter = prosocial_reg$rhs,
  Std_Beta = round(prosocial_reg$est.std, 4),
  CI_Lower = round(prosocial_reg$ci.lower, 4), 
  CI_Upper = round(prosocial_reg$ci.upper, 4),
  p_value = round(prosocial_reg$pvalue, 4),
  Significance = ifelse(prosocial_reg$pvalue < 0.001, "***",
                        ifelse(prosocial_reg$pvalue < 0.01, "**",
                               ifelse(prosocial_reg$pvalue < 0.05, "*", "")))
)
print(prosocial_results)

# STEP 4: H3 Model 2 - Positive Reciprocity
print("\nRunning H3 Model 2: Positive Reciprocity...")

posrec.model <- '
# Level 1: Individual endorsement predicting positive reciprocity
UG_posrec ~ D_end_CWC + H_end_CWC + F_end_CWC

# Level 2: Country-level norms predicting positive reciprocity
UG_posrec ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

posrec.fit <- sem(
  model = posrec.model,
  data = DF_reciprocity_H3,
  cluster = "country_res_full"
)

print("POSITIVE RECIPROCITY MODEL RESULTS:")
print(summary(posrec.fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE))

# Extract standardized results for positive reciprocity model
posrec_std <- standardizedSolution(posrec.fit, ci = TRUE, level = 0.95)
posrec_reg <- posrec_std[posrec_std$op == "~",]
print("\nStandardized Coefficients with 95% CI:")
posrec_results <- data.frame(
  Parameter = posrec_reg$rhs,
  Std_Beta = round(posrec_reg$est.std, 4),
  CI_Lower = round(posrec_reg$ci.lower, 4),
  CI_Upper = round(posrec_reg$ci.upper, 4),
  p_value = round(posrec_reg$pvalue, 4),
  Significance = ifelse(posrec_reg$pvalue < 0.001, "***",
                        ifelse(posrec_reg$pvalue < 0.01, "**",
                               ifelse(posrec_reg$pvalue < 0.05, "*", "")))
)
print(posrec_results)

# STEP 5: H3 Model 3 - Negative Reciprocity  
print("\nRunning H3 Model 3: Negative Reciprocity...")

negrec.model <- '
# Level 1: Individual endorsement predicting negative reciprocity
UG_negrec ~ D_end_CWC + H_end_CWC + F_end_CWC

# Level 2: Country-level norms predicting negative reciprocity
UG_negrec ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

negrec.fit <- sem(
  model = negrec.model,
  data = DF_reciprocity_H3,
  cluster = "country_res_full"
)

print("NEGATIVE RECIPROCITY MODEL RESULTS:")
print(summary(negrec.fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE))

# Extract standardized results for negative reciprocity model
negrec_std <- standardizedSolution(negrec.fit, ci = TRUE, level = 0.95)
negrec_reg <- negrec_std[negrec_std$op == "~",]
print("\nStandardized Coefficients with 95% CI:")
negrec_results <- data.frame(
  Parameter = negrec_reg$rhs,
  Std_Beta = round(negrec_reg$est.std, 4),
  CI_Lower = round(negrec_reg$ci.lower, 4),
  CI_Upper = round(negrec_reg$ci.upper, 4),
  p_value = round(negrec_reg$pvalue, 4),
  Significance = ifelse(negrec_reg$pvalue < 0.001, "***",
                        ifelse(negrec_reg$pvalue < 0.01, "**",
                               ifelse(negrec_reg$pvalue < 0.05, "*", "")))
)
print(negrec_results)


# R-squared comparison
print("\nR-SQUARED COMPARISON:")
cat("Prosocial Behavior: R² = ", round(inspect(prosocial.fit, "r2"), 3), "\n")
cat("Positive Reciprocity: R² = ", round(inspect(posrec.fit, "r2"), 3), "\n") 
cat("Negative Reciprocity: R² = ", round(inspect(negrec.fit, "r2"), 3), "\n")


print("\nH2 MODEL - Standardized Coefficients with 95% CI:")
print(h2_results)
print("\nPROSOCIAL MODEL - Standardized Coefficients with 95% CI:")
print(prosocial_results)
print("\nPOSITIVE RECIPROCITY MODEL - Standardized Coefficients with 95% CI:")
print(posrec_results)

print("\nNEGATIVE RECIPROCITY MODEL - Standardized Coefficients with 95% CI:")
print(negrec_results)

dt7 <- dt6 %>%
  semi_join(dt5, by = "ResponseId")
dt7$prosocial <- as.numeric(dt7$Dictator_decision)

##use dt7 for all tests that involve both dictator and ultimatum games

dt7 <- dt7 %>%
  mutate(
    # Individual-level variables: group-mean centering (CWC)
    D_end_CWC = center(D_end, type = "CWC", cluster = country_res_full),
    H_end_CWC = center(H_end, type = "CWC", cluster = country_res_full),
    F_end_CWC = center(F_end, type = "CWC", cluster = country_res_full),
    D_self_end_CWC = center(D_self_end, type = "CWC", cluster=country_res_full),
    D_other_end_CWC = center(D_other_end, type = "CWC", cluster=country_res_full),
    H_self_end_CWC = center(H_self_end, type = "CWC", cluster=country_res_full),
    H_other_end_CWC = center(H_other_end, type = "CWC", cluster=country_res_full),
    F_self_end_CWC = center(F_self_end, type = "CWC", cluster=country_res_full),
    F_other_end_CWC = center(F_other_end, type = "CWC", cluster=country_res_full),
    
    # Country-level variables: grand-mean centering (CGM) 
    D_norm_agg_CGM = center(D_norm_mean_country, type = "CGM"),
    H_norm_agg_CGM = center(H_norm_mean_country, type = "CGM"),
    F_norm_agg_CGM = center(F_norm_mean_country, type = "CGM"),
    D_end_agg_CGM = center(D_end_mean_country, type = "CGM"),
    H_end_agg_CGM = center(H_end_mean_country, type = "CGM"),
    F_end_agg_CGM = center(F_end_mean_country, type = "CGM")
  )


prosocial.model <- '
level: 1 
prosocial ~ D_end_CWC + H_end_CWC + F_end_CWC
UG_negrec ~ D_end_CWC + H_end_CWC + F_end_CWC
UG_posrec ~ D_end_CWC + H_end_CWC + F_end_CWC
level: 2 
prosocial~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
UG_negrec ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
UG_posrec~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

prosocial.model.1 <- '
level: 1 
prosocial ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
UG_negrec ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
UG_posrec ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
level: 2 
prosocial~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
UG_negrec ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
UG_posrec~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

prosocial.model.2 <- '
level: 1 
prosocial ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
UG_negrec ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
UG_posrec ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
level: 2 
prosocial~ D_end_agg_CGM + H_end_agg_CGM + F_end_agg_CGM
UG_negrec ~ D_end_agg_CGM + H_end_agg_CGM + F_end_agg_CGM
UG_posrec~ D_end_agg_CGM + H_end_agg_CGM + F_end_agg_CGM
'

prosocial.model.3 <- '
level: 1 
prosocial ~ D_self_end + D_other_end + H_self_end + H_other_end + F_self_end + F_other_end
UG_negrec ~ D_self_end + D_other_end + H_self_end + H_other_end + F_self_end + F_other_end
UG_posrec ~ D_self_end + D_other_end + H_self_end + H_other_end + F_self_end + F_other_end
level: 2 
prosocial~ D_norm_mean_country + H_norm_mean_country + F_norm_mean_country
UG_negrec ~ D_norm_mean_country + H_norm_mean_country + F_norm_mean_country
UG_posrec~ D_norm_mean_country + H_norm_mean_country + F_norm_mean_country
'

prosocial.model.4 <- '
level: 1 
UG_negrec ~ D_self_end + D_other_end + H_self_end + H_other_end + F_self_end + F_other_end
UG_posrec ~ D_self_end + D_other_end + H_self_end + H_other_end + F_self_end + F_other_end
level: 2 
UG_negrec ~ D_end_mean_country + H_end_mean_country + F_end_mean_country
UG_posrec~ D_end_mean_country + H_end_mean_country + F_end_mean_country
'

prosocial.model <- sem(
  model = prosocial.model.1,
  data = dt7,
  cluster = "country_res_full"
)

summary(prosocial.model, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE)

print("NEGATIVE RECIPROCITY MODEL RESULTS:")
print(summary(negrec.fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE))

```

#H3 supplemenatry analysis: 
##models with 6-factor (self and other-concerns) individual-level predictor

```{r h3-modelm supplementary}
# ============================================================================
# H3 ANALYSIS - MULTILEVEL PATH MODELS WITH 6-FACTOR INDIVIDUAL PREDICTORS
# ============================================================================

print("Preparing H3 multilevel path model analysis with 6-factor individual predictors...")
print("Using dt5 for prosocial, dt6 for reciprocity outcomes...")

# STEP 1: Prepare prosocial data (dt5) with 6-factor individual predictors + country norms
print("Preparing prosocial model data from dt5...")
DF_prosocial_H3_6factor <- dt5 %>%
  filter(!is.na(prosocial) & 
           !is.na(D_self_end) & !is.na(D_other_end) & 
           !is.na(H_self_end) & !is.na(H_other_end) & 
           !is.na(F_self_end) & !is.na(F_other_end) &
           !is.na(D_norm_mean_country) & !is.na(H_norm_mean_country) & !is.na(F_norm_mean_country)) %>%
  mutate(
    # Individual-level variables: 6-factor model with group-mean centering (CWC)
    D_self_end_CWC = center(D_self_end, type = "CWC", cluster = country_res_full),
    D_other_end_CWC = center(D_other_end, type = "CWC", cluster = country_res_full),
    H_self_end_CWC = center(H_self_end, type = "CWC", cluster = country_res_full),
    H_other_end_CWC = center(H_other_end, type = "CWC", cluster = country_res_full),
    F_self_end_CWC = center(F_self_end, type = "CWC", cluster = country_res_full),
    F_other_end_CWC = center(F_other_end, type = "CWC", cluster = country_res_full),
    
    # Country-level variables: grand-mean centering (CGM)
    D_norm_agg_CGM = center(D_norm_mean_country, type = "CGM"),
    H_norm_agg_CGM = center(H_norm_mean_country, type = "CGM"),
    F_norm_agg_CGM = center(F_norm_mean_country, type = "CGM")
  )

print(paste("Prosocial model sample size:", nrow(DF_prosocial_H3_6factor)))

# STEP 2: Prepare reciprocity data (dt6) with 6-factor individual predictors + country norms
print("Preparing reciprocity model data from dt6...")
DF_reciprocity_H3_6factor <- dt6 %>%
  filter(!is.na(UG_posrec) & !is.na(UG_negrec) & 
           !is.na(D_self_end) & !is.na(D_other_end) & 
           !is.na(H_self_end) & !is.na(H_other_end) & 
           !is.na(F_self_end) & !is.na(F_other_end) &
           !is.na(D_norm_mean_country) & !is.na(H_norm_mean_country) & !is.na(F_norm_mean_country)) %>%
  mutate(
    # Individual-level variables: 6-factor model with group-mean centering (CWC)
    D_self_end_CWC = center(D_self_end, type = "CWC", cluster = country_res_full),
    D_other_end_CWC = center(D_other_end, type = "CWC", cluster = country_res_full),
    H_self_end_CWC = center(H_self_end, type = "CWC", cluster = country_res_full),
    H_other_end_CWC = center(H_other_end, type = "CWC", cluster = country_res_full),
    F_self_end_CWC = center(F_self_end, type = "CWC", cluster = country_res_full),
    F_other_end_CWC = center(F_other_end, type = "CWC", cluster = country_res_full),
    
    # Country-level variables: grand-mean centering (CGM) 
    D_norm_agg_CGM = center(D_norm_mean_country, type = "CGM"),
    H_norm_agg_CGM = center(H_norm_mean_country, type = "CGM"),
    F_norm_agg_CGM = center(F_norm_mean_country, type = "CGM")
  )

print(paste("Reciprocity model sample size:", nrow(DF_reciprocity_H3_6factor)))

# STEP 3: H3 Model 1 - Prosocial Behavior (6-factor individual predictors)
print("\nRunning H3 Model 1: Prosocial Behavior with 6-Factor Individual Predictors...")

prosocial_6factor.model <- '
# Level 1: 6-factor individual endorsement predicting prosocial behavior
prosocial ~ D_self_end_CWC + D_other_end_CWC + 
            H_self_end_CWC + H_other_end_CWC + 
            F_self_end_CWC + F_other_end_CWC

# Level 2: Country-level norms predicting prosocial behavior  
prosocial ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

prosocial_6factor.fit <- sem(
  model = prosocial_6factor.model,
  data = DF_prosocial_H3_6factor,
  cluster = "country_res_full"
)

print("PROSOCIAL MODEL RESULTS (6-Factor Individual Predictors):")
print(summary(prosocial_6factor.fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE))

# Extract standardized results for prosocial model
prosocial_6factor_std <- standardizedSolution(prosocial_6factor.fit, ci = TRUE, level = 0.95)
prosocial_6factor_reg <- prosocial_6factor_std[prosocial_6factor_std$op == "~",]
print("\nStandardized Coefficients with 95% CI:")
prosocial_6factor_results <- data.frame(
  Parameter = prosocial_6factor_reg$rhs,
  Std_Beta = round(prosocial_6factor_reg$est.std, 4),
  CI_Lower = round(prosocial_6factor_reg$ci.lower, 4), 
  CI_Upper = round(prosocial_6factor_reg$ci.upper, 4),
  p_value = round(prosocial_6factor_reg$pvalue, 4),
  Significance = ifelse(prosocial_6factor_reg$pvalue < 0.001, "***",
                        ifelse(prosocial_6factor_reg$pvalue < 0.01, "**",
                               ifelse(prosocial_6factor_reg$pvalue < 0.05, "*", "")))
)
print(prosocial_6factor_results)

# STEP 4: H3 Model 2 - Positive Reciprocity (6-factor individual predictors)
print("\nRunning H3 Model 2: Positive Reciprocity with 6-Factor Individual Predictors...")

posrec_6factor.model <- '
# Level 1: 6-factor individual endorsement predicting positive reciprocity
UG_posrec ~ D_self_end_CWC + D_other_end_CWC + 
            H_self_end_CWC + H_other_end_CWC + 
            F_self_end_CWC + F_other_end_CWC

# Level 2: Country-level norms predicting positive reciprocity
UG_posrec ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

posrec_6factor.fit <- sem(
  model = posrec_6factor.model,
  data = DF_reciprocity_H3_6factor,
  cluster = "country_res_full"
)

print("POSITIVE RECIPROCITY MODEL RESULTS (6-Factor Individual Predictors):")
print(summary(posrec_6factor.fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE))

# Extract standardized results for positive reciprocity model
posrec_6factor_std <- standardizedSolution(posrec_6factor.fit, ci = TRUE, level = 0.95)
posrec_6factor_reg <- posrec_6factor_std[posrec_6factor_std$op == "~",]
print("\nStandardized Coefficients with 95% CI:")
posrec_6factor_results <- data.frame(
  Parameter = posrec_6factor_reg$rhs,
  Std_Beta = round(posrec_6factor_reg$est.std, 4),
  CI_Lower = round(posrec_6factor_reg$ci.lower, 4),
  CI_Upper = round(posrec_6factor_reg$ci.upper, 4),
  p_value = round(posrec_6factor_reg$pvalue, 4),
  Significance = ifelse(posrec_6factor_reg$pvalue < 0.001, "***",
                        ifelse(posrec_6factor_reg$pvalue < 0.01, "**",
                               ifelse(posrec_6factor_reg$pvalue < 0.05, "*", "")))
)
print(posrec_6factor_results)

# STEP 5: H3 Model 3 - Negative Reciprocity (6-factor individual predictors)
print("\nRunning H3 Model 3: Negative Reciprocity with 6-Factor Individual Predictors...")

negrec_6factor.model <- '
# Level 1: 6-factor individual endorsement predicting negative reciprocity
UG_negrec ~ D_self_end_CWC + D_other_end_CWC + 
            H_self_end_CWC + H_other_end_CWC + 
            F_self_end_CWC + F_other_end_CWC

# Level 2: Country-level norms predicting negative reciprocity
UG_negrec ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
'

negrec_6factor.fit <- sem(
  model = negrec_6factor.model,
  data = DF_reciprocity_H3_6factor,
  cluster = "country_res_full"
)

print("NEGATIVE RECIPROCITY MODEL RESULTS (6-Factor Individual Predictors):")
print(summary(negrec_6factor.fit, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE))

# Extract standardized results for negative reciprocity model
negrec_6factor_std <- standardizedSolution(negrec_6factor.fit, ci = TRUE, level = 0.95)
negrec_6factor_reg <- negrec_6factor_std[negrec_6factor_std$op == "~",]
print("\nStandardized Coefficients with 95% CI:")
negrec_6factor_results <- data.frame(
  Parameter = negrec_6factor_reg$rhs,
  Std_Beta = round(negrec_6factor_reg$est.std, 4),
  CI_Lower = round(negrec_6factor_reg$ci.lower, 4),
  CI_Upper = round(negrec_6factor_reg$ci.upper, 4),
  p_value = round(negrec_6factor_reg$pvalue, 4),
  Significance = ifelse(negrec_6factor_reg$pvalue < 0.001, "***",
                        ifelse(negrec_6factor_reg$pvalue < 0.01, "**",
                               ifelse(negrec_6factor_reg$pvalue < 0.05, "*", "")))
)
print(negrec_6factor_results)


# R-squared comparison
print("\nR-SQUARED COMPARISON:")
cat("Prosocial Behavior (6-factor): R² = ", round(inspect(prosocial_6factor.fit, "r2"), 3), "\n")
cat("Positive Reciprocity (6-factor): R² = ", round(inspect(posrec_6factor.fit, "r2"), 3), "\n") 
cat("Negative Reciprocity (6-factor): R² = ", round(inspect(negrec_6factor.fit, "r2"), 3), "\n")

print("\nPROSOCIAL MODEL (6-Factor) - Standardized Coefficients with 95% CI:")
print(prosocial_6factor_results)

print("\nPOSITIVE RECIPROCITY MODEL (6-Factor) - Standardized Coefficients with 95% CI:")
print(posrec_6factor_results)

print("\nNEGATIVE RECIPROCITY MODEL (6-Factor) - Standardized Coefficients with 95% CI:")
print(negrec_6factor_results)
```


# H4

*Hypothesis*:

H4a: Individual endorsement of honor culture will positively predict attitude toward violence.

H4b: Individual endorsement of face culture will positively predict other-face concern in interpersonal conflict.

H4c: Individual endorsement of dignity culture will negatively predict other-face concern in interpersonal conflict.

*Analysis Plan*:

H4a: A multilevel, random-intercept model (country) predicting attitude to violence from individual-level endorsement and country-level norm scores for honor, face, and dignity.

H4b-c: A multilevel, random-intercept model (country) predicting other-face concern from individual-level endorsement and country-level norm scores for honor, face, and dignity.

*Evaluation*:

H4a: A significant (p\<.05) positive effect of individual-level honor will be interpreted as support for the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

H4b: A significant (p\<.05) positive effect of individual-level face will be interpreted as support for the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

H4c: A significant (p\<.05) negative effect of individual-level dignity will be interpreted as support for the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

## Data Simulation

```{r h4-data-simulation}
# making up numbers here for each group differently 
DF_final_H4 <- DF_final_H3 %>% 
  mutate(attviol = c(rnorm(300, mean = 4, sd = 1), 
                     rnorm(300, mean = 5.2, sd = 1),
                     rnorm(300, mean = 4.76, sd = 1), 
                     rnorm(300, mean = 5.16, sd = 1),
                     rnorm(300, mean = 4.8, sd = 1)),
         oface = c(rnorm(300, mean = 3.1, sd = 1), 
                     rnorm(300, mean = 2.4, sd = 1),
                     rnorm(300, mean = 3.56, sd = 1), 
                     rnorm(300, mean = 2.10, sd = 1),
                     rnorm(300, mean = 2.78, sd = 1))) 
```

## Proposed Model

```{r h4-model}
h3.model.a <- lmer(attviol ~ D_individual_Z + H_individual_Z + F_individual_Z + 
                     D_sample_Z + H_sample_Z + F_sample_Z + (1|country),
                   data = DF_final_H4,
                   na.action = "na.omit"
                   )

summary(h3.model.a)

h3.model.b <- lmer(oface ~ D_individual_Z + H_individual_Z + F_individual_Z + 
                     D_sample_Z + H_sample_Z + F_sample_Z + (1|country),
                   data = DF_final_H4, 
                   na.action = "na.omit")

summary(h3.model.b)
```

## Power

```{r h4-calc-power, eval = F}
# power simulation
n_people <- seq(20, 100, by = 10)

power.save.h4a <- list()
power.save.h4b <- list()
start.number <- 1

for (i in 1:1000){ # how many times to run the power 
  for (p in n_people){ # how many participants 
    
    # random effect of country
    country_ran_eff <- data.frame(
      country = 1:50,
      ran_eff = rnorm(n = 50, mean = .31, sd = .05)
    )
    
    # simulate a dataset with 50 countries by the number of people 
    DF <- DF_final_H4 %>% 
      # get variables
      select(attviol, D_individual, H_individual, 
             F_individual, D_sample, H_sample, F_sample, 
             country) %>% 
      # make enough data to make correlation work
      sim_df(., n = 50*p) %>% 
      # create fake countries
      mutate(country = rep(1:50, length.out = nrow(.))) %>% 
      # merge with fake random intercept effects 
      left_join(country_ran_eff, by = "country") %>% 
      group_by(country) %>% 
      # create fixed effects prosocial
      mutate(
        # intercept * random intercept effect 
        attviol = 4*ran_eff + 
          # fixed effects 
          rnorm(1, mean = -.07, sd = .10)*D_individual + 
          rnorm(1, mean = .20, sd = .10)*H_individual + 
          rnorm(1, mean = -.08, sd = .10)*F_individual + 
          rnorm(1, mean = .10, sd = .10)*D_sample + 
          rnorm(1, mean = .05, sd = .10)*H_sample + 
          rnorm(1, mean = -.10, sd = .10)*F_sample + 
          # small error sigma for each person
          rnorm(1, mean = 2, sd = 1), 
        oface = 4*ran_eff + 
          # fixed effects 
          rnorm(1, mean = -.20, sd = .10)*D_individual + 
          rnorm(1, mean = -.08, sd = .10)*H_individual + 
          rnorm(1, mean = .20, sd = .10)*F_individual + 
          rnorm(1, mean = -.07, sd = .10)*D_sample + 
          rnorm(1, mean = -.10, sd = .10)*H_sample + 
          rnorm(1, mean = .03, sd = .10)*F_sample + 
          # small error sigma for each person
          rnorm(1, mean = 2, sd = 1)
        ) 
      
    power.model.h4a <- lmer(
      attviol ~ D_individual + H_individual + F_individual +
        D_sample + H_sample + F_sample + (1|country),
      data = DF)
    
    coef.model <- as.data.frame(summary(power.model.h4a)[["coefficients"]])
    # underestimating variance here 
    coef.model$`Std. Error` <- coef.model$`Std. Error`*10  
    # recalc t and p
    coef.model$`t value` <- coef.model$Estimate / coef.model$`Std. Error`
    coef.model$`Pr(>|t|)` <- pt(coef.model$`t value`, df = coef.model$df, lower.tail = FALSE)*2

    power.save.h4a[[start.number]] <- c(p, i, coef.model$`Pr(>|t|)`[3])
    power.save.h4a[[start.number]] <- as.data.frame(t(power.save.h4a[[start.number]]))
    colnames(power.save.h4a[[start.number]]) <- c("sample_size", "run", 
                                              "h_individual")
    
    power.model.h4b <- lmer(
      oface ~ D_individual + H_individual + F_individual +
        D_sample + H_sample + F_sample + (1|country),
      na.action = "na.omit", 
      data = DF)
    
    coef.model <- as.data.frame(summary(power.model.h4b)[["coefficients"]])
    # underestimating variance here 
    coef.model$`Std. Error` <- coef.model$`Std. Error`*10  
    # recalc t and p
    coef.model$`t value` <- coef.model$Estimate / coef.model$`Std. Error`
    coef.model$`Pr(>|t|)` <- pt(abs(coef.model$`t value`), df = coef.model$df, lower.tail = FALSE)*2

    power.save.h4b[[start.number]] <- c(p, i, 
                                        coef.model$`Pr(>|t|)`[4], 
                                        coef.model$`Pr(>|t|)`[2])
    power.save.h4b[[start.number]] <- as.data.frame(t(power.save.h4b[[start.number]]))
    colnames(power.save.h4b[[start.number]]) <- c("sample_size", "run", 
                                              "f_individual", "d_individual")
    start.number <- start.number + 1
    
  }
  
}

power.save.df.h4a <- bind_rows(power.save.h4a) %>% 
  mutate(sig = h_individual <= .05) %>% 
  group_by(sample_size) %>% 
  summarize(power = sum(sig) / n())

export(power.save.df.h4a, "power/h4a_power_summary.csv", row.names = F)

power.save.df.h4b <- bind_rows(power.save.h4b) %>% 
  mutate(
    f_individual = ifelse(f_individual > 1, 1, f_individual),
    d_individual = ifelse(d_individual > 1, 1, d_individual),
    sig_hb = f_individual <= .05,
    sig_hc = d_individual <= .05) %>% 
  group_by(sample_size) %>% 
  summarize(power_hb = sum(sig_hb) / n(),
            power_hc = sum(sig_hc) / n())

export(power.save.df.h4b, "power/h4b_power_summary.csv", row.names = F)
```

```{r h4-show-power}
power.save.df.h4a <- import("power/h4a_power_summary.csv")

power.save.df.h4a

power.save.df.h4b <- import("power/h4b_power_summary.csv")

power.save.df.h4b
```

## Analysis (Shuxian)
```{r h4-analysis}
# Prepare dt4 with 3-factor and 6-factor individual predictors + country norms
DF_final_H4 <- dt4 %>%
  mutate(
    # Individual-level variables: 6-factor model with group-mean centering (CWC)
    D_self_end_CWC = center(D_self_end, type = "CWC", cluster = country_res_full),
    D_other_end_CWC = center(D_other_end, type = "CWC", cluster = country_res_full),
    H_self_end_CWC = center(H_self_end, type = "CWC", cluster = country_res_full),
    H_other_end_CWC = center(H_other_end, type = "CWC", cluster = country_res_full),
    F_self_end_CWC = center(F_self_end, type = "CWC", cluster = country_res_full),
    F_other_end_CWC = center(F_other_end, type = "CWC", cluster = country_res_full),
    
    # Individual-level variables: 3-factor model with group-mean centering (CWC)
    D_end_CWC = center(D_end, type = "CWC", cluster = country_res_full),
    H_end_CWC = center(H_end, type = "CWC", cluster = country_res_full),
    F_end_CWC = center(F_end, type = "CWC", cluster = country_res_full),
    
    # Country-level variables: grand-mean centering (CGM)
    D_norm_agg_CGM = center(D_norm_mean_country, type = "CGM"),
    H_norm_agg_CGM = center(H_norm_mean_country, type = "CGM"),
    F_norm_agg_CGM = center(F_norm_mean_country, type = "CGM")
  )

# Test hypothesis 4a (6-factor individual predictors)
h4.model.a.6f <- lmer(Total_Violence ~ D_self_end_CWC + D_other_end_CWC +
                     H_self_end_CWC + H_other_end_CWC +
                     F_self_end_CWC + F_other_end_CWC +
                     D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM + (1|country_res_full),
                   data = DF_final_H4,
                   na.action = "na.omit")
# Do not present numbers in scientific notation
#options(scipen = 999, digits = 4)
summary(h4.model.a.6f)

# Test hypothesis 4a (3-factor individual predictors)
h4.model.a.3f <- lmer(Total_Violence ~ D_end_CWC + H_end_CWC + F_end_CWC +
                     D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM + (1|country_res_full),
                   data = DF_final_H4,
                   na.action = "na.omit")
summary(h4.model.a.3f)

# Test hypotheses 4b-c (6-factor individual predictors)
h4.model.b.6f <- lmer(Other_Face_Concern ~ D_self_end_CWC + D_other_end_CWC +
                     H_self_end_CWC + H_other_end_CWC +
                     F_self_end_CWC + F_other_end_CWC +
                     D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM + (1|country_res_full),
                   data = DF_final_H4, 
                   na.action = "na.omit")
summary(h4.model.b.6f)

# Test hypotheses 4b-c (3-factor individual predictors)
h4.model.b.3f <- lmer(Other_Face_Concern ~ D_end_CWC + H_end_CWC + F_end_CWC +
                     D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM + (1|country_res_full),
                   data = DF_final_H4, 
                   na.action = "na.omit")
summary(h4.model.b.3f)
```

# H5

*Hypothesis*:

H5a: Individual endorsement of honor culture will positively predict retaliation in response to provocation.

H5b: Individual endorsement of face culture will positively predict withdrawal in response to provocation.

H5c: Individual endorsement of dignity culture will positively predict humor in response to provocation.

*Analysis Plan*:

A multilevel, random-intercept path model predicting retaliation, withdrawal, and humor as reactions to provocation from individual-level endorsement and sample-level aggregate scores for honor, face, and dignity.

Country will be used as the cluster variable for random intercepts.

Level 1: Retaliation, withdrawal, and humor will be predicted by DHF scores for individual endorsement.

Level 2: Retaliation, withdrawal, and humor will be predicted by DHF scores for sample aggregated norms.

*Evaluation*:

A significant positive effect (p\<.05) of sample-level honor logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level face logic on positive reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

A significant positive effect (p\<.05) of sample-level honor logic on negative reciprocity will support the hypothesis. Non-significant effect or an effect in the opposite direction will provide evidence against the hypothesis.

## Data Simulation

```{r h5-data-simulation}
DF_final_H5 <- DF_final_H3 %>% 
  mutate(retaliation = c(rnorm(300, mean = 4, sd = 1), 
                     rnorm(300, mean = 5.2, sd = 1),
                     rnorm(300, mean = 4.76, sd = 1), 
                     rnorm(300, mean = 5.16, sd = 1),
                     rnorm(300, mean = 4.8, sd = 1)),
         withdrawal = c(rnorm(300, mean = 3.1, sd = 1), 
                     rnorm(300, mean = 2.4, sd = 1),
                     rnorm(300, mean = 3.56, sd = 1), 
                     rnorm(300, mean = 2.10, sd = 1),
                     rnorm(300, mean = 2.78, sd = 1)),
         humor = c(rnorm(300, mean = 4.7, sd = 1), 
                     rnorm(300, mean = 6.2, sd = 1),
                     rnorm(300, mean = 3.4, sd = 1), 
                     rnorm(300, mean = 5.0, sd = 1),
                     rnorm(300, mean = 5.23, sd = 1))) 
```

## Power

Parameters are based on *z*-score estimation, which do not involve degrees of freedom for significance purposes. If we assume our standard errors are approximate from the sample data (\~ .10 across parameters as high estimate with smaller sample size models), we would be able to detect regression loadings of approximately .20 (i.e., 1.96 \* SE).

```{r}
provocation.model <-'
  retaliation ~ D_individual_Z + H_individual_Z + F_individual_Z
  withdrawal ~ D_individual_Z + H_individual_Z + F_individual_Z
  humor ~ D_individual_Z + H_individual_Z + F_individual_Z
'
  
provocation.fit <- sem(
  model = provocation.model,
  data = DF_final_H5
)

tidy(provocation.fit)
```

## Proposed Model

```{r h5-model, eval = F}
provocation.model <-'
Level: 1
  retaliation ~ D_individual_Z + H_individual_Z + F_individual_Z
  withdrawal ~ D_individual_Z + H_individual_Z + F_individual_Z
  humor ~ D_individual_Z + H_individual_Z + F_individual_Z
Level: 2
  retaliation  ~ D_sample_agg_Z + H _sample_agg_Z + F_sample_agg_Z
  withdrawal ~ D_sample_agg_Z + H_sample_agg_Z + F_sample_agg_Z 
  humor ~ D_sample_agg_Z + H _sample_agg_Z + F_sample_agg_Z 
'
  
provocation.fit <- sem(
  model = provocation.model,
  data = DF_final_H5,
  cluster = "country"
)

summary(provocation.fit, 
        standardized = TRUE,
        fit.measures = TRUE,
        rsquare = TRUE)

tidy(fitmeasures(provocation.fit))
tidy(provocation.fit)
```

## Analysis (Shuxian)
```{r h5-analysis, eval = F}
# 6-factor individual predictors
provocation.model.6f <-'
Level: 1
  Retaliation ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
  Withdrawal ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
  Humor ~ D_self_end_CWC + D_other_end_CWC + H_self_end_CWC + H_other_end_CWC + F_self_end_CWC + F_other_end_CWC
Level: 2
  Retaliation  ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
  Withdrawal ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
  Humor ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM 
'

provocation.fit.6f <- sem(
  model = provocation.model.6f,
  data = DF_final_H4,
  cluster = "country_res_full"
)

summary(provocation.fit.6f, 
        standardized = TRUE,
        fit.measures = TRUE,
        rsquare = TRUE)

tidy(fitmeasures(provocation.fit.6f))
tidy(provocation.fit.6f)

# 3-factor individual predictors
provocation.model.3f <-'
Level: 1
  Retaliation ~ D_end_CWC + H_end_CWC + F_end_CWC
  Withdrawal ~ D_end_CWC + H_end_CWC + F_end_CWC
  Humor ~ D_end_CWC + H_end_CWC + F_end_CWC
Level: 2
  Retaliation  ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
  Withdrawal ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM
  Humor ~ D_norm_agg_CGM + H_norm_agg_CGM + F_norm_agg_CGM 
'

provocation.fit.3f <- sem(
  model = provocation.model.3f,
  data = DF_final_H4,
  cluster = "country_res_full"
)

summary(provocation.fit.3f, 
        standardized = TRUE,
        fit.measures = TRUE,
        rsquare = TRUE)

tidy(fitmeasures(provocation.fit.3f))
tidy(provocation.fit.3f)
```
